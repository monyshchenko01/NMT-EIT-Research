{ "cells": [  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-04T10:40:39.669427Z",     "start_time": "2025-06-04T10:40:37.712936Z"    }   },   "cell_type": "code",   "source": "!pip install chardet",   "id": "38ebf8bee66f072c",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "Collecting chardet\r\n",      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\r\n",      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\r\n",      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m199.4/199.4 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",      "\u001B[?25hInstalling collected packages: chardet\r\n",      "Successfully installed chardet-5.2.0\r\n",      "\r\n",      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"     ]    }   ],   "execution_count": 13  },  {   "cell_type": "code",   "id": "initial_id",   "metadata": {    "collapsed": true,    "ExecuteTime": {     "end_time": "2025-06-06T10:37:05.804786Z",     "start_time": "2025-06-06T10:37:05.690779Z"    }   },   "source": [    "config = {\n",    "    \"NMT\": {\n",    "        \"outid\": \"id\",\n",    "        \"Birth\": \"birth_year\",\n",    "        \"SexTypeName\": \"gender\",\n",    "        \"RegName\": \"region_name\",\n",    "        \"AreaName\": \"area_name\",\n",    "        \"TerName\": \"territory_name\",\n",    "        \"RegTypeName\": \"region_type\",\n",    "        \"TerTypeName\": \"territory_type\",\n",    "        \"EOName\": \"education_org_name\",\n",    "        \"EOTypeName\": \"education_org_type\",\n",    "        \"EORegName\": \"education_org_region\",\n",    "        \"EOAreaName\": \"education_org_area\",\n",    "        \"EOTerName\": \"education_org_territory\",\n",    "        \"EOParent\": \"education_org_parent\",\n",    "        \"Test\": \"test_name\",\n",    "        \"TestDate\": \"test_date\",\n",    "\n",    "        \"UkrBlock\": \"ukrainian_test_name\",\n",    "        \"UkrBlockStatus\": \"ukrainian_test_status\",\n",    "        \"UkrBlockBall100\": \"ukrainian_score_100\",\n",    "        \"UkrBlockBall\": \"ukrainian_score\",\n",    "\n",    "        \"HistBlock\": \"history_test_name\",\n",    "        \"HistBlockLang\": \"history_language\",\n",    "        \"HistBlockStatus\": \"history_test_status\",\n",    "        \"HistBlockBall100\": \"history_score_100\",\n",    "        \"HistBlockBall\": \"history_score\",\n",    "\n",    "        \"MathBlock\": \"math_test_name\",\n",    "        \"MathBlockLang\": \"math_language\",\n",    "        \"MathBlockStatus\": \"math_test_status\",\n",    "        \"MathBlockBall100\": \"math_score_100\",\n",    "        \"MathBlockBall\": \"math_score\",\n",    "\n",    "        \"PhysBlock\": \"physics_test_name\",\n",    "        \"PhysBlockLang\": \"physics_language\",\n",    "        \"PhysBlockStatus\": \"physics_test_status\",\n",    "        \"PhysBlockBall100\": \"physics_score_100\",\n",    "        \"PhysBlockBall\": \"physics_score\",\n",    "\n",    "        \"ChemBlock\": \"chemistry_test_name\",\n",    "        \"ChemBlockLang\": \"chemistry_language\",\n",    "        \"ChemBlockStatus\": \"chemistry_test_status\",\n",    "        \"ChemBlockBall100\": \"chemistry_score_100\",\n",    "        \"ChemBlockBall\": \"chemistry_score\",\n",    "\n",    "        \"BioBlock\": \"biology_test_name\",\n",    "        \"BioBlockLang\": \"biology_language\",\n",    "        \"BioBlockStatus\": \"biology_test_status\",\n",    "        \"BioBlockBall100\": \"biology_score_100\",\n",    "        \"BioBlockBall\": \"biology_score\",\n",    "\n",    "        \"GeoBlock\": \"geography_test_name\",\n",    "        \"GeoBlockLang\": \"geography_language\",\n",    "        \"GeoBlockStatus\": \"geography_test_status\",\n",    "        \"GeoBlockBall100\": \"geography_score_100\",\n",    "        \"GeoBlockBall\": \"geography_score\",\n",    "\n",    "        \"EngBlock\": \"english_test_name\",\n",    "        \"EngBlockStatus\": \"english_test_status\",\n",    "        \"EngBlockBall100\": \"english_score_100\",\n",    "        \"EngBlockBall\": \"english_score\",\n",    "\n",    "        \"FraBlock\": \"french_test_name\",\n",    "        \"FraBlockStatus\": \"french_test_status\",\n",    "        \"FraBlockBall100\": \"french_score_100\",\n",    "        \"FraBlockBall\": \"french_score\",\n",    "\n",    "        \"DeuBlock\": \"german_test_name\",\n",    "        \"DeuBlockStatus\": \"german_test_status\",\n",    "        \"DeuBlockBall100\": \"german_score_100\",\n",    "        \"DeuBlockBall\": \"german_score\",\n",    "\n",    "        \"SpaBlock\": \"spanish_test_name\",\n",    "        \"SpaBlockStatus\": \"spanish_test_status\",\n",    "        \"SpaBlockBall100\": \"spanish_score_100\",\n",    "        \"SpaBlockBall\": \"spanish_score\",\n",    "\n",    "        \"UkrLitBlock\": \"ukrainian_lit_test_name\",\n",    "        \"UkrLitBlockStatus\": \"ukrainian_lit_test_status\",\n",    "        \"UkrLitBlockBall100\": \"ukrainian_lit_score_100\",\n",    "        \"UkrLitBlockBall\": \"ukrainian_lit_score\",\n",    "\n",    "        \"PTRegName\": \"pt_region_name\",\n",    "        \"PTAreaName\": \"pt_area_name\",\n",    "        \"PTTerName\": \"pt_territory_name\"\n",    "    },\n",    "\n",    "    \"ZNO\": {\n",    "        \"OUTID\": \"id\",\n",    "        \"Birth\": \"birth_year\",\n",    "        \"SexTypeName\": \"gender\",\n",    "        \"RegName\": \"region_name\",\n",    "        \"AREANAME\": \"area_name\",\n",    "        \"TERNAME\": \"territory_name\",\n",    "        \"RegTypeName\": \"region_type\",\n",    "        \"TerTypeName\": \"territory_type\",\n",    "        \"ClassProfileNAME\": \"class_profile\",\n",    "        \"ClassLangName\": \"class_language\",\n",    "        \"EONAME\": \"education_org_name\",\n",    "        \"EOTypeName\": \"education_org_type\",\n",    "        \"EORegName\": \"education_org_region\",\n",    "        \"EOAreaName\": \"education_org_area\",\n",    "        \"EOTerName\": \"education_org_territory\",\n",    "        \"EOParent\": \"education_org_parent\",\n",    "\n",    "        \"UkrTest\": \"ukrainian_test_name\",\n",    "        \"UkrSubTest\": \"ukrainian_subtest\",\n",    "        \"UkrTestStatus\": \"ukrainian_test_status\",\n",    "        \"UkrBall100\": \"ukrainian_score_100\",\n",    "        \"UkrBall12\": \"ukrainian_score_12\",\n",    "        \"UkrBall\": \"ukrainian_score\",\n",    "        \"UkrAdaptScale\": \"ukrainian_adapt_scale\",\n",    "        \"UkrPTName\": \"ukrainian_pt_name\",\n",    "        \"UkrPTRegName\": \"ukrainian_pt_region\",\n",    "        \"UkrPTAreaName\": \"ukrainian_pt_area\",\n",    "        \"UkrPTTerName\": \"ukrainian_pt_territory\",\n",    "\n",    "        \"HistTest\": \"history_test_name\",\n",    "        \"HistLang\": \"history_language\",\n",    "        \"HistTestStatus\": \"history_test_status\",\n",    "        \"HistBall100\": \"history_score_100\",\n",    "        \"HistBall12\": \"history_score_12\",\n",    "        \"HistBall\": \"history_score\",\n",    "        \"HistPTName\": \"history_pt_name\",\n",    "        \"HistPTRegName\": \"history_pt_region\",\n",    "        \"HistPTAreaName\": \"history_pt_area\",\n",    "        \"HistPTTerName\": \"history_pt_territory\",\n",    "\n",    "        \"MathTest\": \"math_test_name\",\n",    "        \"MathLang\": \"math_language\",\n",    "        \"MathTestStatus\": \"math_test_status\",\n",    "        \"MathBall100\": \"math_score_100\",\n",    "        \"MathBall12\": \"math_score_12\",\n",    "        \"MathDpaLevel\": \"math_dpa_level\",\n",    "        \"MathBall\": \"math_score\",\n",    "        \"MathPTName\": \"math_pt_name\",\n",    "        \"MathPTRegName\": \"math_pt_region\",\n",    "        \"MathPTAreaName\": \"math_pt_area\",\n",    "        \"MathPTTerName\": \"math_pt_territory\",\n",    "\n",    "        \"MathStTest\": \"math_st_test_name\",\n",    "        \"MathStLang\": \"math_st_language\",\n",    "        \"MathStTestStatus\": \"math_st_test_status\",\n",    "        \"MathStBall12\": \"math_st_score_12\",\n",    "        \"MathStBall\": \"math_st_score\",\n",    "        \"MathStPTName\": \"math_st_pt_name\",\n",    "        \"MathStPTRegName\": \"math_st_pt_region\",\n",    "        \"MathStPTAreaName\": \"math_st_pt_area\",\n",    "        \"MathStPTTerName\": \"math_st_pt_territory\",\n",    "\n",    "        \"PhysTest\": \"physics_test_name\",\n",    "        \"PhysLang\": \"physics_language\",\n",    "        \"PhysTestStatus\": \"physics_test_status\",\n",    "        \"PhysBall100\": \"physics_score_100\",\n",    "        \"PhysBall12\": \"physics_score_12\",\n",    "        \"PhysBall\": \"physics_score\",\n",    "        \"PhysPTName\": \"physics_pt_name\",\n",    "        \"PhysPTRegName\": \"physics_pt_region\",\n",    "        \"PhysPTAreaName\": \"physics_pt_area\",\n",    "        \"PhysPTTerName\": \"physics_pt_territory\",\n",    "\n",    "        \"ChemTest\": \"chemistry_test_name\",\n",    "        \"ChemLang\": \"chemistry_language\",\n",    "        \"ChemTestStatus\": \"chemistry_test_status\",\n",    "        \"ChemBall100\": \"chemistry_score_100\",\n",    "        \"ChemBall12\": \"chemistry_score_12\",\n",    "        \"ChemBall\": \"chemistry_score\",\n",    "        \"ChemPTName\": \"chemistry_pt_name\",\n",    "        \"ChemPTRegName\": \"chemistry_pt_region\",\n",    "        \"ChemPTAreaName\": \"chemistry_pt_area\",\n",    "        \"ChemPTTerName\": \"chemistry_pt_territory\",\n",    "\n",    "        \"BioTest\": \"biology_test_name\",\n",    "        \"BioLang\": \"biology_language\",\n",    "        \"BioTestStatus\": \"biology_test_status\",\n",    "        \"BioBall100\": \"biology_score_100\",\n",    "        \"BioBall12\": \"biology_score_12\",\n",    "        \"BioBall\": \"biology_score\",\n",    "        \"BioPTName\": \"biology_pt_name\",\n",    "        \"BioPTRegName\": \"biology_pt_region\",\n",    "        \"BioPTAreaName\": \"biology_pt_area\",\n",    "        \"BioPTTerName\": \"biology_pt_territory\",\n",    "\n",    "        \"GeoTest\": \"geography_test_name\",\n",    "        \"GeoLang\": \"geography_language\",\n",    "        \"GeoTestStatus\": \"geography_test_status\",\n",    "        \"GeoBall100\": \"geography_score_100\",\n",    "        \"GeoBall12\": \"geography_score_12\",\n",    "        \"GeoBall\": \"geography_score\",\n",    "        \"GeoPTName\": \"geography_pt_name\",\n",    "        \"GeoPTRegName\": \"geography_pt_region\",\n",    "        \"GeoPTAreaName\": \"geography_pt_area\",\n",    "        \"GeoPTTerName\": \"geography_pt_territory\",\n",    "\n",    "        \"EngTest\": \"english_test_name\",\n",    "        \"EngTestStatus\": \"english_test_status\",\n",    "        \"EngBall100\": \"english_score_100\",\n",    "        \"EngBall12\": \"english_score_12\",\n",    "        \"EngDPALevel\": \"english_dpa_level\",\n",    "        \"EngBall\": \"english_score\",\n",    "        \"EngPTName\": \"english_pt_name\",\n",    "        \"EngPTRegName\": \"english_pt_region\",\n",    "        \"EngPTAreaName\": \"english_pt_area\",\n",    "        \"EngPTTerName\": \"english_pt_territory\",\n",    "\n",    "        \"FraTest\": \"french_test_name\",\n",    "        \"FraTestStatus\": \"french_test_status\", \n",    "        \"FraBall100\": \"french_score_100\", \n",    "        \"FraBall12\": \"french_score_12\", \n",    "        \"FraDPALevel\": \"french_dpa_level\",    \n",    "        \"FraBall\": \"french_score\",\n",    "        \"FraPTName\": \"french_pt_name\", \n",    "        \"FraPTRegName\":\"french_pt_region\", \n",    "        \"FraPTAreaName\": \"french_pt_area\", \n",    "        \"FraPTTerName\": \"french_pt_territory\", \n",    "\n",    "        \"DeuTest\": \"german_test_name\",\n",    "        \"DeuTestStatus\": \"german_test_status\",\n",    "        \"DeuBall100\": \"german_score_100\",\n",    "        \"DeuBall12\": \"german_score_12\",\n",    "        \"DeuDPALevel\": \"german_dpa_level\",\n",    "        \"DeuBall\": \"german_score\",\n",    "        \"DeuPTName\": \"german_pt_name\", \n",    "        \"DeuPTRegName\": \"german_pt_region\",\n",    "        \"DeuPTAreaName\": \"german_pt_area\", \n",    "        \"DeuPTTerName\": \"german_pt_territory\",\n",    "        \n",    "        \"SpaTest\": \"spanish_test_name\",\n",    "        \"SpaTestStatus\": \"spanish_est_status\", \n",    "        \"SpaBall100\": \"spanish_score_100\", \n",    "        \"SpaBall12\": \"spanish_score_12\", \n",    "        \"SpaDPALevel\": \"spanish_dpa_level\", \n",    "        \"SpaBall\": \"spanish_score\",\n",    "        \"SpaPTName\":\"spanish_pt_name\", \n",    "        \"SpaPTRegName\": \"spanish_pt_region\", \n",    "        \"SpaPTAreaName\": \"spanish_pt_area\",\n",    "        \"SpaPTTerName\": \"spanish_pt_territory\",\n",    "    }\n",    "}\n"   ],   "outputs": [],   "execution_count": 33  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-06T10:38:20.988931Z",     "start_time": "2025-06-06T10:37:11.289485Z"    }   },   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import os\n",    "import json\n",    "import csv\n",    "import chardet\n",    "\n",    "input_folder = \"data\"\n",    "output_folder = \"transformed_data\"\n",    "os.makedirs(output_folder, exist_ok=True)\n",    "\n",    "def detect_mapping(df):\n",    "    df_columns_lower = [col.lower() for col in df.columns]\n",    "\n",    "    for dataset_type in ['NMT', 'ZNO']:\n",    "        if dataset_type in config:\n",    "            mapping = config[dataset_type]\n",    "            mapping_cols_lower = [col.lower() for col in mapping.keys()]\n",    "            matching_cols = [col for col in mapping_cols_lower if col in df_columns_lower]\n",    "            if len(matching_cols) / len(mapping_cols_lower) >= 0.8:\n",    "                return dataset_type, mapping\n",    "    return None, None\n",    "\n",    "\n",    "def detect_encoding(file_path):\n",    "    \"\"\"Detect file encoding using chardet\"\"\"\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)  # Read first 10KB\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    \"\"\"Load CSV with automatic separator detection and encoding handling\"\"\"\n",    "    # First, detect encoding\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'windows-1251'  # Default fallback\n",    "    \n",    "    print(f\"   Використовується кодування: {encoding}\")\n",    "    \n",    "    # Detect separator\n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','  # Default separator\n",    "    \n",    "    # Load the CSV\n",    "    return pd.read_csv(\n",    "        path, \n",    "        encoding=encoding, \n",    "        sep=sep, \n",    "        on_bad_lines='skip',\n",    "        low_memory=False  # Avoid mixed types warning\n",    "    )\n",    "\n",    "def transform_columns(df, mapping):\n",    "    # Створити словник з ключами у нижньому регістрі\n",    "    mapping_lower = {key.lower(): value for key, value in mapping.items()}\n",    "    \n",    "    new_columns = []\n",    "    for col in df.columns:\n",    "        col_lower = col.lower()\n",    "        if col_lower in mapping_lower:\n",    "            new_columns.append(mapping_lower[col_lower])\n",    "        else:\n",    "            new_columns.append(col)  # якщо немає в мапінгу — залишити як є\n",    "    df.columns = new_columns\n",    "    return df\n",    "\n",    "# Process all CSV files\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        output_path = os.path.join(output_folder, filename)\n",    "        print(f\"🔄 Обробка {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   Завантажено {len(df)} рядків, {len(df.columns)} стовпців\")\n",    "            \n",    "            dataset_type, mapping = detect_mapping(df)\n",    "\n",    "            if mapping is None:\n",    "                print(f\"⚠️ Пропущено {filename}: не знайдено відповідного маппінгу колонок\")\n",    "                print(f\"   Доступні колонки: {list(df.columns[:10])}...\") \n",    "                continue\n",    "\n",    "            print(f\"   Визначено тип датасету: {dataset_type}\")\n",    "                                    \n",    "            df = transform_columns(df, mapping)\n",    "            \n",    "            df.to_csv(output_path, index=False, encoding='utf-8')\n",    "            print(f\"✅ Збережено оброблений файл до {output_path}\")\n",    "            print(f\"   Нові колонки: {list(df.columns[:10])}...\") \n",    "\n",    "        except Exception as e:\n",    "            print(f\"❌ Помилка у файлі {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\n🎉 Обробка завершена! Оброблені файли збережено у папці '{output_folder}'\")"   ],   "id": "f7a2e52f6fceb2fd",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "🔄 Обробка 2020.csv...\n",      "   Використовується кодування: windows-1251\n",      "   Завантажено 379299 рядків, 126 стовпців\n",      "   Визначено тип датасету: ZNO\n",      "✅ Збережено оброблений файл до transformed_data/2020.csv\n",      "   Нові колонки: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'class_profile', 'class_language']...\n",      "🔄 Обробка 2021.csv...\n",      "   Використовується кодування: UTF-8-SIG\n",      "   Завантажено 389323 рядків, 147 стовпців\n",      "   Визначено тип датасету: ZNO\n",      "✅ Збережено оброблений файл до transformed_data/2021.csv\n",      "   Нові колонки: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'class_profile', 'class_language']...\n",      "🔄 Обробка 2023.csv...\n",      "   Використовується кодування: UTF-8-SIG\n",      "   Завантажено 288935 рядків, 59 стовпців\n",      "   Визначено тип датасету: NMT\n",      "✅ Збережено оброблений файл до transformed_data/2023.csv\n",      "   Нові колонки: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'education_org_name', 'education_org_type']...\n",      "🔄 Обробка 2022.csv...\n",      "   Використовується кодування: UTF-8-SIG\n",      "   Завантажено 234104 рядків, 29 стовпців\n",      "⚠️ Пропущено 2022.csv: не знайдено відповідного маппінгу колонок\n",      "   Доступні колонки: ['OUTID', 'Birth', 'SexTypeName', 'RegName', 'AREANAME', 'TERNAME', 'RegTypeName', 'TerTypeName', 'EONAME', 'EOTypeName']...\n",      "🔄 Обробка 2019.csv...\n",      "   Використовується кодування: windows-1251\n",      "   Завантажено 353813 рядків, 126 стовпців\n",      "   Визначено тип датасету: ZNO\n",      "✅ Збережено оброблений файл до transformed_data/2019.csv\n",      "   Нові колонки: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'class_profile', 'class_language']...\n",      "🔄 Обробка 2024.csv...\n",      "   Використовується кодування: UTF-8-SIG\n",      "   Завантажено 312508 рядків, 73 стовпців\n",      "   Визначено тип датасету: NMT\n",      "✅ Збережено оброблений файл до transformed_data/2024.csv\n",      "   Нові колонки: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'education_org_name', 'education_org_type']...\n",      "\n",      "🎉 Обробка завершена! Оброблені файли збережено у папці 'transformed_data'\n"     ]    }   ],   "execution_count": 34  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-06T13:54:51.213214Z",     "start_time": "2025-06-06T13:53:30.189070Z"    }   },   "cell_type": "code",   "source": [    "### ADDING FLAGS ###\n",    "import pandas as pd\n",    "import os\n",    "import csv\n",    "import chardet\n",    "import numpy as np\n",    "\n",    "input_folder = \"transformed_data\"\n",    "\n",    "os.makedirs(output_folder, exist_ok=True)\n",    "\n",    "EASTERN_REGIONS = ['Донецька область', 'Луганська область', 'Харківська область', 'Дніпропетровська область']\n",    "WESTERN_REGIONS = ['Львівська область', 'Івано-Франківська область', 'Тернопільська область', 'Закарпатська область', 'Чернівецька область']\n",    "NORTHERN_REGIONS = ['Волинська область', 'Рівненська область', 'Сумська область', 'Чернігівська область', 'Житомирська область']\n",    "SOUTHERN_REGIONS = ['Одеська область', 'Миколаївська область', 'Херсонська область', 'Запорізька область']\n",    "CENTRAL_REGIONS = ['Київська область', 'Черкаська область', 'Полтавська область', 'Кіровоградська область', 'Вінницька область', 'Хмельницька область']\n",    "\n",    "def detect_encoding(file_path):\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'utf-8'\n",    "    print(f\"   Використовується кодування: {encoding}\")\n",    "    \n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','\n",    "\n",    "    return pd.read_csv(\n",    "        path,\n",    "        encoding=encoding,\n",    "        sep=sep,\n",    "        on_bad_lines='skip',\n",    "        low_memory=False\n",    "    )\n",    "\n",    "# def detect_dataset_type(df, config, threshold=0.8):\n",    "#     df_columns_lower = [col.lower() for col in df.columns]\n",    "#     \n",    "#     for dataset_type, mapping in config.items():\n",    "#         mapping_cols_lower = [col.lower() for col in mapping.keys()]\n",    "#         matching_cols = [col for col in mapping_cols_lower if col in df_columns_lower]\n",    "#         if len(matching_cols) / len(mapping_cols_lower) >= threshold:\n",    "#             return dataset_type\n",    "#     return None\n",    "\n",    "def detect_dataset_type_by_filename(filename):\n",    "    import re\n",    "    # Виділяємо рік з назви файлу, наприклад з \"2020.csv\"\n",    "    match = re.search(r'(\\d{4})', filename)\n",    "    if match:\n",    "        year = int(match.group(1))\n",    "        if year < 2022:\n",    "            return 'ZNO'\n",    "        else:\n",    "            return 'NMT'\n",    "    return None\n",    "\n",    "def add_flags_and_features(df, dataset_type):\n",    "    import re\n",    "    score_cols = [col for col in df.columns if 'score_100' in col]\n",    "    for col in score_cols:\n",    "        # Replace commas with dots and convert to numeric\n",    "        df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",    "\n",    "    # Diagnostic: Print stats for score_cols\n",    "    print(f\"   Діагностика для {len(score_cols)} score_100 стовпців:\")\n",    "    for col in score_cols:\n",    "        non_null_count = df[col].notna().sum()\n",    "        positive_count = (df[col] > 0).sum() if non_null_count > 0 else 0\n",    "        print(f\"     {col}: {non_null_count} не-NaN, {positive_count} > 0\")\n",    "    \n",    "    \n",    "    # Convert test_date to datetime (only for NMT)\n",    "    if dataset_type == 'NMT' and 'test_date' in df.columns:\n",    "        df['test_date'] = pd.to_datetime(df['test_date'], errors='coerce')\n",    "    \n",    "        # Calculate student age\n",    "    if 'birth_year' in df.columns:\n",    "        df['birth_year'] = pd.to_numeric(df['birth_year'], errors='coerce')\n",    "        if dataset_type == 'ZNO':\n",    "            # Extract year from filename (e.g., 2020 from 2020.csv)\n",    "            match = re.search(r'(\\d{4})', filename)\n",    "            if match:\n",    "                test_year = int(match.group(1))\n",    "                df['student_age'] = test_year - df['birth_year']\n",    "        elif dataset_type == 'NMT':\n",    "            # Use year from test_date\n",    "            df['student_age'] = df['test_date'].dt.year - df['birth_year']\n",    "        # Ensure student_age is Int64 and handle negative or invalid ages\n",    "        df['student_age'] = df['student_age'].clip(lower=0).astype('Int64')\n",    "    else:\n",    "        print(f\"   Попередження: стовпець 'birth_year' відсутній, 'student_age' не розраховано\")\n",    "        \n",    "    def classify_region(region):\n",    "        if pd.isna(region):\n",    "            return 'other'\n",    "        region = region.strip()\n",    "        if region in EASTERN_REGIONS:\n",    "            return 'east'\n",    "        elif region in WESTERN_REGIONS:\n",    "            return 'west'\n",    "        elif region in NORTHERN_REGIONS:\n",    "            return 'north'\n",    "        elif region in SOUTHERN_REGIONS:\n",    "            return 'south'\n",    "        elif region in CENTRAL_REGIONS:\n",    "            return 'central'\n",    "        else:\n",    "            return 'other'\n",    "\n",    "    df['region_flag'] = df['region_name'].apply(classify_region)\n",    "\n",    "    subject_cols = {\n",    "        'NMT': {\n",    "            'ukrainian': 'ukrainian_score_100',\n",    "            'math': 'math_score_100',\n",    "            'history': 'history_score_100',\n",    "            'physics': 'physics_score_100',\n",    "            'chemistry': 'chemistry_score_100',\n",    "            'biology': 'biology_score_100',\n",    "            'geography': 'geography_score_100',\n",    "            'english': 'english_score_100',\n",    "            'french': 'french_score_100',\n",    "            'german': 'german_score_100',\n",    "            'spanish': 'spanish_score_100',\n",    "            'ukrainian_literature': 'ukrainian_lit_score_100'\n",    "        },\n",    "        'ZNO': {\n",    "            'ukrainian': 'ukrainian_score_100',\n",    "            'math': 'math_score_100',\n",    "            'history': 'history_score_100',\n",    "            'physics': 'physics_score_100',\n",    "            'chemistry': 'chemistry_score_100',\n",    "            'biology': 'biology_score_100',\n",    "            'geography': 'geography_score_100',\n",    "            'english': 'english_score_100',\n",    "            'french': 'french_score_100',\n",    "            'german': 'german_score_100',\n",    "            'spanish': 'spanish_score_100'\n",    "        }\n",    "    }\n",    "\n",    "    subjects_taken = pd.Series(0, index=df.index, dtype='Int64')\n",    "    for subject, col in subject_cols[dataset_type].items():\n",    "        if col in df.columns:\n",    "            subjects_taken += (df[col].notna() & (df[col] >= 0)).astype('Int64')\n",    "    df['subjects_count'] = subjects_taken\n",    "\n",    "    score_cols = [col for col in df.columns if 'score_100' in col]\n",    "    df['total_score'] = df[score_cols].sum(axis=1, skipna=True)\n",    "    df['average_score'] = df[score_cols].mean(axis=1, skipna=True)\n",    "     # Diagnostic: Check total and average scores\n",    "    print(f\"   Діагностика: total_score ненульове: {(df['total_score'] > 0).sum()}, \"f\"average_score non-NaN: {df['average_score'].notna().sum()}\")\n",    "    # if 'education_org_type' in df.columns:\n",    "    #     df['education_org_type'] = df['education_org_type'].str.strip().str.lower()\n",    "    #     df['education_org_type'] = df['education_org_type'].replace({\n",    "    #         'ліцей': 'ліцей',\n",    "    #         'школа': 'школа',\n",    "    #         'університет': 'університет',\n",    "    #         'коледж': 'коледж'\n",    "    #     })\n",    "\n",    "    return df\n",    "\n",    "# Process all CSV files in transformed_data\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        print(f\"🔄 Обробка {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   Завантажено {len(df)} рядків, {len(df.columns)} стовпців\")\n",    "            \n",    "            dataset_type = detect_dataset_type_by_filename(filename)\n",    "            if dataset_type is None:\n",    "                print(f\"⚠️ Пропущено {filename}: не вдалося визначити тип датасету\")\n",    "                print(f\"   Доступні колонки: {list(df.columns[:10])}...\")\n",    "                continue\n",    "\n",    "            print(f\"   Визначено тип датасету: {dataset_type}\")\n",    "                                    \n",    "            # Додаємо всі нові флажки та ознаки\n",    "            df = add_flags_and_features(df, dataset_type)\n",    "\n",    "            # Перезаписуємо той самий файл\n",    "            df.to_csv(input_path, index=False, encoding='utf-8')\n",    "            print(f\"✅ Збережено оброблений файл до {input_path}\")\n",    "            print(f\"   Нові колонки: {list(df.columns[-10:])}...\") \n",    "\n",    "        except Exception as e:\n",    "            print(f\"❌ Помилка у файлі {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\n🎉 Обробка завершена! Всі зміни збережено у папці '{input_folder}'\")"   ],   "id": "21271297a1656521",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "🔄 Обробка 2020.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 379299 рядків, 127 стовпців\n",      "   Визначено тип датасету: ZNO\n",      "   Діагностика для 11 score_100 стовпців:\n",      "     ukrainian_score_100: 274454 не-NaN, 251929 > 0\n",      "     history_score_100: 178642 не-NaN, 154814 > 0\n",      "     math_score_100: 152047 не-NaN, 132734 > 0\n",      "     physics_score_100: 22217 не-NaN, 20517 > 0\n",      "     chemistry_score_100: 11100 не-NaN, 9974 > 0\n",      "     biology_score_100: 74382 не-NaN, 70301 > 0\n",      "     geography_score_100: 92901 не-NaN, 87756 > 0\n",      "     english_score_100: 104965 не-NaN, 97303 > 0\n",      "     french_score_100: 397 не-NaN, 366 > 0\n",      "     german_score_100: 1766 не-NaN, 1565 > 0\n",      "     spanish_score_100: 114 не-NaN, 102 > 0\n",      "   Діагностика: total_score ненульове: 276773, average_score non-NaN: 284592\n",      "✅ Збережено оброблений файл до transformed_data/2020.csv\n",      "   Нові колонки: ['spanish_score', 'spanish_pt_name', 'spanish_pt_region', 'spanish_pt_area', 'spanish_pt_territory', 'student_age', 'region_flag', 'subjects_count', 'total_score', 'average_score']...\n",      "🔄 Обробка 2021.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 389323 рядків, 148 стовпців\n",      "   Визначено тип датасету: ZNO\n",      "   Діагностика для 11 score_100 стовпців:\n",      "     ukrainian_score_100: 288837 не-NaN, 267635 > 0\n",      "     history_score_100: 199373 не-NaN, 163532 > 0\n",      "     math_score_100: 244202 не-NaN, 168369 > 0\n",      "     physics_score_100: 23202 не-NaN, 21275 > 0\n",      "     chemistry_score_100: 9809 не-NaN, 8760 > 0\n",      "     biology_score_100: 81412 не-NaN, 79514 > 0\n",      "     geography_score_100: 113116 не-NaN, 107045 > 0\n",      "     english_score_100: 127714 не-NaN, 114139 > 0\n",      "     french_score_100: 414 не-NaN, 377 > 0\n",      "     german_score_100: 1825 не-NaN, 1617 > 0\n",      "     spanish_score_100: 150 не-NaN, 127 > 0\n",      "   Діагностика: total_score ненульове: 294715, average_score non-NaN: 303565\n",      "✅ Збережено оброблений файл до transformed_data/2021.csv\n",      "   Нові колонки: ['spanish_score', 'spanish_pt_name', 'spanish_pt_region', 'spanish_pt_area', 'spanish_pt_territory', 'student_age', 'region_flag', 'subjects_count', 'total_score', 'average_score']...\n",      "🔄 Обробка 2023.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 288935 рядків, 59 стовпців\n",      "   Визначено тип датасету: NMT\n",      "   Діагностика для 10 score_100 стовпців:\n",      "     ukrainian_score_100: 268128 не-NaN, 267871 > 0\n",      "     history_score_100: 141068 не-NaN, 140844 > 0\n",      "     math_score_100: 268128 не-NaN, 256741 > 0\n",      "     physics_score_100: 5254 не-NaN, 5036 > 0\n",      "     chemistry_score_100: 3218 не-NaN, 3206 > 0\n",      "     biology_score_100: 36009 не-NaN, 35944 > 0\n",      "     english_score_100: 80247 не-NaN, 79814 > 0\n",      "     french_score_100: 273 не-NaN, 272 > 0\n",      "     german_score_100: 1913 не-NaN, 1889 > 0\n",      "     spanish_score_100: 146 не-NaN, 146 > 0\n",      "   Діагностика: total_score ненульове: 268115, average_score non-NaN: 268128\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_60985/169123008.py:86: UserWarning: Parsing dates in %d.%m.%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",      "  df['test_date'] = pd.to_datetime(df['test_date'], errors='coerce')\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "✅ Збережено оброблений файл до transformed_data/2023.csv\n",      "   Нові колонки: ['spanish_score_100', 'spanish_score', 'pt_region_name', 'pt_area_name', 'pt_territory_name', 'student_age', 'region_flag', 'subjects_count', 'total_score', 'average_score']...\n",      "🔄 Обробка 2019.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 353813 рядків, 127 стовпців\n",      "   Визначено тип датасету: ZNO\n",      "   Діагностика для 11 score_100 стовпців:\n",      "     ukrainian_score_100: 338858 не-NaN, 286413 > 0\n",      "     history_score_100: 222449 не-NaN, 186447 > 0\n",      "     math_score_100: 155202 не-NaN, 127093 > 0\n",      "     physics_score_100: 21403 не-NaN, 18202 > 0\n",      "     chemistry_score_100: 13698 не-NaN, 11828 > 0\n",      "     biology_score_100: 76006 не-NaN, 69258 > 0\n",      "     geography_score_100: 75028 не-NaN, 67213 > 0\n",      "     english_score_100: 90906 не-NaN, 79393 > 0\n",      "     french_score_100: 553 не-NaN, 485 > 0\n",      "     german_score_100: 1951 не-NaN, 1550 > 0\n",      "     spanish_score_100: 114 не-NaN, 95 > 0\n",      "   Діагностика: total_score ненульове: 318086, average_score non-NaN: 344861\n",      "✅ Збережено оброблений файл до transformed_data/2019.csv\n",      "   Нові колонки: ['spanish_score', 'spanish_pt_name', 'spanish_pt_region', 'spanish_pt_area', 'spanish_pt_territory', 'student_age', 'region_flag', 'subjects_count', 'total_score', 'average_score']...\n",      "🔄 Обробка 2024.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 312508 рядків, 73 стовпців\n",      "   Визначено тип датасету: NMT\n",      "   Діагностика для 12 score_100 стовпців:\n",      "     ukrainian_score_100: 283370 не-NaN, 282152 > 0\n",      "     history_score_100: 283191 не-NaN, 282866 > 0\n",      "     math_score_100: 283370 не-NaN, 247156 > 0\n",      "     physics_score_100: 7753 не-NaN, 6962 > 0\n",      "     chemistry_score_100: 3270 не-NaN, 3009 > 0\n",      "     biology_score_100: 53965 не-NaN, 53769 > 0\n",      "     geography_score_100: 59917 не-NaN, 59816 > 0\n",      "     english_score_100: 112592 не-NaN, 110352 > 0\n",      "     french_score_100: 275 не-NaN, 270 > 0\n",      "     german_score_100: 2881 не-NaN, 2832 > 0\n",      "     spanish_score_100: 143 не-NaN, 136 > 0\n",      "     ukrainian_lit_score_100: 42395 не-NaN, 41245 > 0\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_60985/169123008.py:86: UserWarning: Parsing dates in %d.%m.%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",      "  df['test_date'] = pd.to_datetime(df['test_date'], errors='coerce')\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "   Діагностика: total_score ненульове: 283358, average_score non-NaN: 283370\n",      "✅ Збережено оброблений файл до transformed_data/2024.csv\n",      "   Нові колонки: ['ukrainian_lit_score_100', 'ukrainian_lit_score', 'pt_region_name', 'pt_area_name', 'pt_territory_name', 'student_age', 'region_flag', 'subjects_count', 'total_score', 'average_score']...\n",      "\n",      "🎉 Обробка завершена! Всі зміни збережено у папці 'transformed_data'\n"     ]    }   ],   "execution_count": 45  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-06T13:53:06.646260Z",     "start_time": "2025-06-06T13:52:07.599965Z"    }   },   "cell_type": "code",   "source": [    "### DROPPING COLUMNS ###\n",    "import pandas as pd\n",    "import os\n",    "import csv\n",    "import chardet\n",    "\n",    "input_folder = \"transformed_data\"\n",    "os.makedirs(input_folder, exist_ok=True)\n",    "\n",    "columns_to_drop = [\n",    "    'total_score', 'average_score', 'subjects_count', 'region_flag',\n",    "]\n",    "\n",    "def detect_encoding(file_path):\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'utf-8'\n",    "    print(f\"   Використовується кодування: {encoding}\")\n",    "    \n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','\n",    "\n",    "    return pd.read_csv(\n",    "        path,\n",    "        encoding=encoding,\n",    "        sep=sep,\n",    "        on_bad_lines='skip',\n",    "        low_memory=False\n",    "    )\n",    "\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        print(f\"🔄 Обробка {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   Завантажено {len(df)} рядків, {len(df.columns)} стовпців\")\n",    "\n",    "            existing_columns = [col for col in columns_to_drop if col in df.columns]\n",    "            if not existing_columns:\n",    "                print(f\"   Жодна з колонок для видалення не знайдена. Пропускаємо.\")\n",    "                continue\n",    "\n",    "            df = df.drop(columns=existing_columns, errors='ignore')\n",    "            print(f\"   Видалено {len(existing_columns)} колонок: {existing_columns}\")\n",    "            print(f\"   Залишилося {len(df.columns)} стовпців\")\n",    "\n",    "            df.to_csv(input_path, index=False, encoding='utf-8')\n",    "            print(f\"✅ Збережено оброблений файл до {input_path}\")\n",    "\n",    "        except Exception as e:\n",    "            print(f\"❌ Помилка у файлі {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\n🎉 Обробка завершена! Оновлені файли збережено у папці '{input_folder}'\")"   ],   "id": "1aa1a50b904282e",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "🔄 Обробка 2020.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 379299 рядків, 131 стовпців\n",      "   Видалено 4 колонок: ['total_score', 'average_score', 'subjects_count', 'region_flag']\n",      "   Залишилося 127 стовпців\n",      "✅ Збережено оброблений файл до transformed_data/2020.csv\n",      "🔄 Обробка 2021.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 389323 рядків, 152 стовпців\n",      "   Видалено 4 колонок: ['total_score', 'average_score', 'subjects_count', 'region_flag']\n",      "   Залишилося 148 стовпців\n",      "✅ Збережено оброблений файл до transformed_data/2021.csv\n",      "🔄 Обробка 2023.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 288935 рядків, 59 стовпців\n",      "   Жодна з колонок для видалення не знайдена. Пропускаємо.\n",      "🔄 Обробка 2019.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 353813 рядків, 131 стовпців\n",      "   Видалено 4 колонок: ['total_score', 'average_score', 'subjects_count', 'region_flag']\n",      "   Залишилося 127 стовпців\n",      "✅ Збережено оброблений файл до transformed_data/2019.csv\n",      "🔄 Обробка 2024.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 312508 рядків, 73 стовпців\n",      "   Жодна з колонок для видалення не знайдена. Пропускаємо.\n",      "\n",      "🎉 Обробка завершена! Оновлені файли збережено у папці 'transformed_data'\n"     ]    }   ],   "execution_count": 44  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}