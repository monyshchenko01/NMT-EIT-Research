{ "cells": [  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-04T10:40:39.669427Z",     "start_time": "2025-06-04T10:40:37.712936Z"    }   },   "cell_type": "code",   "source": "!pip install chardet",   "id": "38ebf8bee66f072c",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "Collecting chardet\r\n",      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\r\n",      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\r\n",      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m199.4/199.4 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",      "\u001B[?25hInstalling collected packages: chardet\r\n",      "Successfully installed chardet-5.2.0\r\n",      "\r\n",      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"     ]    }   ],   "execution_count": 13  },  {   "cell_type": "code",   "id": "initial_id",   "metadata": {    "collapsed": true,    "ExecuteTime": {     "end_time": "2025-06-06T10:37:05.804786Z",     "start_time": "2025-06-06T10:37:05.690779Z"    }   },   "source": [    "config = {\n",    "    \"NMT\": {\n",    "        \"outid\": \"id\",\n",    "        \"Birth\": \"birth_year\",\n",    "        \"SexTypeName\": \"gender\",\n",    "        \"RegName\": \"region_name\",\n",    "        \"AreaName\": \"area_name\",\n",    "        \"TerName\": \"territory_name\",\n",    "        \"RegTypeName\": \"region_type\",\n",    "        \"TerTypeName\": \"territory_type\",\n",    "        \"EOName\": \"education_org_name\",\n",    "        \"EOTypeName\": \"education_org_type\",\n",    "        \"EORegName\": \"education_org_region\",\n",    "        \"EOAreaName\": \"education_org_area\",\n",    "        \"EOTerName\": \"education_org_territory\",\n",    "        \"EOParent\": \"education_org_parent\",\n",    "        \"Test\": \"test_name\",\n",    "        \"TestDate\": \"test_date\",\n",    "\n",    "        \"UkrBlock\": \"ukrainian_test_name\",\n",    "        \"UkrBlockStatus\": \"ukrainian_test_status\",\n",    "        \"UkrBlockBall100\": \"ukrainian_score_100\",\n",    "        \"UkrBlockBall\": \"ukrainian_score\",\n",    "\n",    "        \"HistBlock\": \"history_test_name\",\n",    "        \"HistBlockLang\": \"history_language\",\n",    "        \"HistBlockStatus\": \"history_test_status\",\n",    "        \"HistBlockBall100\": \"history_score_100\",\n",    "        \"HistBlockBall\": \"history_score\",\n",    "\n",    "        \"MathBlock\": \"math_test_name\",\n",    "        \"MathBlockLang\": \"math_language\",\n",    "        \"MathBlockStatus\": \"math_test_status\",\n",    "        \"MathBlockBall100\": \"math_score_100\",\n",    "        \"MathBlockBall\": \"math_score\",\n",    "\n",    "        \"PhysBlock\": \"physics_test_name\",\n",    "        \"PhysBlockLang\": \"physics_language\",\n",    "        \"PhysBlockStatus\": \"physics_test_status\",\n",    "        \"PhysBlockBall100\": \"physics_score_100\",\n",    "        \"PhysBlockBall\": \"physics_score\",\n",    "\n",    "        \"ChemBlock\": \"chemistry_test_name\",\n",    "        \"ChemBlockLang\": \"chemistry_language\",\n",    "        \"ChemBlockStatus\": \"chemistry_test_status\",\n",    "        \"ChemBlockBall100\": \"chemistry_score_100\",\n",    "        \"ChemBlockBall\": \"chemistry_score\",\n",    "\n",    "        \"BioBlock\": \"biology_test_name\",\n",    "        \"BioBlockLang\": \"biology_language\",\n",    "        \"BioBlockStatus\": \"biology_test_status\",\n",    "        \"BioBlockBall100\": \"biology_score_100\",\n",    "        \"BioBlockBall\": \"biology_score\",\n",    "\n",    "        \"GeoBlock\": \"geography_test_name\",\n",    "        \"GeoBlockLang\": \"geography_language\",\n",    "        \"GeoBlockStatus\": \"geography_test_status\",\n",    "        \"GeoBlockBall100\": \"geography_score_100\",\n",    "        \"GeoBlockBall\": \"geography_score\",\n",    "\n",    "        \"EngBlock\": \"english_test_name\",\n",    "        \"EngBlockStatus\": \"english_test_status\",\n",    "        \"EngBlockBall100\": \"english_score_100\",\n",    "        \"EngBlockBall\": \"english_score\",\n",    "\n",    "        \"FraBlock\": \"french_test_name\",\n",    "        \"FraBlockStatus\": \"french_test_status\",\n",    "        \"FraBlockBall100\": \"french_score_100\",\n",    "        \"FraBlockBall\": \"french_score\",\n",    "\n",    "        \"DeuBlock\": \"german_test_name\",\n",    "        \"DeuBlockStatus\": \"german_test_status\",\n",    "        \"DeuBlockBall100\": \"german_score_100\",\n",    "        \"DeuBlockBall\": \"german_score\",\n",    "\n",    "        \"SpaBlock\": \"spanish_test_name\",\n",    "        \"SpaBlockStatus\": \"spanish_test_status\",\n",    "        \"SpaBlockBall100\": \"spanish_score_100\",\n",    "        \"SpaBlockBall\": \"spanish_score\",\n",    "\n",    "        \"UkrLitBlock\": \"ukrainian_lit_test_name\",\n",    "        \"UkrLitBlockStatus\": \"ukrainian_lit_test_status\",\n",    "        \"UkrLitBlockBall100\": \"ukrainian_lit_score_100\",\n",    "        \"UkrLitBlockBall\": \"ukrainian_lit_score\",\n",    "\n",    "        \"PTRegName\": \"pt_region_name\",\n",    "        \"PTAreaName\": \"pt_area_name\",\n",    "        \"PTTerName\": \"pt_territory_name\"\n",    "    },\n",    "\n",    "    \"ZNO\": {\n",    "        \"OUTID\": \"id\",\n",    "        \"Birth\": \"birth_year\",\n",    "        \"SexTypeName\": \"gender\",\n",    "        \"RegName\": \"region_name\",\n",    "        \"AREANAME\": \"area_name\",\n",    "        \"TERNAME\": \"territory_name\",\n",    "        \"RegTypeName\": \"region_type\",\n",    "        \"TerTypeName\": \"territory_type\",\n",    "        \"ClassProfileNAME\": \"class_profile\",\n",    "        \"ClassLangName\": \"class_language\",\n",    "        \"EONAME\": \"education_org_name\",\n",    "        \"EOTypeName\": \"education_org_type\",\n",    "        \"EORegName\": \"education_org_region\",\n",    "        \"EOAreaName\": \"education_org_area\",\n",    "        \"EOTerName\": \"education_org_territory\",\n",    "        \"EOParent\": \"education_org_parent\",\n",    "\n",    "        \"UkrTest\": \"ukrainian_test_name\",\n",    "        \"UkrSubTest\": \"ukrainian_subtest\",\n",    "        \"UkrTestStatus\": \"ukrainian_test_status\",\n",    "        \"UkrBall100\": \"ukrainian_score_100\",\n",    "        \"UkrBall12\": \"ukrainian_score_12\",\n",    "        \"UkrBall\": \"ukrainian_score\",\n",    "        \"UkrAdaptScale\": \"ukrainian_adapt_scale\",\n",    "        \"UkrPTName\": \"ukrainian_pt_name\",\n",    "        \"UkrPTRegName\": \"ukrainian_pt_region\",\n",    "        \"UkrPTAreaName\": \"ukrainian_pt_area\",\n",    "        \"UkrPTTerName\": \"ukrainian_pt_territory\",\n",    "\n",    "        \"HistTest\": \"history_test_name\",\n",    "        \"HistLang\": \"history_language\",\n",    "        \"HistTestStatus\": \"history_test_status\",\n",    "        \"HistBall100\": \"history_score_100\",\n",    "        \"HistBall12\": \"history_score_12\",\n",    "        \"HistBall\": \"history_score\",\n",    "        \"HistPTName\": \"history_pt_name\",\n",    "        \"HistPTRegName\": \"history_pt_region\",\n",    "        \"HistPTAreaName\": \"history_pt_area\",\n",    "        \"HistPTTerName\": \"history_pt_territory\",\n",    "\n",    "        \"MathTest\": \"math_test_name\",\n",    "        \"MathLang\": \"math_language\",\n",    "        \"MathTestStatus\": \"math_test_status\",\n",    "        \"MathBall100\": \"math_score_100\",\n",    "        \"MathBall12\": \"math_score_12\",\n",    "        \"MathDpaLevel\": \"math_dpa_level\",\n",    "        \"MathBall\": \"math_score\",\n",    "        \"MathPTName\": \"math_pt_name\",\n",    "        \"MathPTRegName\": \"math_pt_region\",\n",    "        \"MathPTAreaName\": \"math_pt_area\",\n",    "        \"MathPTTerName\": \"math_pt_territory\",\n",    "\n",    "        \"MathStTest\": \"math_st_test_name\",\n",    "        \"MathStLang\": \"math_st_language\",\n",    "        \"MathStTestStatus\": \"math_st_test_status\",\n",    "        \"MathStBall12\": \"math_st_score_12\",\n",    "        \"MathStBall\": \"math_st_score\",\n",    "        \"MathStPTName\": \"math_st_pt_name\",\n",    "        \"MathStPTRegName\": \"math_st_pt_region\",\n",    "        \"MathStPTAreaName\": \"math_st_pt_area\",\n",    "        \"MathStPTTerName\": \"math_st_pt_territory\",\n",    "\n",    "        \"PhysTest\": \"physics_test_name\",\n",    "        \"PhysLang\": \"physics_language\",\n",    "        \"PhysTestStatus\": \"physics_test_status\",\n",    "        \"PhysBall100\": \"physics_score_100\",\n",    "        \"PhysBall12\": \"physics_score_12\",\n",    "        \"PhysBall\": \"physics_score\",\n",    "        \"PhysPTName\": \"physics_pt_name\",\n",    "        \"PhysPTRegName\": \"physics_pt_region\",\n",    "        \"PhysPTAreaName\": \"physics_pt_area\",\n",    "        \"PhysPTTerName\": \"physics_pt_territory\",\n",    "\n",    "        \"ChemTest\": \"chemistry_test_name\",\n",    "        \"ChemLang\": \"chemistry_language\",\n",    "        \"ChemTestStatus\": \"chemistry_test_status\",\n",    "        \"ChemBall100\": \"chemistry_score_100\",\n",    "        \"ChemBall12\": \"chemistry_score_12\",\n",    "        \"ChemBall\": \"chemistry_score\",\n",    "        \"ChemPTName\": \"chemistry_pt_name\",\n",    "        \"ChemPTRegName\": \"chemistry_pt_region\",\n",    "        \"ChemPTAreaName\": \"chemistry_pt_area\",\n",    "        \"ChemPTTerName\": \"chemistry_pt_territory\",\n",    "\n",    "        \"BioTest\": \"biology_test_name\",\n",    "        \"BioLang\": \"biology_language\",\n",    "        \"BioTestStatus\": \"biology_test_status\",\n",    "        \"BioBall100\": \"biology_score_100\",\n",    "        \"BioBall12\": \"biology_score_12\",\n",    "        \"BioBall\": \"biology_score\",\n",    "        \"BioPTName\": \"biology_pt_name\",\n",    "        \"BioPTRegName\": \"biology_pt_region\",\n",    "        \"BioPTAreaName\": \"biology_pt_area\",\n",    "        \"BioPTTerName\": \"biology_pt_territory\",\n",    "\n",    "        \"GeoTest\": \"geography_test_name\",\n",    "        \"GeoLang\": \"geography_language\",\n",    "        \"GeoTestStatus\": \"geography_test_status\",\n",    "        \"GeoBall100\": \"geography_score_100\",\n",    "        \"GeoBall12\": \"geography_score_12\",\n",    "        \"GeoBall\": \"geography_score\",\n",    "        \"GeoPTName\": \"geography_pt_name\",\n",    "        \"GeoPTRegName\": \"geography_pt_region\",\n",    "        \"GeoPTAreaName\": \"geography_pt_area\",\n",    "        \"GeoPTTerName\": \"geography_pt_territory\",\n",    "\n",    "        \"EngTest\": \"english_test_name\",\n",    "        \"EngTestStatus\": \"english_test_status\",\n",    "        \"EngBall100\": \"english_score_100\",\n",    "        \"EngBall12\": \"english_score_12\",\n",    "        \"EngDPALevel\": \"english_dpa_level\",\n",    "        \"EngBall\": \"english_score\",\n",    "        \"EngPTName\": \"english_pt_name\",\n",    "        \"EngPTRegName\": \"english_pt_region\",\n",    "        \"EngPTAreaName\": \"english_pt_area\",\n",    "        \"EngPTTerName\": \"english_pt_territory\",\n",    "\n",    "        \"FraTest\": \"french_test_name\",\n",    "        \"FraTestStatus\": \"french_test_status\", \n",    "        \"FraBall100\": \"french_score_100\", \n",    "        \"FraBall12\": \"french_score_12\", \n",    "        \"FraDPALevel\": \"french_dpa_level\",    \n",    "        \"FraBall\": \"french_score\",\n",    "        \"FraPTName\": \"french_pt_name\", \n",    "        \"FraPTRegName\":\"french_pt_region\", \n",    "        \"FraPTAreaName\": \"french_pt_area\", \n",    "        \"FraPTTerName\": \"french_pt_territory\", \n",    "\n",    "        \"DeuTest\": \"german_test_name\",\n",    "        \"DeuTestStatus\": \"german_test_status\",\n",    "        \"DeuBall100\": \"german_score_100\",\n",    "        \"DeuBall12\": \"german_score_12\",\n",    "        \"DeuDPALevel\": \"german_dpa_level\",\n",    "        \"DeuBall\": \"german_score\",\n",    "        \"DeuPTName\": \"german_pt_name\", \n",    "        \"DeuPTRegName\": \"german_pt_region\",\n",    "        \"DeuPTAreaName\": \"german_pt_area\", \n",    "        \"DeuPTTerName\": \"german_pt_territory\",\n",    "        \n",    "        \"SpaTest\": \"spanish_test_name\",\n",    "        \"SpaTestStatus\": \"spanish_est_status\", \n",    "        \"SpaBall100\": \"spanish_score_100\", \n",    "        \"SpaBall12\": \"spanish_score_12\", \n",    "        \"SpaDPALevel\": \"spanish_dpa_level\", \n",    "        \"SpaBall\": \"spanish_score\",\n",    "        \"SpaPTName\":\"spanish_pt_name\", \n",    "        \"SpaPTRegName\": \"spanish_pt_region\", \n",    "        \"SpaPTAreaName\": \"spanish_pt_area\",\n",    "        \"SpaPTTerName\": \"spanish_pt_territory\",\n",    "    }\n",    "}\n"   ],   "outputs": [],   "execution_count": 33  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-06T10:38:20.988931Z",     "start_time": "2025-06-06T10:37:11.289485Z"    }   },   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import os\n",    "import json\n",    "import csv\n",    "import chardet\n",    "\n",    "input_folder = \"data\"\n",    "output_folder = \"transformed_data\"\n",    "os.makedirs(output_folder, exist_ok=True)\n",    "\n",    "def detect_mapping(df):\n",    "    df_columns_lower = [col.lower() for col in df.columns]\n",    "\n",    "    for dataset_type in ['NMT', 'ZNO']:\n",    "        if dataset_type in config:\n",    "            mapping = config[dataset_type]\n",    "            mapping_cols_lower = [col.lower() for col in mapping.keys()]\n",    "            matching_cols = [col for col in mapping_cols_lower if col in df_columns_lower]\n",    "            if len(matching_cols) / len(mapping_cols_lower) >= 0.8:\n",    "                return dataset_type, mapping\n",    "    return None, None\n",    "\n",    "\n",    "def detect_encoding(file_path):\n",    "    \"\"\"Detect file encoding using chardet\"\"\"\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)  # Read first 10KB\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    \"\"\"Load CSV with automatic separator detection and encoding handling\"\"\"\n",    "    # First, detect encoding\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'windows-1251'  # Default fallback\n",    "    \n",    "    print(f\"   Використовується кодування: {encoding}\")\n",    "    \n",    "    # Detect separator\n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','  # Default separator\n",    "    \n",    "    # Load the CSV\n",    "    return pd.read_csv(\n",    "        path, \n",    "        encoding=encoding, \n",    "        sep=sep, \n",    "        on_bad_lines='skip',\n",    "        low_memory=False  # Avoid mixed types warning\n",    "    )\n",    "\n",    "def transform_columns(df, mapping):\n",    "    # Створити словник з ключами у нижньому регістрі\n",    "    mapping_lower = {key.lower(): value for key, value in mapping.items()}\n",    "    \n",    "    new_columns = []\n",    "    for col in df.columns:\n",    "        col_lower = col.lower()\n",    "        if col_lower in mapping_lower:\n",    "            new_columns.append(mapping_lower[col_lower])\n",    "        else:\n",    "            new_columns.append(col)  # якщо немає в мапінгу — залишити як є\n",    "    df.columns = new_columns\n",    "    return df\n",    "\n",    "# Process all CSV files\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        output_path = os.path.join(output_folder, filename)\n",    "        print(f\"🔄 Обробка {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   Завантажено {len(df)} рядків, {len(df.columns)} стовпців\")\n",    "            \n",    "            dataset_type, mapping = detect_mapping(df)\n",    "\n",    "            if mapping is None:\n",    "                print(f\"⚠️ Пропущено {filename}: не знайдено відповідного маппінгу колонок\")\n",    "                print(f\"   Доступні колонки: {list(df.columns[:10])}...\") \n",    "                continue\n",    "\n",    "            print(f\"   Визначено тип датасету: {dataset_type}\")\n",    "                                    \n",    "            df = transform_columns(df, mapping)\n",    "            \n",    "            df.to_csv(output_path, index=False, encoding='utf-8')\n",    "            print(f\"✅ Збережено оброблений файл до {output_path}\")\n",    "            print(f\"   Нові колонки: {list(df.columns[:10])}...\") \n",    "\n",    "        except Exception as e:\n",    "            print(f\"❌ Помилка у файлі {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\n🎉 Обробка завершена! Оброблені файли збережено у папці '{output_folder}'\")"   ],   "id": "f7a2e52f6fceb2fd",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "🔄 Обробка 2020.csv...\n",      "   Використовується кодування: windows-1251\n",      "   Завантажено 379299 рядків, 126 стовпців\n",      "   Визначено тип датасету: ZNO\n",      "✅ Збережено оброблений файл до transformed_data/2020.csv\n",      "   Нові колонки: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'class_profile', 'class_language']...\n",      "🔄 Обробка 2021.csv...\n",      "   Використовується кодування: UTF-8-SIG\n",      "   Завантажено 389323 рядків, 147 стовпців\n",      "   Визначено тип датасету: ZNO\n",      "✅ Збережено оброблений файл до transformed_data/2021.csv\n",      "   Нові колонки: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'class_profile', 'class_language']...\n",      "🔄 Обробка 2023.csv...\n",      "   Використовується кодування: UTF-8-SIG\n",      "   Завантажено 288935 рядків, 59 стовпців\n",      "   Визначено тип датасету: NMT\n",      "✅ Збережено оброблений файл до transformed_data/2023.csv\n",      "   Нові колонки: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'education_org_name', 'education_org_type']...\n",      "🔄 Обробка 2022.csv...\n",      "   Використовується кодування: UTF-8-SIG\n",      "   Завантажено 234104 рядків, 29 стовпців\n",      "⚠️ Пропущено 2022.csv: не знайдено відповідного маппінгу колонок\n",      "   Доступні колонки: ['OUTID', 'Birth', 'SexTypeName', 'RegName', 'AREANAME', 'TERNAME', 'RegTypeName', 'TerTypeName', 'EONAME', 'EOTypeName']...\n",      "🔄 Обробка 2019.csv...\n",      "   Використовується кодування: windows-1251\n",      "   Завантажено 353813 рядків, 126 стовпців\n",      "   Визначено тип датасету: ZNO\n",      "✅ Збережено оброблений файл до transformed_data/2019.csv\n",      "   Нові колонки: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'class_profile', 'class_language']...\n",      "🔄 Обробка 2024.csv...\n",      "   Використовується кодування: UTF-8-SIG\n",      "   Завантажено 312508 рядків, 73 стовпців\n",      "   Визначено тип датасету: NMT\n",      "✅ Збережено оброблений файл до transformed_data/2024.csv\n",      "   Нові колонки: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'education_org_name', 'education_org_type']...\n",      "\n",      "🎉 Обробка завершена! Оброблені файли збережено у папці 'transformed_data'\n"     ]    }   ],   "execution_count": 34  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-06T10:43:34.523027Z",     "start_time": "2025-06-06T10:43:30.758613Z"    }   },   "cell_type": "code",   "source": [    "### ADDING FLAGS ###\n",    "import pandas as pd\n",    "import os\n",    "import csv\n",    "import chardet\n",    "import numpy as np\n",    "\n",    "input_folder = \"transformed_data\"\n",    "\n",    "os.makedirs(output_folder, exist_ok=True)\n",    "\n",    "# Географічні регіони України\n",    "EASTERN_REGIONS = ['Донецька область', 'Луганська область', 'Харківська область', 'Дніпропетровська область']\n",    "WESTERN_REGIONS = ['Львівська область', 'Івано-Франківська область', 'Тернопільська область', 'Закарпатська область', 'Чернівецька область']\n",    "NORTHERN_REGIONS = ['Волинська область', 'Рівненська область', 'Сумська область', 'Чернігівська область', 'Житомирська область']\n",    "SOUTHERN_REGIONS = ['Одеська область', 'Миколаївська область', 'Херсонська область', 'Запорізька область']\n",    "CENTRAL_REGIONS = ['Київська область', 'Черкаська область', 'Полтавська область', 'Кіровоградська область', 'Вінницька область', 'Хмельницька область']\n",    "\n",    "def detect_encoding(file_path):\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'utf-8'\n",    "    print(f\"   Використовується кодування: {encoding}\")\n",    "    \n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','\n",    "\n",    "    return pd.read_csv(\n",    "        path,\n",    "        encoding=encoding,\n",    "        sep=sep,\n",    "        on_bad_lines='skip',\n",    "        low_memory=False\n",    "    )\n",    "\n",    "# def detect_dataset_type(df, config, threshold=0.8):\n",    "#     df_columns_lower = [col.lower() for col in df.columns]\n",    "#     \n",    "#     for dataset_type, mapping in config.items():\n",    "#         mapping_cols_lower = [col.lower() for col in mapping.keys()]\n",    "#         matching_cols = [col for col in mapping_cols_lower if col in df_columns_lower]\n",    "#         if len(matching_cols) / len(mapping_cols_lower) >= threshold:\n",    "#             return dataset_type\n",    "#     return None\n",    "def detect_dataset_type_by_filename(filename):\n",    "    import re\n",    "\n",    "    # Виділяємо рік з назви файлу, наприклад з \"2020.csv\"\n",    "    match = re.search(r'(\\d{4})', filename)\n",    "    if match:\n",    "        year = int(match.group(1))\n",    "        if year < 2022:\n",    "            return 'ZNO'\n",    "        else:\n",    "            return 'NMT'\n",    "    return None\n",    "\n",    "def add_flags_and_features(df, dataset_type):\n",    "    score_cols = [col for col in df.columns if 'score_100' in col]\n",    "    for col in score_cols:\n",    "        # Replace commas with dots and convert to numeric\n",    "        df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",    "\n",    "    # Diagnostic: Print stats for score_cols\n",    "    print(f\"   Діагностика для {len(score_cols)} score_100 стовпців:\")\n",    "    for col in score_cols:\n",    "        non_null_count = df[col].notna().sum()\n",    "        positive_count = (df[col] > 0).sum() if non_null_count > 0 else 0\n",    "        print(f\"     {col}: {non_null_count} не-NaN, {positive_count} > 0\")\n",    "\n",    "    # Convert test_date to datetime (only for NMT)\n",    "    # if dataset_type == 'NMT' and 'test_date' in df.columns:\n",    "    #     df['test_date'] = pd.to_datetime(df['test_date'], errors='coerce')\n",    "    def classify_region(region):\n",    "        if pd.isna(region):\n",    "            return 'other'\n",    "        region = region.strip()\n",    "        if region in EASTERN_REGIONS:\n",    "            return 'east'\n",    "        elif region in WESTERN_REGIONS:\n",    "            return 'west'\n",    "        elif region in NORTHERN_REGIONS:\n",    "            return 'north'\n",    "        elif region in SOUTHERN_REGIONS:\n",    "            return 'south'\n",    "        elif region in CENTRAL_REGIONS:\n",    "            return 'central'\n",    "        else:\n",    "            return 'other'\n",    "\n",    "    df['region_flag'] = df['region_name'].apply(classify_region)\n",    "\n",    "    subject_cols = {\n",    "        'NMT': {\n",    "            'ukrainian': 'ukrainian_score_100',\n",    "            'math': 'math_score_100',\n",    "            'history': 'history_score_100',\n",    "            'physics': 'physics_score_100',\n",    "            'chemistry': 'chemistry_score_100',\n",    "            'biology': 'biology_score_100',\n",    "            'geography': 'geography_score_100',\n",    "            'english': 'english_score_100',\n",    "            'french': 'french_score_100',\n",    "            'german': 'german_score_100',\n",    "            'spanish': 'spanish_score_100',\n",    "            'ukrainian_literature': 'ukrainian_literature_score_100'\n",    "        },\n",    "        'ZNO': {\n",    "            'ukrainian': 'ukrainian_score_100',\n",    "            'math': 'math_score_100',\n",    "            'history': 'history_score_100',\n",    "            'physics': 'physics_score_100',\n",    "            'chemistry': 'chemistry_score_100',\n",    "            'biology': 'biology_score_100',\n",    "            'geography': 'geography_score_100',\n",    "            'english': 'english_score_100',\n",    "            'french': 'french_score_100',\n",    "            'german': 'german_score_100',\n",    "            'spanish': 'spanish_score_100'\n",    "        }\n",    "    }\n",    "\n",    "    subjects_taken = pd.Series(0, index=df.index, dtype='Int64')\n",    "    for subject, col in subject_cols[dataset_type].items():\n",    "        if col in df.columns:\n",    "            subjects_taken += (df[col].notna() & (df[col] > 0)).astype('Int64')\n",    "    df['subjects_count'] = subjects_taken\n",    "\n",    "    score_cols = [col for col in df.columns if 'score_100' in col]\n",    "    df['total_score'] = df[score_cols].sum(axis=1, skipna=True)\n",    "    df['average_score'] = df[score_cols].mean(axis=1, skipna=True)\n",    "     # Diagnostic: Check total and average scores\n",    "    print(f\"   Діагностика: total_score ненульове: {(df['total_score'] > 0).sum()}, \"f\"average_score non-NaN: {df['average_score'].notna().sum()}\")\n",    "    # if 'education_org_type' in df.columns:\n",    "    #     df['education_org_type'] = df['education_org_type'].str.strip().str.lower()\n",    "    #     df['education_org_type'] = df['education_org_type'].replace({\n",    "    #         'ліцей': 'ліцей',\n",    "    #         'школа': 'школа',\n",    "    #         'університет': 'університет',\n",    "    #         'коледж': 'коледж'\n",    "    #     })\n",    "\n",    "    return df\n",    "\n",    "# Process all CSV files in transformed_data\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        print(f\"🔄 Обробка {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   Завантажено {len(df)} рядків, {len(df.columns)} стовпців\")\n",    "            \n",    "            dataset_type = detect_dataset_type_by_filename(filename)\n",    "            if dataset_type is None:\n",    "                print(f\"⚠️ Пропущено {filename}: не вдалося визначити тип датасету\")\n",    "                print(f\"   Доступні колонки: {list(df.columns[:10])}...\")\n",    "                continue\n",    "\n",    "            print(f\"   Визначено тип датасету: {dataset_type}\")\n",    "                                    \n",    "            # Додаємо всі нові флажки та ознаки\n",    "            df = add_flags_and_features(df, dataset_type)\n",    "\n",    "            # Перезаписуємо той самий файл\n",    "            df.to_csv(input_path, index=False, encoding='utf-8')\n",    "            print(f\"✅ Збережено оброблений файл до {input_path}\")\n",    "            print(f\"   Нові колонки: {list(df.columns[-10:])}...\") \n",    "\n",    "        except Exception as e:\n",    "            print(f\"❌ Помилка у файлі {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\n🎉 Обробка завершена! Всі зміни збережено у папці '{input_folder}'\")\n",    "\n"   ],   "id": "21271297a1656521",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "🔄 Обробка 2020.csv...\n",      "   Використовується кодування: utf-8\n"     ]    },    {     "ename": "KeyboardInterrupt",     "evalue": "",     "output_type": "error",     "traceback": [      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",      "Cell \u001B[0;32mIn[36], line 163\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m🔄 Обробка \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mload_csv_with_auto_sep\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   Завантажено \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(df)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m рядків, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(df\u001B[38;5;241m.\u001B[39mcolumns)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m стовпців\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    166\u001B[0m     dataset_type \u001B[38;5;241m=\u001B[39m detect_dataset_type_by_filename(filename)\n",      "Cell \u001B[0;32mIn[36], line 38\u001B[0m, in \u001B[0;36mload_csv_with_auto_sep\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     36\u001B[0m     sep \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_bad_lines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mskip\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlow_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m     44\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",      "File \u001B[0;32m~/PycharmProjects/Ma_2/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",      "File \u001B[0;32m~/PycharmProjects/Ma_2/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",      "File \u001B[0;32m~/PycharmProjects/Ma_2/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     (\n\u001B[1;32m   1920\u001B[0m         index,\n\u001B[1;32m   1921\u001B[0m         columns,\n\u001B[1;32m   1922\u001B[0m         col_dict,\n\u001B[0;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",      "File \u001B[0;32m~/PycharmProjects/Ma_2/.venv/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:239\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 239\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_first_chunk:\n",      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "     ]    }   ],   "execution_count": 36  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-06T10:24:46.930919Z",     "start_time": "2025-06-06T10:22:59.791177Z"    }   },   "cell_type": "code",   "source": [    "### DROPPING COLUMNS ###\n",    "import pandas as pd\n",    "import os\n",    "import csv\n",    "import chardet\n",    "\n",    "input_folder = \"transformed_data\"\n",    "os.makedirs(input_folder, exist_ok=True)\n",    "\n",    "columns_to_drop = [\n",    "    'took_ukrainian', \n",    "    'took_math',\n",    "    'took_english', 'took_french',\n",    "    'took_history', 'took_physics', 'took_chemistry', 'took_biology', 'took_geography', 'took_german', 'took_spanish',\n",    "    'took_ukrainian_literature', 'total_score', 'average_score', 'subjects_count', 'region_flag',\n",    "]\n",    "\n",    "def detect_encoding(file_path):\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'utf-8'\n",    "    print(f\"   Використовується кодування: {encoding}\")\n",    "    \n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','\n",    "\n",    "    return pd.read_csv(\n",    "        path,\n",    "        encoding=encoding,\n",    "        sep=sep,\n",    "        on_bad_lines='skip',\n",    "        low_memory=False\n",    "    )\n",    "\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        print(f\"🔄 Обробка {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   Завантажено {len(df)} рядків, {len(df.columns)} стовпців\")\n",    "\n",    "            existing_columns = [col for col in columns_to_drop if col in df.columns]\n",    "            if not existing_columns:\n",    "                print(f\"   Жодна з колонок для видалення не знайдена. Пропускаємо.\")\n",    "                continue\n",    "\n",    "            df = df.drop(columns=existing_columns, errors='ignore')\n",    "            print(f\"   Видалено {len(existing_columns)} колонок: {existing_columns}\")\n",    "            print(f\"   Залишилося {len(df.columns)} стовпців\")\n",    "\n",    "            df.to_csv(input_path, index=False, encoding='utf-8')\n",    "            print(f\"✅ Збережено оброблений файл до {input_path}\")\n",    "\n",    "        except Exception as e:\n",    "            print(f\"❌ Помилка у файлі {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\n🎉 Обробка завершена! Оновлені файли збережено у папці '{input_folder}'\")"   ],   "id": "1aa1a50b904282e",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "🔄 Обробка 2020.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 379299 рядків, 127 стовпців\n",      "   Видалено 1 колонок: ['region_flag']\n",      "   Залишилося 126 стовпців\n",      "✅ Збережено оброблений файл до transformed_data/2020.csv\n",      "🔄 Обробка 2021.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 389323 рядків, 148 стовпців\n",      "   Видалено 1 колонок: ['region_flag']\n",      "   Залишилося 147 стовпців\n",      "✅ Збережено оброблений файл до transformed_data/2021.csv\n",      "🔄 Обробка 2023.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 288935 рядків, 60 стовпців\n",      "   Видалено 1 колонок: ['region_flag']\n",      "   Залишилося 59 стовпців\n",      "✅ Збережено оброблений файл до transformed_data/2023.csv\n",      "🔄 Обробка 2019.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 353813 рядків, 127 стовпців\n",      "   Видалено 1 колонок: ['region_flag']\n",      "   Залишилося 126 стовпців\n",      "✅ Збережено оброблений файл до transformed_data/2019.csv\n",      "🔄 Обробка 2024.csv...\n",      "   Використовується кодування: utf-8\n",      "   Завантажено 312508 рядків, 74 стовпців\n",      "   Видалено 1 колонок: ['region_flag']\n",      "   Залишилося 73 стовпців\n",      "✅ Збережено оброблений файл до transformed_data/2024.csv\n",      "\n",      "🎉 Обробка завершена! Оновлені файли збережено у папці 'transformed_data'\n"     ]    }   ],   "execution_count": 31  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}