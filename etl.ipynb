{ "cells": [  {   "metadata": {},   "cell_type": "code",   "source": "!pip install chardet",   "id": "38ebf8bee66f072c",   "outputs": [],   "execution_count": null  },  {   "cell_type": "code",   "id": "initial_id",   "metadata": {    "collapsed": true   },   "source": [    "config = {\n",    "    \"NMT\": {\n",    "        \"outid\": \"id\",\n",    "        \"Birth\": \"birth_year\",\n",    "        \"SexTypeName\": \"gender\",\n",    "        \"RegName\": \"region_name\",\n",    "        \"AreaName\": \"area_name\",\n",    "        \"TerName\": \"territory_name\",\n",    "        \"RegTypeName\": \"region_type\",\n",    "        \"TerTypeName\": \"territory_type\",\n",    "        \"EOName\": \"education_org_name\",\n",    "        \"EOTypeName\": \"education_org_type\",\n",    "        \"EORegName\": \"education_org_region\",\n",    "        \"EOAreaName\": \"education_org_area\",\n",    "        \"EOTerName\": \"education_org_territory\",\n",    "        \"EOParent\": \"education_org_parent\",\n",    "        \"Test\": \"test_name\",\n",    "        \"TestDate\": \"test_date\",\n",    "\n",    "        \"UkrBlock\": \"ukrainian_test_name\",\n",    "        \"UkrBlockStatus\": \"ukrainian_test_status\",\n",    "        \"UkrBlockBall100\": \"ukrainian_score_100\",\n",    "        \"UkrBlockBall\": \"ukrainian_score\",\n",    "\n",    "        \"HistBlock\": \"history_test_name\",\n",    "        \"HistBlockLang\": \"history_language\",\n",    "        \"HistBlockStatus\": \"history_test_status\",\n",    "        \"HistBlockBall100\": \"history_score_100\",\n",    "        \"HistBlockBall\": \"history_score\",\n",    "\n",    "        \"MathBlock\": \"math_test_name\",\n",    "        \"MathBlockLang\": \"math_language\",\n",    "        \"MathBlockStatus\": \"math_test_status\",\n",    "        \"MathBlockBall100\": \"math_score_100\",\n",    "        \"MathBlockBall\": \"math_score\",\n",    "\n",    "        \"PhysBlock\": \"physics_test_name\",\n",    "        \"PhysBlockLang\": \"physics_language\",\n",    "        \"PhysBlockStatus\": \"physics_test_status\",\n",    "        \"PhysBlockBall100\": \"physics_score_100\",\n",    "        \"PhysBlockBall\": \"physics_score\",\n",    "\n",    "        \"ChemBlock\": \"chemistry_test_name\",\n",    "        \"ChemBlockLang\": \"chemistry_language\",\n",    "        \"ChemBlockStatus\": \"chemistry_test_status\",\n",    "        \"ChemBlockBall100\": \"chemistry_score_100\",\n",    "        \"ChemBlockBall\": \"chemistry_score\",\n",    "\n",    "        \"BioBlock\": \"biology_test_name\",\n",    "        \"BioBlockLang\": \"biology_language\",\n",    "        \"BioBlockStatus\": \"biology_test_status\",\n",    "        \"BioBlockBall100\": \"biology_score_100\",\n",    "        \"BioBlockBall\": \"biology_score\",\n",    "\n",    "        \"GeoBlock\": \"geography_test_name\",\n",    "        \"GeoBlockLang\": \"geography_language\",\n",    "        \"GeoBlockStatus\": \"geography_test_status\",\n",    "        \"GeoBlockBall100\": \"geography_score_100\",\n",    "        \"GeoBlockBall\": \"geography_score\",\n",    "\n",    "        \"EngBlock\": \"english_test_name\",\n",    "        \"EngBlockStatus\": \"english_test_status\",\n",    "        \"EngBlockBall100\": \"english_score_100\",\n",    "        \"EngBlockBall\": \"english_score\",\n",    "\n",    "        \"FraBlock\": \"french_test_name\",\n",    "        \"FraBlockStatus\": \"french_test_status\",\n",    "        \"FraBlockBall100\": \"french_score_100\",\n",    "        \"FraBlockBall\": \"french_score\",\n",    "\n",    "        \"DeuBlock\": \"german_test_name\",\n",    "        \"DeuBlockStatus\": \"german_test_status\",\n",    "        \"DeuBlockBall100\": \"german_score_100\",\n",    "        \"DeuBlockBall\": \"german_score\",\n",    "\n",    "        \"SpaBlock\": \"spanish_test_name\",\n",    "        \"SpaBlockStatus\": \"spanish_test_status\",\n",    "        \"SpaBlockBall100\": \"spanish_score_100\",\n",    "        \"SpaBlockBall\": \"spanish_score\",\n",    "\n",    "        \"UkrLitBlock\": \"ukrainian_lit_test_name\",\n",    "        \"UkrLitBlockStatus\": \"ukrainian_lit_test_status\",\n",    "        \"UkrLitBlockBall100\": \"ukrainian_lit_score_100\",\n",    "        \"UkrLitBlockBall\": \"ukrainian_lit_score\",\n",    "\n",    "        \"PTRegName\": \"pt_region_name\",\n",    "        \"PTAreaName\": \"pt_area_name\",\n",    "        \"PTTerName\": \"pt_territory_name\"\n",    "    },\n",    "\n",    "    \"ZNO\": {\n",    "        \"OUTID\": \"id\",\n",    "        \"Birth\": \"birth_year\",\n",    "        \"SexTypeName\": \"gender\",\n",    "        \"RegName\": \"region_name\",\n",    "        \"AREANAME\": \"area_name\",\n",    "        \"TERNAME\": \"territory_name\",\n",    "        \"RegTypeName\": \"region_type\",\n",    "        \"TerTypeName\": \"territory_type\",\n",    "        \"ClassProfileNAME\": \"class_profile\",\n",    "        \"ClassLangName\": \"class_language\",\n",    "        \"EONAME\": \"education_org_name\",\n",    "        \"EOTypeName\": \"education_org_type\",\n",    "        \"EORegName\": \"education_org_region\",\n",    "        \"EOAreaName\": \"education_org_area\",\n",    "        \"EOTerName\": \"education_org_territory\",\n",    "        \"EOParent\": \"education_org_parent\",\n",    "\n",    "        \"UkrTest\": \"ukrainian_test_name\",\n",    "        \"UkrSubTest\": \"ukrainian_subtest\",\n",    "        \"UkrTestStatus\": \"ukrainian_test_status\",\n",    "        \"UkrBall100\": \"ukrainian_score_100\",\n",    "        \"UkrBall12\": \"ukrainian_score_12\",\n",    "        \"UkrBall\": \"ukrainian_score\",\n",    "        \"UkrAdaptScale\": \"ukrainian_adapt_scale\",\n",    "        \"UkrPTName\": \"ukrainian_pt_name\",\n",    "        \"UkrPTRegName\": \"ukrainian_pt_region\",\n",    "        \"UkrPTAreaName\": \"ukrainian_pt_area\",\n",    "        \"UkrPTTerName\": \"ukrainian_pt_territory\",\n",    "\n",    "        \"HistTest\": \"history_test_name\",\n",    "        \"HistLang\": \"history_language\",\n",    "        \"HistTestStatus\": \"history_test_status\",\n",    "        \"HistBall100\": \"history_score_100\",\n",    "        \"HistBall12\": \"history_score_12\",\n",    "        \"HistBall\": \"history_score\",\n",    "        \"HistPTName\": \"history_pt_name\",\n",    "        \"HistPTRegName\": \"history_pt_region\",\n",    "        \"HistPTAreaName\": \"history_pt_area\",\n",    "        \"HistPTTerName\": \"history_pt_territory\",\n",    "\n",    "        \"MathTest\": \"math_test_name\",\n",    "        \"MathLang\": \"math_language\",\n",    "        \"MathTestStatus\": \"math_test_status\",\n",    "        \"MathBall100\": \"math_score_100\",\n",    "        \"MathBall12\": \"math_score_12\",\n",    "        \"MathDpaLevel\": \"math_dpa_level\",\n",    "        \"MathBall\": \"math_score\",\n",    "        \"MathPTName\": \"math_pt_name\",\n",    "        \"MathPTRegName\": \"math_pt_region\",\n",    "        \"MathPTAreaName\": \"math_pt_area\",\n",    "        \"MathPTTerName\": \"math_pt_territory\",\n",    "\n",    "        \"MathStTest\": \"math_st_test_name\",\n",    "        \"MathStLang\": \"math_st_language\",\n",    "        \"MathStTestStatus\": \"math_st_test_status\",\n",    "        \"MathStBall12\": \"math_st_score_12\",\n",    "        \"MathStBall\": \"math_st_score\",\n",    "        \"MathStPTName\": \"math_st_pt_name\",\n",    "        \"MathStPTRegName\": \"math_st_pt_region\",\n",    "        \"MathStPTAreaName\": \"math_st_pt_area\",\n",    "        \"MathStPTTerName\": \"math_st_pt_territory\",\n",    "\n",    "        \"PhysTest\": \"physics_test_name\",\n",    "        \"PhysLang\": \"physics_language\",\n",    "        \"PhysTestStatus\": \"physics_test_status\",\n",    "        \"PhysBall100\": \"physics_score_100\",\n",    "        \"PhysBall12\": \"physics_score_12\",\n",    "        \"PhysBall\": \"physics_score\",\n",    "        \"PhysPTName\": \"physics_pt_name\",\n",    "        \"PhysPTRegName\": \"physics_pt_region\",\n",    "        \"PhysPTAreaName\": \"physics_pt_area\",\n",    "        \"PhysPTTerName\": \"physics_pt_territory\",\n",    "\n",    "        \"ChemTest\": \"chemistry_test_name\",\n",    "        \"ChemLang\": \"chemistry_language\",\n",    "        \"ChemTestStatus\": \"chemistry_test_status\",\n",    "        \"ChemBall100\": \"chemistry_score_100\",\n",    "        \"ChemBall12\": \"chemistry_score_12\",\n",    "        \"ChemBall\": \"chemistry_score\",\n",    "        \"ChemPTName\": \"chemistry_pt_name\",\n",    "        \"ChemPTRegName\": \"chemistry_pt_region\",\n",    "        \"ChemPTAreaName\": \"chemistry_pt_area\",\n",    "        \"ChemPTTerName\": \"chemistry_pt_territory\",\n",    "\n",    "        \"BioTest\": \"biology_test_name\",\n",    "        \"BioLang\": \"biology_language\",\n",    "        \"BioTestStatus\": \"biology_test_status\",\n",    "        \"BioBall100\": \"biology_score_100\",\n",    "        \"BioBall12\": \"biology_score_12\",\n",    "        \"BioBall\": \"biology_score\",\n",    "        \"BioPTName\": \"biology_pt_name\",\n",    "        \"BioPTRegName\": \"biology_pt_region\",\n",    "        \"BioPTAreaName\": \"biology_pt_area\",\n",    "        \"BioPTTerName\": \"biology_pt_territory\",\n",    "\n",    "        \"GeoTest\": \"geography_test_name\",\n",    "        \"GeoLang\": \"geography_language\",\n",    "        \"GeoTestStatus\": \"geography_test_status\",\n",    "        \"GeoBall100\": \"geography_score_100\",\n",    "        \"GeoBall12\": \"geography_score_12\",\n",    "        \"GeoBall\": \"geography_score\",\n",    "        \"GeoPTName\": \"geography_pt_name\",\n",    "        \"GeoPTRegName\": \"geography_pt_region\",\n",    "        \"GeoPTAreaName\": \"geography_pt_area\",\n",    "        \"GeoPTTerName\": \"geography_pt_territory\",\n",    "\n",    "        \"EngTest\": \"english_test_name\",\n",    "        \"EngTestStatus\": \"english_test_status\",\n",    "        \"EngBall100\": \"english_score_100\",\n",    "        \"EngBall12\": \"english_score_12\",\n",    "        \"EngDPALevel\": \"english_dpa_level\",\n",    "        \"EngBall\": \"english_score\",\n",    "        \"EngPTName\": \"english_pt_name\",\n",    "        \"EngPTRegName\": \"english_pt_region\",\n",    "        \"EngPTAreaName\": \"english_pt_area\",\n",    "        \"EngPTTerName\": \"english_pt_territory\",\n",    "\n",    "        \"FraTest\": \"french_test_name\",\n",    "        \"FraTestStatus\": \"french_test_status\", \n",    "        \"FraBall100\": \"french_score_100\", \n",    "        \"FraBall12\": \"french_score_12\", \n",    "        \"FraDPALevel\": \"french_dpa_level\",    \n",    "        \"FraBall\": \"french_score\",\n",    "        \"FraPTName\": \"french_pt_name\", \n",    "        \"FraPTRegName\":\"french_pt_region\", \n",    "        \"FraPTAreaName\": \"french_pt_area\", \n",    "        \"FraPTTerName\": \"french_pt_territory\", \n",    "\n",    "        \"DeuTest\": \"german_test_name\",\n",    "        \"DeuTestStatus\": \"german_test_status\",\n",    "        \"DeuBall100\": \"german_score_100\",\n",    "        \"DeuBall12\": \"german_score_12\",\n",    "        \"DeuDPALevel\": \"german_dpa_level\",\n",    "        \"DeuBall\": \"german_score\",\n",    "        \"DeuPTName\": \"german_pt_name\", \n",    "        \"DeuPTRegName\": \"german_pt_region\",\n",    "        \"DeuPTAreaName\": \"german_pt_area\", \n",    "        \"DeuPTTerName\": \"german_pt_territory\",\n",    "        \n",    "        \"SpaTest\": \"spanish_test_name\",\n",    "        \"SpaTestStatus\": \"spanish_est_status\", \n",    "        \"SpaBall100\": \"spanish_score_100\", \n",    "        \"SpaBall12\": \"spanish_score_12\", \n",    "        \"SpaDPALevel\": \"spanish_dpa_level\", \n",    "        \"SpaBall\": \"spanish_score\",\n",    "        \"SpaPTName\":\"spanish_pt_name\", \n",    "        \"SpaPTRegName\": \"spanish_pt_region\", \n",    "        \"SpaPTAreaName\": \"spanish_pt_area\",\n",    "        \"SpaPTTerName\": \"spanish_pt_territory\",\n",    "    }\n",    "}\n"   ],   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import os\n",    "import json\n",    "import csv\n",    "import chardet\n",    "\n",    "input_folder = \"data\"\n",    "output_folder = \"transformed_data\"\n",    "os.makedirs(output_folder, exist_ok=True)\n",    "\n",    "def detect_mapping(df):\n",    "    df_columns_lower = [col.lower() for col in df.columns]\n",    "\n",    "    for dataset_type in ['NMT', 'ZNO']:\n",    "        if dataset_type in config:\n",    "            mapping = config[dataset_type]\n",    "            mapping_cols_lower = [col.lower() for col in mapping.keys()]\n",    "            matching_cols = [col for col in mapping_cols_lower if col in df_columns_lower]\n",    "            if len(matching_cols) / len(mapping_cols_lower) >= 0.8:\n",    "                return dataset_type, mapping\n",    "    return None, None\n",    "\n",    "\n",    "def detect_encoding(file_path):\n",    "    \"\"\"Detect file encoding using chardet\"\"\"\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)  # Read first 10KB\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    \"\"\"Load CSV with automatic separator detection and encoding handling\"\"\"\n",    "    # First, detect encoding\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'windows-1251'  # Default fallback\n",    "    \n",    "    print(f\"   Використовується кодування: {encoding}\")\n",    "    \n",    "    # Detect separator\n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','  # Default separator\n",    "    \n",    "    # Load the CSV\n",    "    return pd.read_csv(\n",    "        path, \n",    "        encoding=encoding, \n",    "        sep=sep, \n",    "        on_bad_lines='skip',\n",    "        low_memory=False  # Avoid mixed types warning\n",    "    )\n",    "\n",    "def transform_columns(df, mapping):\n",    "    # Створити словник з ключами у нижньому регістрі\n",    "    mapping_lower = {key.lower(): value for key, value in mapping.items()}\n",    "    \n",    "    new_columns = []\n",    "    for col in df.columns:\n",    "        col_lower = col.lower()\n",    "        if col_lower in mapping_lower:\n",    "            new_columns.append(mapping_lower[col_lower])\n",    "        else:\n",    "            new_columns.append(col)  # якщо немає в мапінгу — залишити як є\n",    "    df.columns = new_columns\n",    "    return df\n",    "\n",    "# Process all CSV files\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        output_path = os.path.join(output_folder, filename)\n",    "        print(f\"🔄 Обробка {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   Завантажено {len(df)} рядків, {len(df.columns)} стовпців\")\n",    "            \n",    "            dataset_type, mapping = detect_mapping(df)\n",    "\n",    "            if mapping is None:\n",    "                print(f\"⚠️ Пропущено {filename}: не знайдено відповідного маппінгу колонок\")\n",    "                print(f\"   Доступні колонки: {list(df.columns[:10])}...\") \n",    "                continue\n",    "\n",    "            print(f\"   Визначено тип датасету: {dataset_type}\")\n",    "                                    \n",    "            df = transform_columns(df, mapping)\n",    "            \n",    "            df.to_csv(output_path, index=False, encoding='utf-8')\n",    "            print(f\"✅ Збережено оброблений файл до {output_path}\")\n",    "            print(f\"   Нові колонки: {list(df.columns[:10])}...\") \n",    "\n",    "        except Exception as e:\n",    "            print(f\"❌ Помилка у файлі {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\n🎉 Обробка завершена! Оброблені файли збережено у папці '{output_folder}'\")"   ],   "id": "f7a2e52f6fceb2fd",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "### ADDING FLAGS ###\n",    "import pandas as pd\n",    "import os\n",    "import csv\n",    "import chardet\n",    "import numpy as np\n",    "\n",    "input_folder = \"transformed_data\"\n",    "\n",    "os.makedirs(output_folder, exist_ok=True)\n",    "\n",    "# Географічні регіони України\n",    "EASTERN_REGIONS = ['Донецька область', 'Луганська область', 'Харківська область', 'Дніпропетровська область']\n",    "WESTERN_REGIONS = ['Львівська область', 'Івано-Франківська область', 'Тернопільська область', 'Закарпатська область', 'Чернівецька область']\n",    "NORTHERN_REGIONS = ['Волинська область', 'Рівненська область', 'Сумська область', 'Чернігівська область', 'Житомирська область']\n",    "SOUTHERN_REGIONS = ['Одеська область', 'Миколаївська область', 'Херсонська область', 'Запорізька область']\n",    "CENTRAL_REGIONS = ['Київська область', 'Черкаська область', 'Полтавська область', 'Кіровоградська область', 'Вінницька область', 'Хмельницька область']\n",    "\n",    "def detect_encoding(file_path):\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'utf-8'\n",    "    print(f\"   Використовується кодування: {encoding}\")\n",    "    \n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','\n",    "\n",    "    return pd.read_csv(\n",    "        path,\n",    "        encoding=encoding,\n",    "        sep=sep,\n",    "        on_bad_lines='skip',\n",    "        low_memory=False\n",    "    )\n",    "\n",    "# def detect_dataset_type(df, config, threshold=0.8):\n",    "#     df_columns_lower = [col.lower() for col in df.columns]\n",    "#     \n",    "#     for dataset_type, mapping in config.items():\n",    "#         mapping_cols_lower = [col.lower() for col in mapping.keys()]\n",    "#         matching_cols = [col for col in mapping_cols_lower if col in df_columns_lower]\n",    "#         if len(matching_cols) / len(mapping_cols_lower) >= threshold:\n",    "#             return dataset_type\n",    "#     return None\n",    "def detect_dataset_type_by_filename(filename):\n",    "    import re\n",    "\n",    "    # Виділяємо рік з назви файлу, наприклад з \"2020.csv\"\n",    "    match = re.search(r'(\\d{4})', filename)\n",    "    if match:\n",    "        year = int(match.group(1))\n",    "        if year < 2022:\n",    "            return 'ZNO'\n",    "        else:\n",    "            return 'NMT'\n",    "    return None\n",    "\n",    "def add_flags_and_features(df, dataset_type):\n",    "    score_cols = [col for col in df.columns if 'score_100' in col]\n",    "    for col in score_cols:\n",    "        # Replace commas with dots and convert to numeric\n",    "        df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",    "\n",    "    # Diagnostic: Print stats for score_cols\n",    "    print(f\"   Діагностика для {len(score_cols)} score_100 стовпців:\")\n",    "    for col in score_cols:\n",    "        non_null_count = df[col].notna().sum()\n",    "        positive_count = (df[col] > 0).sum() if non_null_count > 0 else 0\n",    "        print(f\"     {col}: {non_null_count} не-NaN, {positive_count} > 0\")\n",    "\n",    "    # Convert test_date to datetime (only for NMT)\n",    "    # if dataset_type == 'NMT' and 'test_date' in df.columns:\n",    "    #     df['test_date'] = pd.to_datetime(df['test_date'], errors='coerce')\n",    "    def classify_region(region):\n",    "        if pd.isna(region):\n",    "            return 'other'\n",    "        region = region.strip()\n",    "        if region in EASTERN_REGIONS:\n",    "            return 'east'\n",    "        elif region in WESTERN_REGIONS:\n",    "            return 'west'\n",    "        elif region in NORTHERN_REGIONS:\n",    "            return 'north'\n",    "        elif region in SOUTHERN_REGIONS:\n",    "            return 'south'\n",    "        elif region in CENTRAL_REGIONS:\n",    "            return 'central'\n",    "        else:\n",    "            return 'other'\n",    "\n",    "    df['region_flag'] = df['region_name'].apply(classify_region)\n",    "\n",    "    subject_cols = {\n",    "        'NMT': {\n",    "            'ukrainian': 'ukrainian_score_100',\n",    "            'math': 'math_score_100',\n",    "            'history': 'history_score_100',\n",    "            'physics': 'physics_score_100',\n",    "            'chemistry': 'chemistry_score_100',\n",    "            'biology': 'biology_score_100',\n",    "            'geography': 'geography_score_100',\n",    "            'english': 'english_score_100',\n",    "            'french': 'french_score_100',\n",    "            'german': 'german_score_100',\n",    "            'spanish': 'spanish_score_100',\n",    "            'ukrainian_literature': 'ukrainian_literature_score_100'\n",    "        },\n",    "        'ZNO': {\n",    "            'ukrainian': 'ukrainian_score_100',\n",    "            'math': 'math_score_100',\n",    "            'history': 'history_score_100',\n",    "            'physics': 'physics_score_100',\n",    "            'chemistry': 'chemistry_score_100',\n",    "            'biology': 'biology_score_100',\n",    "            'geography': 'geography_score_100',\n",    "            'english': 'english_score_100',\n",    "            'french': 'french_score_100',\n",    "            'german': 'german_score_100',\n",    "            'spanish': 'spanish_score_100'\n",    "        }\n",    "    }\n",    "\n",    "    subjects_taken = pd.Series(0, index=df.index, dtype='Int64')\n",    "    for subject, col in subject_cols[dataset_type].items():\n",    "        if col in df.columns:\n",    "            subjects_taken += (df[col].notna() & (df[col] > 0)).astype('Int64')\n",    "    df['subjects_count'] = subjects_taken\n",    "\n",    "    score_cols = [col for col in df.columns if 'score_100' in col]\n",    "    df['total_score'] = df[score_cols].sum(axis=1, skipna=True)\n",    "    df['average_score'] = df[score_cols].mean(axis=1, skipna=True)\n",    "     # Diagnostic: Check total and average scores\n",    "    print(f\"   Діагностика: total_score ненульове: {(df['total_score'] > 0).sum()}, \"f\"average_score non-NaN: {df['average_score'].notna().sum()}\")\n",    "    # if 'education_org_type' in df.columns:\n",    "    #     df['education_org_type'] = df['education_org_type'].str.strip().str.lower()\n",    "    #     df['education_org_type'] = df['education_org_type'].replace({\n",    "    #         'ліцей': 'ліцей',\n",    "    #         'школа': 'школа',\n",    "    #         'університет': 'університет',\n",    "    #         'коледж': 'коледж'\n",    "    #     })\n",    "\n",    "    return df\n",    "\n",    "# Process all CSV files in transformed_data\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        print(f\"🔄 Обробка {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   Завантажено {len(df)} рядків, {len(df.columns)} стовпців\")\n",    "            \n",    "            dataset_type = detect_dataset_type_by_filename(filename)\n",    "            if dataset_type is None:\n",    "                print(f\"⚠️ Пропущено {filename}: не вдалося визначити тип датасету\")\n",    "                print(f\"   Доступні колонки: {list(df.columns[:10])}...\")\n",    "                continue\n",    "\n",    "            print(f\"   Визначено тип датасету: {dataset_type}\")\n",    "                                    \n",    "            # Додаємо всі нові флажки та ознаки\n",    "            df = add_flags_and_features(df, dataset_type)\n",    "\n",    "            # Перезаписуємо той самий файл\n",    "            df.to_csv(input_path, index=False, encoding='utf-8')\n",    "            print(f\"✅ Збережено оброблений файл до {input_path}\")\n",    "            print(f\"   Нові колонки: {list(df.columns[-10:])}...\") \n",    "\n",    "        except Exception as e:\n",    "            print(f\"❌ Помилка у файлі {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\n🎉 Обробка завершена! Всі зміни збережено у папці '{input_folder}'\")\n",    "\n"   ],   "id": "21271297a1656521",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "### DROPPING COLUMNS ###\n",    "import pandas as pd\n",    "import os\n",    "import csv\n",    "import chardet\n",    "\n",    "input_folder = \"transformed_data\"\n",    "os.makedirs(input_folder, exist_ok=True)\n",    "\n",    "columns_to_drop = [\n",    "    'took_ukrainian', \n",    "    'took_math',\n",    "    'took_english', 'took_french',\n",    "    'took_history', 'took_physics', 'took_chemistry', 'took_biology', 'took_geography', 'took_german', 'took_spanish',\n",    "    'took_ukrainian_literature', 'total_score', 'average_score', 'subjects_count', 'region_flag',\n",    "]\n",    "\n",    "def detect_encoding(file_path):\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'utf-8'\n",    "    print(f\"   Використовується кодування: {encoding}\")\n",    "    \n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','\n",    "\n",    "    return pd.read_csv(\n",    "        path,\n",    "        encoding=encoding,\n",    "        sep=sep,\n",    "        on_bad_lines='skip',\n",    "        low_memory=False\n",    "    )\n",    "\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        print(f\"🔄 Обробка {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   Завантажено {len(df)} рядків, {len(df.columns)} стовпців\")\n",    "\n",    "            existing_columns = [col for col in columns_to_drop if col in df.columns]\n",    "            if not existing_columns:\n",    "                print(f\"   Жодна з колонок для видалення не знайдена. Пропускаємо.\")\n",    "                continue\n",    "\n",    "            df = df.drop(columns=existing_columns, errors='ignore')\n",    "            print(f\"   Видалено {len(existing_columns)} колонок: {existing_columns}\")\n",    "            print(f\"   Залишилося {len(df.columns)} стовпців\")\n",    "\n",    "            df.to_csv(input_path, index=False, encoding='utf-8')\n",    "            print(f\"✅ Збережено оброблений файл до {input_path}\")\n",    "\n",    "        except Exception as e:\n",    "            print(f\"❌ Помилка у файлі {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\n🎉 Обробка завершена! Оновлені файли збережено у папці '{input_folder}'\")"   ],   "id": "1aa1a50b904282e",   "outputs": [],   "execution_count": null  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}