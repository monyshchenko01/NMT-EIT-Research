{ "cells": [  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-04T10:40:39.669427Z",     "start_time": "2025-06-04T10:40:37.712936Z"    }   },   "cell_type": "code",   "source": "!pip install chardet",   "id": "38ebf8bee66f072c",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "Collecting chardet\r\n",      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\r\n",      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\r\n",      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m199.4/199.4 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",      "\u001B[?25hInstalling collected packages: chardet\r\n",      "Successfully installed chardet-5.2.0\r\n",      "\r\n",      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"     ]    }   ],   "execution_count": 13  },  {   "cell_type": "code",   "id": "initial_id",   "metadata": {    "collapsed": true,    "ExecuteTime": {     "end_time": "2025-06-06T10:37:05.804786Z",     "start_time": "2025-06-06T10:37:05.690779Z"    }   },   "source": [    "config = {\n",    "    \"NMT\": {\n",    "        \"outid\": \"id\",\n",    "        \"Birth\": \"birth_year\",\n",    "        \"SexTypeName\": \"gender\",\n",    "        \"RegName\": \"region_name\",\n",    "        \"AreaName\": \"area_name\",\n",    "        \"TerName\": \"territory_name\",\n",    "        \"RegTypeName\": \"region_type\",\n",    "        \"TerTypeName\": \"territory_type\",\n",    "        \"EOName\": \"education_org_name\",\n",    "        \"EOTypeName\": \"education_org_type\",\n",    "        \"EORegName\": \"education_org_region\",\n",    "        \"EOAreaName\": \"education_org_area\",\n",    "        \"EOTerName\": \"education_org_territory\",\n",    "        \"EOParent\": \"education_org_parent\",\n",    "        \"Test\": \"test_name\",\n",    "        \"TestDate\": \"test_date\",\n",    "\n",    "        \"UkrBlock\": \"ukrainian_test_name\",\n",    "        \"UkrBlockStatus\": \"ukrainian_test_status\",\n",    "        \"UkrBlockBall100\": \"ukrainian_score_100\",\n",    "        \"UkrBlockBall\": \"ukrainian_score\",\n",    "\n",    "        \"HistBlock\": \"history_test_name\",\n",    "        \"HistBlockLang\": \"history_language\",\n",    "        \"HistBlockStatus\": \"history_test_status\",\n",    "        \"HistBlockBall100\": \"history_score_100\",\n",    "        \"HistBlockBall\": \"history_score\",\n",    "\n",    "        \"MathBlock\": \"math_test_name\",\n",    "        \"MathBlockLang\": \"math_language\",\n",    "        \"MathBlockStatus\": \"math_test_status\",\n",    "        \"MathBlockBall100\": \"math_score_100\",\n",    "        \"MathBlockBall\": \"math_score\",\n",    "\n",    "        \"PhysBlock\": \"physics_test_name\",\n",    "        \"PhysBlockLang\": \"physics_language\",\n",    "        \"PhysBlockStatus\": \"physics_test_status\",\n",    "        \"PhysBlockBall100\": \"physics_score_100\",\n",    "        \"PhysBlockBall\": \"physics_score\",\n",    "\n",    "        \"ChemBlock\": \"chemistry_test_name\",\n",    "        \"ChemBlockLang\": \"chemistry_language\",\n",    "        \"ChemBlockStatus\": \"chemistry_test_status\",\n",    "        \"ChemBlockBall100\": \"chemistry_score_100\",\n",    "        \"ChemBlockBall\": \"chemistry_score\",\n",    "\n",    "        \"BioBlock\": \"biology_test_name\",\n",    "        \"BioBlockLang\": \"biology_language\",\n",    "        \"BioBlockStatus\": \"biology_test_status\",\n",    "        \"BioBlockBall100\": \"biology_score_100\",\n",    "        \"BioBlockBall\": \"biology_score\",\n",    "\n",    "        \"GeoBlock\": \"geography_test_name\",\n",    "        \"GeoBlockLang\": \"geography_language\",\n",    "        \"GeoBlockStatus\": \"geography_test_status\",\n",    "        \"GeoBlockBall100\": \"geography_score_100\",\n",    "        \"GeoBlockBall\": \"geography_score\",\n",    "\n",    "        \"EngBlock\": \"english_test_name\",\n",    "        \"EngBlockStatus\": \"english_test_status\",\n",    "        \"EngBlockBall100\": \"english_score_100\",\n",    "        \"EngBlockBall\": \"english_score\",\n",    "\n",    "        \"FraBlock\": \"french_test_name\",\n",    "        \"FraBlockStatus\": \"french_test_status\",\n",    "        \"FraBlockBall100\": \"french_score_100\",\n",    "        \"FraBlockBall\": \"french_score\",\n",    "\n",    "        \"DeuBlock\": \"german_test_name\",\n",    "        \"DeuBlockStatus\": \"german_test_status\",\n",    "        \"DeuBlockBall100\": \"german_score_100\",\n",    "        \"DeuBlockBall\": \"german_score\",\n",    "\n",    "        \"SpaBlock\": \"spanish_test_name\",\n",    "        \"SpaBlockStatus\": \"spanish_test_status\",\n",    "        \"SpaBlockBall100\": \"spanish_score_100\",\n",    "        \"SpaBlockBall\": \"spanish_score\",\n",    "\n",    "        \"UkrLitBlock\": \"ukrainian_lit_test_name\",\n",    "        \"UkrLitBlockStatus\": \"ukrainian_lit_test_status\",\n",    "        \"UkrLitBlockBall100\": \"ukrainian_lit_score_100\",\n",    "        \"UkrLitBlockBall\": \"ukrainian_lit_score\",\n",    "\n",    "        \"PTRegName\": \"pt_region_name\",\n",    "        \"PTAreaName\": \"pt_area_name\",\n",    "        \"PTTerName\": \"pt_territory_name\"\n",    "    },\n",    "\n",    "    \"ZNO\": {\n",    "        \"OUTID\": \"id\",\n",    "        \"Birth\": \"birth_year\",\n",    "        \"SexTypeName\": \"gender\",\n",    "        \"RegName\": \"region_name\",\n",    "        \"AREANAME\": \"area_name\",\n",    "        \"TERNAME\": \"territory_name\",\n",    "        \"RegTypeName\": \"region_type\",\n",    "        \"TerTypeName\": \"territory_type\",\n",    "        \"ClassProfileNAME\": \"class_profile\",\n",    "        \"ClassLangName\": \"class_language\",\n",    "        \"EONAME\": \"education_org_name\",\n",    "        \"EOTypeName\": \"education_org_type\",\n",    "        \"EORegName\": \"education_org_region\",\n",    "        \"EOAreaName\": \"education_org_area\",\n",    "        \"EOTerName\": \"education_org_territory\",\n",    "        \"EOParent\": \"education_org_parent\",\n",    "\n",    "        \"UkrTest\": \"ukrainian_test_name\",\n",    "        \"UkrSubTest\": \"ukrainian_subtest\",\n",    "        \"UkrTestStatus\": \"ukrainian_test_status\",\n",    "        \"UkrBall100\": \"ukrainian_score_100\",\n",    "        \"UkrBall12\": \"ukrainian_score_12\",\n",    "        \"UkrBall\": \"ukrainian_score\",\n",    "        \"UkrAdaptScale\": \"ukrainian_adapt_scale\",\n",    "        \"UkrPTName\": \"ukrainian_pt_name\",\n",    "        \"UkrPTRegName\": \"ukrainian_pt_region\",\n",    "        \"UkrPTAreaName\": \"ukrainian_pt_area\",\n",    "        \"UkrPTTerName\": \"ukrainian_pt_territory\",\n",    "\n",    "        \"HistTest\": \"history_test_name\",\n",    "        \"HistLang\": \"history_language\",\n",    "        \"HistTestStatus\": \"history_test_status\",\n",    "        \"HistBall100\": \"history_score_100\",\n",    "        \"HistBall12\": \"history_score_12\",\n",    "        \"HistBall\": \"history_score\",\n",    "        \"HistPTName\": \"history_pt_name\",\n",    "        \"HistPTRegName\": \"history_pt_region\",\n",    "        \"HistPTAreaName\": \"history_pt_area\",\n",    "        \"HistPTTerName\": \"history_pt_territory\",\n",    "\n",    "        \"MathTest\": \"math_test_name\",\n",    "        \"MathLang\": \"math_language\",\n",    "        \"MathTestStatus\": \"math_test_status\",\n",    "        \"MathBall100\": \"math_score_100\",\n",    "        \"MathBall12\": \"math_score_12\",\n",    "        \"MathDpaLevel\": \"math_dpa_level\",\n",    "        \"MathBall\": \"math_score\",\n",    "        \"MathPTName\": \"math_pt_name\",\n",    "        \"MathPTRegName\": \"math_pt_region\",\n",    "        \"MathPTAreaName\": \"math_pt_area\",\n",    "        \"MathPTTerName\": \"math_pt_territory\",\n",    "\n",    "        \"MathStTest\": \"math_st_test_name\",\n",    "        \"MathStLang\": \"math_st_language\",\n",    "        \"MathStTestStatus\": \"math_st_test_status\",\n",    "        \"MathStBall12\": \"math_st_score_12\",\n",    "        \"MathStBall\": \"math_st_score\",\n",    "        \"MathStPTName\": \"math_st_pt_name\",\n",    "        \"MathStPTRegName\": \"math_st_pt_region\",\n",    "        \"MathStPTAreaName\": \"math_st_pt_area\",\n",    "        \"MathStPTTerName\": \"math_st_pt_territory\",\n",    "\n",    "        \"PhysTest\": \"physics_test_name\",\n",    "        \"PhysLang\": \"physics_language\",\n",    "        \"PhysTestStatus\": \"physics_test_status\",\n",    "        \"PhysBall100\": \"physics_score_100\",\n",    "        \"PhysBall12\": \"physics_score_12\",\n",    "        \"PhysBall\": \"physics_score\",\n",    "        \"PhysPTName\": \"physics_pt_name\",\n",    "        \"PhysPTRegName\": \"physics_pt_region\",\n",    "        \"PhysPTAreaName\": \"physics_pt_area\",\n",    "        \"PhysPTTerName\": \"physics_pt_territory\",\n",    "\n",    "        \"ChemTest\": \"chemistry_test_name\",\n",    "        \"ChemLang\": \"chemistry_language\",\n",    "        \"ChemTestStatus\": \"chemistry_test_status\",\n",    "        \"ChemBall100\": \"chemistry_score_100\",\n",    "        \"ChemBall12\": \"chemistry_score_12\",\n",    "        \"ChemBall\": \"chemistry_score\",\n",    "        \"ChemPTName\": \"chemistry_pt_name\",\n",    "        \"ChemPTRegName\": \"chemistry_pt_region\",\n",    "        \"ChemPTAreaName\": \"chemistry_pt_area\",\n",    "        \"ChemPTTerName\": \"chemistry_pt_territory\",\n",    "\n",    "        \"BioTest\": \"biology_test_name\",\n",    "        \"BioLang\": \"biology_language\",\n",    "        \"BioTestStatus\": \"biology_test_status\",\n",    "        \"BioBall100\": \"biology_score_100\",\n",    "        \"BioBall12\": \"biology_score_12\",\n",    "        \"BioBall\": \"biology_score\",\n",    "        \"BioPTName\": \"biology_pt_name\",\n",    "        \"BioPTRegName\": \"biology_pt_region\",\n",    "        \"BioPTAreaName\": \"biology_pt_area\",\n",    "        \"BioPTTerName\": \"biology_pt_territory\",\n",    "\n",    "        \"GeoTest\": \"geography_test_name\",\n",    "        \"GeoLang\": \"geography_language\",\n",    "        \"GeoTestStatus\": \"geography_test_status\",\n",    "        \"GeoBall100\": \"geography_score_100\",\n",    "        \"GeoBall12\": \"geography_score_12\",\n",    "        \"GeoBall\": \"geography_score\",\n",    "        \"GeoPTName\": \"geography_pt_name\",\n",    "        \"GeoPTRegName\": \"geography_pt_region\",\n",    "        \"GeoPTAreaName\": \"geography_pt_area\",\n",    "        \"GeoPTTerName\": \"geography_pt_territory\",\n",    "\n",    "        \"EngTest\": \"english_test_name\",\n",    "        \"EngTestStatus\": \"english_test_status\",\n",    "        \"EngBall100\": \"english_score_100\",\n",    "        \"EngBall12\": \"english_score_12\",\n",    "        \"EngDPALevel\": \"english_dpa_level\",\n",    "        \"EngBall\": \"english_score\",\n",    "        \"EngPTName\": \"english_pt_name\",\n",    "        \"EngPTRegName\": \"english_pt_region\",\n",    "        \"EngPTAreaName\": \"english_pt_area\",\n",    "        \"EngPTTerName\": \"english_pt_territory\",\n",    "\n",    "        \"FraTest\": \"french_test_name\",\n",    "        \"FraTestStatus\": \"french_test_status\", \n",    "        \"FraBall100\": \"french_score_100\", \n",    "        \"FraBall12\": \"french_score_12\", \n",    "        \"FraDPALevel\": \"french_dpa_level\",    \n",    "        \"FraBall\": \"french_score\",\n",    "        \"FraPTName\": \"french_pt_name\", \n",    "        \"FraPTRegName\":\"french_pt_region\", \n",    "        \"FraPTAreaName\": \"french_pt_area\", \n",    "        \"FraPTTerName\": \"french_pt_territory\", \n",    "\n",    "        \"DeuTest\": \"german_test_name\",\n",    "        \"DeuTestStatus\": \"german_test_status\",\n",    "        \"DeuBall100\": \"german_score_100\",\n",    "        \"DeuBall12\": \"german_score_12\",\n",    "        \"DeuDPALevel\": \"german_dpa_level\",\n",    "        \"DeuBall\": \"german_score\",\n",    "        \"DeuPTName\": \"german_pt_name\", \n",    "        \"DeuPTRegName\": \"german_pt_region\",\n",    "        \"DeuPTAreaName\": \"german_pt_area\", \n",    "        \"DeuPTTerName\": \"german_pt_territory\",\n",    "        \n",    "        \"SpaTest\": \"spanish_test_name\",\n",    "        \"SpaTestStatus\": \"spanish_est_status\", \n",    "        \"SpaBall100\": \"spanish_score_100\", \n",    "        \"SpaBall12\": \"spanish_score_12\", \n",    "        \"SpaDPALevel\": \"spanish_dpa_level\", \n",    "        \"SpaBall\": \"spanish_score\",\n",    "        \"SpaPTName\":\"spanish_pt_name\", \n",    "        \"SpaPTRegName\": \"spanish_pt_region\", \n",    "        \"SpaPTAreaName\": \"spanish_pt_area\",\n",    "        \"SpaPTTerName\": \"spanish_pt_territory\",\n",    "    }\n",    "}\n"   ],   "outputs": [],   "execution_count": 33  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-06T10:38:20.988931Z",     "start_time": "2025-06-06T10:37:11.289485Z"    }   },   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import os\n",    "import json\n",    "import csv\n",    "import chardet\n",    "\n",    "input_folder = \"data\"\n",    "output_folder = \"transformed_data\"\n",    "os.makedirs(output_folder, exist_ok=True)\n",    "\n",    "def detect_mapping(df):\n",    "    df_columns_lower = [col.lower() for col in df.columns]\n",    "\n",    "    for dataset_type in ['NMT', 'ZNO']:\n",    "        if dataset_type in config:\n",    "            mapping = config[dataset_type]\n",    "            mapping_cols_lower = [col.lower() for col in mapping.keys()]\n",    "            matching_cols = [col for col in mapping_cols_lower if col in df_columns_lower]\n",    "            if len(matching_cols) / len(mapping_cols_lower) >= 0.8:\n",    "                return dataset_type, mapping\n",    "    return None, None\n",    "\n",    "\n",    "def detect_encoding(file_path):\n",    "    \"\"\"Detect file encoding using chardet\"\"\"\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)  # Read first 10KB\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    \"\"\"Load CSV with automatic separator detection and encoding handling\"\"\"\n",    "    # First, detect encoding\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'windows-1251'  # Default fallback\n",    "    \n",    "    print(f\"   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: {encoding}\")\n",    "    \n",    "    # Detect separator\n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','  # Default separator\n",    "    \n",    "    # Load the CSV\n",    "    return pd.read_csv(\n",    "        path, \n",    "        encoding=encoding, \n",    "        sep=sep, \n",    "        on_bad_lines='skip',\n",    "        low_memory=False  # Avoid mixed types warning\n",    "    )\n",    "\n",    "def transform_columns(df, mapping):\n",    "    # –°—Ç–≤–æ—Ä–∏—Ç–∏ —Å–ª–æ–≤–Ω–∏–∫ –∑ –∫–ª—é—á–∞–º–∏ —É –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ\n",    "    mapping_lower = {key.lower(): value for key, value in mapping.items()}\n",    "    \n",    "    new_columns = []\n",    "    for col in df.columns:\n",    "        col_lower = col.lower()\n",    "        if col_lower in mapping_lower:\n",    "            new_columns.append(mapping_lower[col_lower])\n",    "        else:\n",    "            new_columns.append(col)  # —è–∫—â–æ –Ω–µ–º–∞—î –≤ –º–∞–ø—ñ–Ω–≥—É ‚Äî –∑–∞–ª–∏—à–∏—Ç–∏ —è–∫ —î\n",    "    df.columns = new_columns\n",    "    return df\n",    "\n",    "# Process all CSV files\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        output_path = os.path.join(output_folder, filename)\n",    "        print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "            \n",    "            dataset_type, mapping = detect_mapping(df)\n",    "\n",    "            if mapping is None:\n",    "                print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {filename}: –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ–≥–æ –º–∞–ø–ø—ñ–Ω–≥—É –∫–æ–ª–æ–Ω–æ–∫\")\n",    "                print(f\"   –î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns[:10])}...\") \n",    "                continue\n",    "\n",    "            print(f\"   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: {dataset_type}\")\n",    "                                    \n",    "            df = transform_columns(df, mapping)\n",    "            \n",    "            df.to_csv(output_path, index=False, encoding='utf-8')\n",    "            print(f\"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ {output_path}\")\n",    "            print(f\"   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns[:10])}...\") \n",    "\n",    "        except Exception as e:\n",    "            print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\nüéâ –û–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ñ–∞–π–ª–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É –ø–∞–ø—Ü—ñ '{output_folder}'\")"   ],   "id": "f7a2e52f6fceb2fd",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîÑ –û–±—Ä–æ–±–∫–∞ 2020.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: windows-1251\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 379299 —Ä—è–¥–∫—ñ–≤, 126 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: ZNO\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2020.csv\n",      "   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'class_profile', 'class_language']...\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2021.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: UTF-8-SIG\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 389323 —Ä—è–¥–∫—ñ–≤, 147 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: ZNO\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2021.csv\n",      "   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'class_profile', 'class_language']...\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2023.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: UTF-8-SIG\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 288935 —Ä—è–¥–∫—ñ–≤, 59 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: NMT\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2023.csv\n",      "   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'education_org_name', 'education_org_type']...\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2022.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: UTF-8-SIG\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 234104 —Ä—è–¥–∫—ñ–≤, 29 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ 2022.csv: –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ–≥–æ –º–∞–ø–ø—ñ–Ω–≥—É –∫–æ–ª–æ–Ω–æ–∫\n",      "   –î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: ['OUTID', 'Birth', 'SexTypeName', 'RegName', 'AREANAME', 'TERNAME', 'RegTypeName', 'TerTypeName', 'EONAME', 'EOTypeName']...\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2019.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: windows-1251\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 353813 —Ä—è–¥–∫—ñ–≤, 126 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: ZNO\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2019.csv\n",      "   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'class_profile', 'class_language']...\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2024.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: UTF-8-SIG\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 312508 —Ä—è–¥–∫—ñ–≤, 73 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: NMT\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2024.csv\n",      "   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: ['id', 'birth_year', 'gender', 'region_name', 'area_name', 'territory_name', 'region_type', 'territory_type', 'education_org_name', 'education_org_type']...\n",      "\n",      "üéâ –û–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ñ–∞–π–ª–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É –ø–∞–ø—Ü—ñ 'transformed_data'\n"     ]    }   ],   "execution_count": 34  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-06T13:54:51.213214Z",     "start_time": "2025-06-06T13:53:30.189070Z"    }   },   "cell_type": "code",   "source": [    "### ADDING FLAGS ###\n",    "import pandas as pd\n",    "import os\n",    "import csv\n",    "import chardet\n",    "import numpy as np\n",    "\n",    "input_folder = \"transformed_data\"\n",    "\n",    "os.makedirs(output_folder, exist_ok=True)\n",    "\n",    "EASTERN_REGIONS = ['–î–æ–Ω–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–õ—É–≥–∞–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–•–∞—Ä–∫—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å']\n",    "WESTERN_REGIONS = ['–õ—å–≤—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–Ü–≤–∞–Ω–æ-–§—Ä–∞–Ω–∫—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–¢–µ—Ä–Ω–æ–ø—ñ–ª—å—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–ó–∞–∫–∞—Ä–ø–∞—Ç—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–ß–µ—Ä–Ω—ñ–≤–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å']\n",    "NORTHERN_REGIONS = ['–í–æ–ª–∏–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–†—ñ–≤–Ω–µ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–°—É–º—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–ß–µ—Ä–Ω—ñ–≥—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–ñ–∏—Ç–æ–º–∏—Ä—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å']\n",    "SOUTHERN_REGIONS = ['–û–¥–µ—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞ –æ–±–ª–∞—Å—Ç—å']\n",    "CENTRAL_REGIONS = ['–ö–∏—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–ß–µ—Ä–∫–∞—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–ü–æ–ª—Ç–∞–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–ö—ñ—Ä–æ–≤–æ–≥—Ä–∞–¥—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–í—ñ–Ω–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å', '–•–º–µ–ª—å–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å']\n",    "\n",    "def detect_encoding(file_path):\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'utf-8'\n",    "    print(f\"   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: {encoding}\")\n",    "    \n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','\n",    "\n",    "    return pd.read_csv(\n",    "        path,\n",    "        encoding=encoding,\n",    "        sep=sep,\n",    "        on_bad_lines='skip',\n",    "        low_memory=False\n",    "    )\n",    "\n",    "# def detect_dataset_type(df, config, threshold=0.8):\n",    "#     df_columns_lower = [col.lower() for col in df.columns]\n",    "#     \n",    "#     for dataset_type, mapping in config.items():\n",    "#         mapping_cols_lower = [col.lower() for col in mapping.keys()]\n",    "#         matching_cols = [col for col in mapping_cols_lower if col in df_columns_lower]\n",    "#         if len(matching_cols) / len(mapping_cols_lower) >= threshold:\n",    "#             return dataset_type\n",    "#     return None\n",    "\n",    "def detect_dataset_type_by_filename(filename):\n",    "    import re\n",    "    # –í–∏–¥—ñ–ª—è—î–º–æ —Ä—ñ–∫ –∑ –Ω–∞–∑–≤–∏ —Ñ–∞–π–ª—É, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥ –∑ \"2020.csv\"\n",    "    match = re.search(r'(\\d{4})', filename)\n",    "    if match:\n",    "        year = int(match.group(1))\n",    "        if year < 2022:\n",    "            return 'ZNO'\n",    "        else:\n",    "            return 'NMT'\n",    "    return None\n",    "\n",    "def add_flags_and_features(df, dataset_type):\n",    "    import re\n",    "    score_cols = [col for col in df.columns if 'score_100' in col]\n",    "    for col in score_cols:\n",    "        # Replace commas with dots and convert to numeric\n",    "        df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",    "\n",    "    # Diagnostic: Print stats for score_cols\n",    "    print(f\"   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è {len(score_cols)} score_100 —Å—Ç–æ–≤–ø—Ü—ñ–≤:\")\n",    "    for col in score_cols:\n",    "        non_null_count = df[col].notna().sum()\n",    "        positive_count = (df[col] > 0).sum() if non_null_count > 0 else 0\n",    "        print(f\"     {col}: {non_null_count} –Ω–µ-NaN, {positive_count} > 0\")\n",    "    \n",    "    \n",    "    # Convert test_date to datetime (only for NMT)\n",    "    if dataset_type == 'NMT' and 'test_date' in df.columns:\n",    "        df['test_date'] = pd.to_datetime(df['test_date'], errors='coerce')\n",    "    \n",    "        # Calculate student age\n",    "    if 'birth_year' in df.columns:\n",    "        df['birth_year'] = pd.to_numeric(df['birth_year'], errors='coerce')\n",    "        if dataset_type == 'ZNO':\n",    "            # Extract year from filename (e.g., 2020 from 2020.csv)\n",    "            match = re.search(r'(\\d{4})', filename)\n",    "            if match:\n",    "                test_year = int(match.group(1))\n",    "                df['student_age'] = test_year - df['birth_year']\n",    "        elif dataset_type == 'NMT':\n",    "            # Use year from test_date\n",    "            df['student_age'] = df['test_date'].dt.year - df['birth_year']\n",    "        # Ensure student_age is Int64 and handle negative or invalid ages\n",    "        df['student_age'] = df['student_age'].clip(lower=0).astype('Int64')\n",    "    else:\n",    "        print(f\"   –ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è: —Å—Ç–æ–≤–ø–µ—Ü—å 'birth_year' –≤—ñ–¥—Å—É—Ç–Ω—ñ–π, 'student_age' –Ω–µ —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–æ\")\n",    "        \n",    "    def classify_region(region):\n",    "        if pd.isna(region):\n",    "            return 'other'\n",    "        region = region.strip()\n",    "        if region in EASTERN_REGIONS:\n",    "            return 'east'\n",    "        elif region in WESTERN_REGIONS:\n",    "            return 'west'\n",    "        elif region in NORTHERN_REGIONS:\n",    "            return 'north'\n",    "        elif region in SOUTHERN_REGIONS:\n",    "            return 'south'\n",    "        elif region in CENTRAL_REGIONS:\n",    "            return 'central'\n",    "        else:\n",    "            return 'other'\n",    "\n",    "    df['region_flag'] = df['region_name'].apply(classify_region)\n",    "\n",    "    subject_cols = {\n",    "        'NMT': {\n",    "            'ukrainian': 'ukrainian_score_100',\n",    "            'math': 'math_score_100',\n",    "            'history': 'history_score_100',\n",    "            'physics': 'physics_score_100',\n",    "            'chemistry': 'chemistry_score_100',\n",    "            'biology': 'biology_score_100',\n",    "            'geography': 'geography_score_100',\n",    "            'english': 'english_score_100',\n",    "            'french': 'french_score_100',\n",    "            'german': 'german_score_100',\n",    "            'spanish': 'spanish_score_100',\n",    "            'ukrainian_literature': 'ukrainian_lit_score_100'\n",    "        },\n",    "        'ZNO': {\n",    "            'ukrainian': 'ukrainian_score_100',\n",    "            'math': 'math_score_100',\n",    "            'history': 'history_score_100',\n",    "            'physics': 'physics_score_100',\n",    "            'chemistry': 'chemistry_score_100',\n",    "            'biology': 'biology_score_100',\n",    "            'geography': 'geography_score_100',\n",    "            'english': 'english_score_100',\n",    "            'french': 'french_score_100',\n",    "            'german': 'german_score_100',\n",    "            'spanish': 'spanish_score_100'\n",    "        }\n",    "    }\n",    "\n",    "    subjects_taken = pd.Series(0, index=df.index, dtype='Int64')\n",    "    for subject, col in subject_cols[dataset_type].items():\n",    "        if col in df.columns:\n",    "            subjects_taken += (df[col].notna() & (df[col] >= 0)).astype('Int64')\n",    "    df['subjects_count'] = subjects_taken\n",    "\n",    "    score_cols = [col for col in df.columns if 'score_100' in col]\n",    "    df['total_score'] = df[score_cols].sum(axis=1, skipna=True)\n",    "    df['average_score'] = df[score_cols].mean(axis=1, skipna=True)\n",    "     # Diagnostic: Check total and average scores\n",    "    print(f\"   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: total_score –Ω–µ–Ω—É–ª—å–æ–≤–µ: {(df['total_score'] > 0).sum()}, \"f\"average_score non-NaN: {df['average_score'].notna().sum()}\")\n",    "    # if 'education_org_type' in df.columns:\n",    "    #     df['education_org_type'] = df['education_org_type'].str.strip().str.lower()\n",    "    #     df['education_org_type'] = df['education_org_type'].replace({\n",    "    #         '–ª—ñ—Ü–µ–π': '–ª—ñ—Ü–µ–π',\n",    "    #         '—à–∫–æ–ª–∞': '—à–∫–æ–ª–∞',\n",    "    #         '—É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç': '—É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç',\n",    "    #         '–∫–æ–ª–µ–¥–∂': '–∫–æ–ª–µ–¥–∂'\n",    "    #     })\n",    "\n",    "    return df\n",    "\n",    "# Process all CSV files in transformed_data\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "            \n",    "            dataset_type = detect_dataset_type_by_filename(filename)\n",    "            if dataset_type is None:\n",    "                print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {filename}: –Ω–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–∑–Ω–∞—á–∏—Ç–∏ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É\")\n",    "                print(f\"   –î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns[:10])}...\")\n",    "                continue\n",    "\n",    "            print(f\"   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: {dataset_type}\")\n",    "                                    \n",    "            # –î–æ–¥–∞—î–º–æ –≤—Å—ñ –Ω–æ–≤—ñ —Ñ–ª–∞–∂–∫–∏ —Ç–∞ –æ–∑–Ω–∞–∫–∏\n",    "            df = add_flags_and_features(df, dataset_type)\n",    "\n",    "            # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—É—î–º–æ —Ç–æ–π —Å–∞–º–∏–π —Ñ–∞–π–ª\n",    "            df.to_csv(input_path, index=False, encoding='utf-8')\n",    "            print(f\"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ {input_path}\")\n",    "            print(f\"   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns[-10:])}...\") \n",    "\n",    "        except Exception as e:\n",    "            print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\nüéâ –û–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –í—Å—ñ –∑–º—ñ–Ω–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É –ø–∞–ø—Ü—ñ '{input_folder}'\")"   ],   "id": "21271297a1656521",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîÑ –û–±—Ä–æ–±–∫–∞ 2020.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: utf-8\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 379299 —Ä—è–¥–∫—ñ–≤, 127 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: ZNO\n",      "   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è 11 score_100 —Å—Ç–æ–≤–ø—Ü—ñ–≤:\n",      "     ukrainian_score_100: 274454 –Ω–µ-NaN, 251929 > 0\n",      "     history_score_100: 178642 –Ω–µ-NaN, 154814 > 0\n",      "     math_score_100: 152047 –Ω–µ-NaN, 132734 > 0\n",      "     physics_score_100: 22217 –Ω–µ-NaN, 20517 > 0\n",      "     chemistry_score_100: 11100 –Ω–µ-NaN, 9974 > 0\n",      "     biology_score_100: 74382 –Ω–µ-NaN, 70301 > 0\n",      "     geography_score_100: 92901 –Ω–µ-NaN, 87756 > 0\n",      "     english_score_100: 104965 –Ω–µ-NaN, 97303 > 0\n",      "     french_score_100: 397 –Ω–µ-NaN, 366 > 0\n",      "     german_score_100: 1766 –Ω–µ-NaN, 1565 > 0\n",      "     spanish_score_100: 114 –Ω–µ-NaN, 102 > 0\n",      "   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: total_score –Ω–µ–Ω—É–ª—å–æ–≤–µ: 276773, average_score non-NaN: 284592\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2020.csv\n",      "   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: ['spanish_score', 'spanish_pt_name', 'spanish_pt_region', 'spanish_pt_area', 'spanish_pt_territory', 'student_age', 'region_flag', 'subjects_count', 'total_score', 'average_score']...\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2021.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: utf-8\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 389323 —Ä—è–¥–∫—ñ–≤, 148 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: ZNO\n",      "   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è 11 score_100 —Å—Ç–æ–≤–ø—Ü—ñ–≤:\n",      "     ukrainian_score_100: 288837 –Ω–µ-NaN, 267635 > 0\n",      "     history_score_100: 199373 –Ω–µ-NaN, 163532 > 0\n",      "     math_score_100: 244202 –Ω–µ-NaN, 168369 > 0\n",      "     physics_score_100: 23202 –Ω–µ-NaN, 21275 > 0\n",      "     chemistry_score_100: 9809 –Ω–µ-NaN, 8760 > 0\n",      "     biology_score_100: 81412 –Ω–µ-NaN, 79514 > 0\n",      "     geography_score_100: 113116 –Ω–µ-NaN, 107045 > 0\n",      "     english_score_100: 127714 –Ω–µ-NaN, 114139 > 0\n",      "     french_score_100: 414 –Ω–µ-NaN, 377 > 0\n",      "     german_score_100: 1825 –Ω–µ-NaN, 1617 > 0\n",      "     spanish_score_100: 150 –Ω–µ-NaN, 127 > 0\n",      "   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: total_score –Ω–µ–Ω—É–ª—å–æ–≤–µ: 294715, average_score non-NaN: 303565\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2021.csv\n",      "   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: ['spanish_score', 'spanish_pt_name', 'spanish_pt_region', 'spanish_pt_area', 'spanish_pt_territory', 'student_age', 'region_flag', 'subjects_count', 'total_score', 'average_score']...\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2023.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: utf-8\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 288935 —Ä—è–¥–∫—ñ–≤, 59 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: NMT\n",      "   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è 10 score_100 —Å—Ç–æ–≤–ø—Ü—ñ–≤:\n",      "     ukrainian_score_100: 268128 –Ω–µ-NaN, 267871 > 0\n",      "     history_score_100: 141068 –Ω–µ-NaN, 140844 > 0\n",      "     math_score_100: 268128 –Ω–µ-NaN, 256741 > 0\n",      "     physics_score_100: 5254 –Ω–µ-NaN, 5036 > 0\n",      "     chemistry_score_100: 3218 –Ω–µ-NaN, 3206 > 0\n",      "     biology_score_100: 36009 –Ω–µ-NaN, 35944 > 0\n",      "     english_score_100: 80247 –Ω–µ-NaN, 79814 > 0\n",      "     french_score_100: 273 –Ω–µ-NaN, 272 > 0\n",      "     german_score_100: 1913 –Ω–µ-NaN, 1889 > 0\n",      "     spanish_score_100: 146 –Ω–µ-NaN, 146 > 0\n",      "   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: total_score –Ω–µ–Ω—É–ª—å–æ–≤–µ: 268115, average_score non-NaN: 268128\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_60985/169123008.py:86: UserWarning: Parsing dates in %d.%m.%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",      "  df['test_date'] = pd.to_datetime(df['test_date'], errors='coerce')\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2023.csv\n",      "   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: ['spanish_score_100', 'spanish_score', 'pt_region_name', 'pt_area_name', 'pt_territory_name', 'student_age', 'region_flag', 'subjects_count', 'total_score', 'average_score']...\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2019.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: utf-8\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 353813 —Ä—è–¥–∫—ñ–≤, 127 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: ZNO\n",      "   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è 11 score_100 —Å—Ç–æ–≤–ø—Ü—ñ–≤:\n",      "     ukrainian_score_100: 338858 –Ω–µ-NaN, 286413 > 0\n",      "     history_score_100: 222449 –Ω–µ-NaN, 186447 > 0\n",      "     math_score_100: 155202 –Ω–µ-NaN, 127093 > 0\n",      "     physics_score_100: 21403 –Ω–µ-NaN, 18202 > 0\n",      "     chemistry_score_100: 13698 –Ω–µ-NaN, 11828 > 0\n",      "     biology_score_100: 76006 –Ω–µ-NaN, 69258 > 0\n",      "     geography_score_100: 75028 –Ω–µ-NaN, 67213 > 0\n",      "     english_score_100: 90906 –Ω–µ-NaN, 79393 > 0\n",      "     french_score_100: 553 –Ω–µ-NaN, 485 > 0\n",      "     german_score_100: 1951 –Ω–µ-NaN, 1550 > 0\n",      "     spanish_score_100: 114 –Ω–µ-NaN, 95 > 0\n",      "   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: total_score –Ω–µ–Ω—É–ª—å–æ–≤–µ: 318086, average_score non-NaN: 344861\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2019.csv\n",      "   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: ['spanish_score', 'spanish_pt_name', 'spanish_pt_region', 'spanish_pt_area', 'spanish_pt_territory', 'student_age', 'region_flag', 'subjects_count', 'total_score', 'average_score']...\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2024.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: utf-8\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 312508 —Ä—è–¥–∫—ñ–≤, 73 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–∑–Ω–∞—á–µ–Ω–æ —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É: NMT\n",      "   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è 12 score_100 —Å—Ç–æ–≤–ø—Ü—ñ–≤:\n",      "     ukrainian_score_100: 283370 –Ω–µ-NaN, 282152 > 0\n",      "     history_score_100: 283191 –Ω–µ-NaN, 282866 > 0\n",      "     math_score_100: 283370 –Ω–µ-NaN, 247156 > 0\n",      "     physics_score_100: 7753 –Ω–µ-NaN, 6962 > 0\n",      "     chemistry_score_100: 3270 –Ω–µ-NaN, 3009 > 0\n",      "     biology_score_100: 53965 –Ω–µ-NaN, 53769 > 0\n",      "     geography_score_100: 59917 –Ω–µ-NaN, 59816 > 0\n",      "     english_score_100: 112592 –Ω–µ-NaN, 110352 > 0\n",      "     french_score_100: 275 –Ω–µ-NaN, 270 > 0\n",      "     german_score_100: 2881 –Ω–µ-NaN, 2832 > 0\n",      "     spanish_score_100: 143 –Ω–µ-NaN, 136 > 0\n",      "     ukrainian_lit_score_100: 42395 –Ω–µ-NaN, 41245 > 0\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_60985/169123008.py:86: UserWarning: Parsing dates in %d.%m.%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",      "  df['test_date'] = pd.to_datetime(df['test_date'], errors='coerce')\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "   –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: total_score –Ω–µ–Ω—É–ª—å–æ–≤–µ: 283358, average_score non-NaN: 283370\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2024.csv\n",      "   –ù–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: ['ukrainian_lit_score_100', 'ukrainian_lit_score', 'pt_region_name', 'pt_area_name', 'pt_territory_name', 'student_age', 'region_flag', 'subjects_count', 'total_score', 'average_score']...\n",      "\n",      "üéâ –û–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –í—Å—ñ –∑–º—ñ–Ω–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É –ø–∞–ø—Ü—ñ 'transformed_data'\n"     ]    }   ],   "execution_count": 45  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-06-06T13:53:06.646260Z",     "start_time": "2025-06-06T13:52:07.599965Z"    }   },   "cell_type": "code",   "source": [    "### DROPPING COLUMNS ###\n",    "import pandas as pd\n",    "import os\n",    "import csv\n",    "import chardet\n",    "\n",    "input_folder = \"transformed_data\"\n",    "os.makedirs(input_folder, exist_ok=True)\n",    "\n",    "columns_to_drop = [\n",    "    'total_score', 'average_score', 'subjects_count', 'region_flag',\n",    "]\n",    "\n",    "def detect_encoding(file_path):\n",    "    with open(file_path, 'rb') as f:\n",    "        sample = f.read(10000)\n",    "        result = chardet.detect(sample)\n",    "        return result['encoding']\n",    "\n",    "def load_csv_with_auto_sep(path):\n",    "    encoding = detect_encoding(path)\n",    "    if encoding is None:\n",    "        encoding = 'utf-8'\n",    "    print(f\"   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: {encoding}\")\n",    "    \n",    "    try:\n",    "        with open(path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            dialect = csv.Sniffer().sniff(sample)\n",    "            sep = dialect.delimiter\n",    "    except:\n",    "        sep = ','\n",    "\n",    "    return pd.read_csv(\n",    "        path,\n",    "        encoding=encoding,\n",    "        sep=sep,\n",    "        on_bad_lines='skip',\n",    "        low_memory=False\n",    "    )\n",    "\n",    "for filename in os.listdir(input_folder):\n",    "    if filename.endswith(\".csv\"):\n",    "        input_path = os.path.join(input_folder, filename)\n",    "        print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename}...\")\n",    "\n",    "        try:\n",    "            df = load_csv_with_auto_sep(input_path)\n",    "            print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "\n",    "            existing_columns = [col for col in columns_to_drop if col in df.columns]\n",    "            if not existing_columns:\n",    "                print(f\"   –ñ–æ–¥–Ω–∞ –∑ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ.\")\n",    "                continue\n",    "\n",    "            df = df.drop(columns=existing_columns, errors='ignore')\n",    "            print(f\"   –í–∏–¥–∞–ª–µ–Ω–æ {len(existing_columns)} –∫–æ–ª–æ–Ω–æ–∫: {existing_columns}\")\n",    "            print(f\"   –ó–∞–ª–∏—à–∏–ª–æ—Å—è {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "\n",    "            df.to_csv(input_path, index=False, encoding='utf-8')\n",    "            print(f\"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ {input_path}\")\n",    "\n",    "        except Exception as e:\n",    "            print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "print(f\"\\nüéâ –û–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–Ω–æ–≤–ª–µ–Ω—ñ —Ñ–∞–π–ª–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É –ø–∞–ø—Ü—ñ '{input_folder}'\")"   ],   "id": "1aa1a50b904282e",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîÑ –û–±—Ä–æ–±–∫–∞ 2020.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: utf-8\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 379299 —Ä—è–¥–∫—ñ–≤, 131 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–¥–∞–ª–µ–Ω–æ 4 –∫–æ–ª–æ–Ω–æ–∫: ['total_score', 'average_score', 'subjects_count', 'region_flag']\n",      "   –ó–∞–ª–∏—à–∏–ª–æ—Å—è 127 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2020.csv\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2021.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: utf-8\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 389323 —Ä—è–¥–∫—ñ–≤, 152 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–¥–∞–ª–µ–Ω–æ 4 –∫–æ–ª–æ–Ω–æ–∫: ['total_score', 'average_score', 'subjects_count', 'region_flag']\n",      "   –ó–∞–ª–∏—à–∏–ª–æ—Å—è 148 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2021.csv\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2023.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: utf-8\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 288935 —Ä—è–¥–∫—ñ–≤, 59 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –ñ–æ–¥–Ω–∞ –∑ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ.\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2019.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: utf-8\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 353813 —Ä—è–¥–∫—ñ–≤, 131 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –í–∏–¥–∞–ª–µ–Ω–æ 4 –∫–æ–ª–æ–Ω–æ–∫: ['total_score', 'average_score', 'subjects_count', 'region_flag']\n",      "   –ó–∞–ª–∏—à–∏–ª–æ—Å—è 127 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π —Ñ–∞–π–ª –¥–æ transformed_data/2019.csv\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2024.csv...\n",      "   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: utf-8\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 312508 —Ä—è–¥–∫—ñ–≤, 73 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –ñ–æ–¥–Ω–∞ –∑ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ.\n",      "\n",      "üéâ –û–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–Ω–æ–≤–ª–µ–Ω—ñ —Ñ–∞–π–ª–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É –ø–∞–ø—Ü—ñ 'transformed_data'\n"     ]    }   ],   "execution_count": 44  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}