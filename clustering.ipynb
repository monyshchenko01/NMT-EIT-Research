{ "cells": [  {   "cell_type": "code",   "execution_count": null,   "id": "initial_id",   "metadata": {    "collapsed": true   },   "outputs": [],   "source": [    "import os\n",    "import pandas as pd\n",    "import numpy as np\n",    "from scipy.stats import kruskal\n",    "from scipy.stats import rankdata\n",    "import matplotlib.pyplot as plt\n",    "import seaborn as sns\n",    "import chardet\n",    "import csv\n",    "import re\n",    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",    "from sklearn.decomposition import PCA\n",    "from sklearn.preprocessing import StandardScaler\n",    "\n",    "INPUT_FOLDER = \"filtered_data\"\n",    "RESULTS_FOLDER = \"results\"\n",    "GRAPHS_FOLDER = os.path.join(RESULTS_FOLDER, \"graphs\")\n",    "for folder in [RESULTS_FOLDER, GRAPHS_FOLDER]:\n",    "    os.makedirs(folder, exist_ok=True)\n",    "\n",    "sns.set_style(\"whitegrid\")\n",    "\n",    "def detect_encoding(file_path):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î –∫–æ–¥—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—É.\"\"\"\n",    "    try:\n",    "        with open(file_path, 'rb') as f:\n",    "            return chardet.detect(f.read(10000))['encoding'] or 'utf-8'\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–æ–¥—É–≤–∞–Ω–Ω—è –¥–ª—è {file_path}: {e}\")\n",    "        return 'utf-8'\n",    "\n",    "def detect_separator(file_path, encoding):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫ —É CSV-—Ñ–∞–π–ª—ñ.\"\"\"\n",    "    try:\n",    "        with open(file_path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            return csv.Sniffer().sniff(sample).delimiter\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫–∞ –¥–ª—è {file_path}: {e}\")\n",    "        return ','\n",    "\n",    "def load_csv(file_path):\n",    "    \"\"\"–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î CSV-—Ñ–∞–π–ª.\"\"\"\n",    "    encoding = detect_encoding(file_path)\n",    "    sep = detect_separator(file_path, encoding)\n",    "    print(f\"   –ö–æ–¥—É–≤–∞–Ω–Ω—è: {encoding}, —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫: '{sep}'\")\n",    "    \n",    "    try:\n",    "        df = pd.read_csv(file_path, encoding=encoding, sep=sep, quotechar='\"', on_bad_lines='skip', low_memory=False)\n",    "        print(f\"   –ü–µ—Ä—à—ñ 5 –∫–æ–ª–æ–Ω–æ–∫: {list(df.columns[:5])}\")\n",    "        return df\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è {file_path}: {e}\")\n",    "        return None\n",    "\n",    "def detect_dataset_type(filename):\n",    "    match = re.search(r'(\\d{4})', filename)\n",    "    if match:\n",    "        year = int(match.group(1))\n",    "        return 'NMT' if year >= 2022 else 'ZNO'\n",    "    return None\n",    "\n",    "def compute_mean_scores(df, filename):\n",    "    year = int(filename.split('.')[0])\n",    "    df_scores = df[df['average_score'].notna() & df['education_org_type'].notna()].copy()\n",    "    mean_scores = df_scores.groupby('education_org_type')['average_score'].mean().reset_index()\n",    "    mean_scores_dict = {t: mean_scores[mean_scores['education_org_type'] == t]['average_score'].mean() \n",    "                       if t in mean_scores['education_org_type'].values else np.nan \n",    "                       for t in mean_scores['education_org_type'].unique()}\n",    "    mean_scores_pivot = pd.DataFrame([mean_scores_dict])\n",    "    mean_scores_pivot['year'] = year\n",    "    table_path = os.path.join(\"results\", \"mean_scores_all_years.csv\")\n",    "    if os.path.exists(table_path):\n",    "        existing_df = pd.read_csv(table_path)\n",    "        existing_df = existing_df[existing_df[\"year\"] != year]\n",    "        updated_df = pd.concat([existing_df, mean_scores_pivot], ignore_index=True)\n",    "    else:\n",    "        updated_df = mean_scores_pivot\n",    "    updated_df.to_csv(table_path, index=False)\n",    "    print(f\"‚úÖ –¢–∞–±–ª–∏—Ü—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö –±–∞–ª—ñ–≤ –æ–Ω–æ–≤–ª–µ–Ω–æ: {table_path}\")\n",    "\n",    "def cluster_education_types(table_path):\n",    "    if os.path.exists(table_path):\n",    "        cluster_data = pd.read_csv(table_path)\n",    "        if len(cluster_data) >= 2 and cluster_data.drop('year', axis=1).notna().any().any():\n",    "            types = [col for col in cluster_data.columns if col != 'year']\n",    "            cluster_data_selected = cluster_data[['year'] + types]\n",    "\n",    "            cluster_data_transposed = cluster_data_selected.set_index('year').transpose()\n",    "            X = cluster_data_transposed.values\n",    "            \n",    "            column_means = np.nanmean(X, axis=0)\n",    "            X = np.where(np.isnan(X), np.tile(column_means, (X.shape[0], 1)), X)\n",    "            scaler = StandardScaler()\n",    "            X_scaled = scaler.fit_transform(X)\n",    "\n",    "            pca = PCA(n_components=2)\n",    "            X_pca = pca.fit_transform(X_scaled)\n",    "\n",    "            kmeans = KMeans(n_clusters=4, random_state=42)\n",    "            kmeans_clusters = kmeans.fit_predict(X_scaled)\n",    "\n",    "            agg_clustering = AgglomerativeClustering(n_clusters=4)\n",    "            agg_clusters = agg_clustering.fit_predict(X_scaled)\n",    "\n",    "            plt.figure(figsize=(10, 6))\n",    "            scatter_kmeans = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_clusters, cmap='viridis', s=100)\n",    "            plt.title(\"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è —Ç–∏–ø—ñ–≤ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –∑–∞–∫–ª–∞–¥—ñ–≤ (KMeans, 4 –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤)\")\n",    "            plt.xlabel(\"–ü–µ—Ä—à–∞ –≥–æ–ª–æ–≤–Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞\")\n",    "            plt.ylabel(\"–î—Ä—É–≥–∞ –≥–æ–ª–æ–≤–Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞\")\n",    "            types = cluster_data_transposed.index\n",    "            for i, txt in enumerate(types):\n",    "                plt.annotate(txt, (X_pca[i, 0], X_pca[i, 1]), xytext=(5, 5), textcoords='offset points')\n",    "            plt.colorbar(scatter_kmeans, label='–ö–ª–∞—Å—Ç–µ—Ä')\n",    "            kmeans_path = os.path.join(\"results/graphs\", \"cluster_education_kmeans.png\")\n",    "            plt.savefig(kmeans_path, dpi=300, bbox_inches=\"tight\")\n",    "            plt.close()\n",    "            print(f\"‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó (KMeans) –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {kmeans_path}\")\n",    "\n",    "            plt.figure(figsize=(10, 6))\n",    "            scatter_agg = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=agg_clusters, cmap='plasma', s=100)\n",    "            plt.title(\"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è —Ç–∏–ø—ñ–≤ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –∑–∞–∫–ª–∞–¥—ñ–≤ (Agglomerative, 4 –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤)\")\n",    "            plt.xlabel(\"–ü–µ—Ä—à–∞ –≥–æ–ª–æ–≤–Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞\")\n",    "            plt.ylabel(\"–î—Ä—É–≥–∞ –≥–æ–ª–æ–≤–Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞\")\n",    "            for i, txt in enumerate(types):\n",    "                plt.annotate(txt, (X_pca[i, 0], X_pca[i, 1]), xytext=(5, 5), textcoords='offset points')\n",    "            plt.colorbar(scatter_agg, label='–ö–ª–∞—Å—Ç–µ—Ä')\n",    "            agg_path = os.path.join(\"results/graphs\", \"cluster_education_agg.png\")\n",    "            plt.savefig(agg_path, dpi=300, bbox_inches=\"tight\")\n",    "            plt.close()\n",    "            print(f\"‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó (Agglomerative) –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {agg_path}\")\n",    "        else:\n",    "            print(\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó\")\n",    "                                                            \n",    "for filename in os.listdir(INPUT_FOLDER):\n",    "    if not filename.endswith(\".csv\"):\n",    "        continue\n",    "    \n",    "    file_path = os.path.join(INPUT_FOLDER, filename)\n",    "    print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename}...\")\n",    "    \n",    "    try:\n",    "        df = load_csv(file_path)\n",    "        if df is None or df.empty:\n",    "            print(f\"‚ö†Ô∏è –§–∞–π–ª {filename} –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏\")\n",    "            continue\n",    "        \n",    "        dataset_type = detect_dataset_type(filename)\n",    "        if not dataset_type:\n",    "            print(f\"‚ö†Ô∏è –ù–µ–≤—ñ–¥–æ–º–∏–π —Ç–∏–ø –¥–∞–Ω–∏—Ö: {filename}\")\n",    "            continue\n",    "        \n",    "        print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "        compute_mean_scores(df, filename)\n",    "    \n",    "    except Exception as e:\n",    "        print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "        import traceback\n",    "        traceback.print_exc()\n",    "\n",    "table_path = os.path.join(\"results\", \"mean_scores_all_years.csv\")\n",    "cluster_education_types(table_path)\n",    "\n",    "print(f\"\\nüéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{RESULTS_FOLDER}'\")"   ]  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}