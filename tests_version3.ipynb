{ "cells": [  {   "cell_type": "code",   "id": "initial_id",   "metadata": {    "collapsed": true   },   "source": [    "def analyze_gender_math(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î —Ä—ñ–∑–Ω–∏—Ü—é –≤ –æ—Ü—ñ–Ω–∫–∞—Ö –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∑–∞ —Å—Ç–∞—Ç—Ç—é.\"\"\"\n",    "    required_cols = ['math_score_100', 'gender']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_math = df[df['math_score_100'].notna() & df['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])]\n",    "    male_scores = df_math[df_math['gender'] == '—á–æ–ª–æ–≤—ñ—á–∞']['math_score_100']\n",    "    female_scores = df_math[df_math['gender'] == '–∂—ñ–Ω–æ—á–∞']['math_score_100']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(male_scores) >= 30 and len(female_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(male_scores, female_scores, equal_var=False, nan_policy='omit')\n",    "        result.update({\n",    "            'male_count': len(male_scores), 'female_count': len(female_scores),\n",    "            'male_avg': male_scores.mean(), 'female_avg': female_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: —á–æ–ª–æ–≤—ñ–∫—ñ–≤={len(male_scores)}, –∂—ñ–Ω–æ–∫={len(female_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return male_scores, female_scores"   ],   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_abroad_results(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ü–æ—Ä—ñ–≤–Ω—é—î –æ—Ü—ñ–Ω–∫–∏ –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∑–∞ –∫–æ—Ä–¥–æ–Ω–æ–º —ñ –≤ –£–∫—Ä–∞—ó–Ω—ñ (–ª–∏—à–µ –¥–ª—è –ù–ú–¢).\"\"\"\n",    "    if dataset_type != 'NMT':\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    required_cols = ['math_score_100', 'pt_region_name']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_scores = df[df['math_score_100'].notna() & df['pt_region_name'].notna()]\n",    "    df_scores['location'] = df_scores['pt_region_name'].apply(\n",    "        lambda x: '–ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º' if isinstance(x, str) and any(c in x.lower() for c in ['–ø–æ–ª—å—â–∞', '–ª–∞—Ç–≤—ñ—è']) else '–£–∫—Ä–∞—ó–Ω–∞'\n",    "    )\n",    "    \n",    "    abroad_scores = df_scores[df_scores['location'] == '–ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º']['math_score_100']\n",    "    ukraine_scores = df_scores[df_scores['location'] == '–£–∫—Ä–∞—ó–Ω–∞']['math_score_100']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(abroad_scores) >= 30 and len(ukraine_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(abroad_scores, ukraine_scores, equal_var=False, nan_policy='omit')\n",    "        result.update({\n",    "            'abroad_count': len(abroad_scores), 'ukraine_count': len(ukraine_scores),\n",    "            'abroad_avg': abroad_scores.mean(), 'ukraine_avg': ukraine_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: –∑–∞ –∫–æ—Ä–¥–æ–Ω–æ–º={len(abroad_scores)}, –£–∫—Ä–∞—ó–Ω–∞={len(ukraine_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return abroad_scores, ukraine_scores"   ],   "id": "6d63d1bd06b88360",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_subject_correlation(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î –∫–æ—Ä–µ–ª—è—Ü—ñ—é –º—ñ–∂ —É—Å—ñ–º–∞ –ø—Ä–µ–¥–º–µ—Ç–∞–º–∏.\"\"\"\n",    "    subjects = [\n",    "        'ukrainian_score_100', 'math_score_100',\n",    "        'biology_score_100', 'chemistry_score_100', 'physics_score_100',\n",    "        'english_score_100', 'geography_score_100', 'ukrainian_literature_score_100',\n",    "        'history_score_100', 'french_score_100', 'german_score_100', 'spanish_score_100'\n",    "    ]\n",    "    available_subjects = [s for s in subjects if s in df.columns]\n",    "    if len(available_subjects) < 2:\n",    "        print(f\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ –¥–ª—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —É {filename}: {available_subjects}\")\n",    "        return pd.DataFrame()\n",    "    \n",    "    df_subjects = df[available_subjects].dropna()\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(df_subjects) >= 30:\n",    "        corr_matrix = df_subjects.corr(method='pearson').round(2)\n",    "        for i, s1 in enumerate(available_subjects):\n",    "            for s2 in available_subjects[i+1:]:\n",    "                result[f'{s1.replace(\"_score_100\", \"\")}_{s2.replace(\"_score_100\", \"\")}_corr'] = \\\n",    "                    corr_matrix.loc[s1, s2]\n",    "        result['corr_matrix'] = corr_matrix  # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥–ª—è –≥—Ä–∞—Ñ—ñ–∫–∞\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: {len(df_subjects)} –∑–∞–ø–∏—Å—ñ–≤'\n",    "    \n",    "    all_results.append(result)\n",    "    return df_subjects"   ],   "id": "e74124edcc9ef533",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_additional_subjects(df, dataset_type, filename, all_results):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î —á–∞—Å—Ç–æ—Ç—É –≤–∏–±–æ—Ä—É –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –ø—Ä–µ–¥–º–µ—Ç—ñ–≤.\"\"\"\n",    "    subjects = [\n",    "        'biology_score_100', 'chemistry_score_100', 'physics_score_100',\n",    "        'english_score_100', 'geography_score_100', 'ukrainian_literature_score_100',\n",    "        'history_score_100', 'french_score_100', 'german_score_100', 'spanish_score_100',\n",    "    ]\n",    "    counts = {}\n",    "    for subject in subjects:\n",    "        if subject in df.columns:\n",    "            counts[subject.replace('_score_100', '')] = df[subject].notna().sum()\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type, **counts}\n",    "    all_results.append(result)\n",    "    return counts"   ],   "id": "ac139e29b8764ce0",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_age_groups(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ü–æ—Ä—ñ–≤–Ω—é—î –æ—Ü—ñ–Ω–∫–∏ –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∑–∞ –≤—ñ–∫–æ–º (17/18).\"\"\"\n",    "    required_cols = ['math_score_100', 'student_age']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_age = df[df['math_score_100'].notna() & df['student_age'].isin([17, 18])]\n",    "    age_17_scores = df_age[df_age['student_age'] == 17]['math_score_100']\n",    "    age_18_scores = df_age[df_age['student_age'] == 18]['math_score_100']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(age_17_scores) >= 30 and len(age_18_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(age_17_scores, age_18_scores, equal_var=False, nan_policy='omit')\n",    "        result.update({\n",    "            'age_17_count': len(age_17_scores), 'age_18_count': len(age_18_scores),\n",    "            'age_17_avg': age_17_scores.mean(), 'age_18_avg': age_18_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: 17={len(age_17_scores)}, 18={len(age_18_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return age_17_scores, age_18_scores"   ],   "id": "beeaac2b5d68e837",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "import os\n",    "import pandas as pd\n",    "import numpy as np\n",    "from scipy.stats import ttest_ind\n",    "import chardet\n",    "import re\n",    "import csv\n",    "import matplotlib.pyplot as plt\n",    "import seaborn as sns\n",    "from pathlib import Path\n",    "\n",    "# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–∞–ø–æ–∫\n",    "INPUT_FOLDER = \"filtered_data\"\n",    "RESULTS_FOLDER = \"results\"\n",    "GRAPHS_FOLDER = os.path.join(RESULTS_FOLDER, \"graphs\")\n",    "for folder in [RESULTS_FOLDER, GRAPHS_FOLDER]:\n",    "    os.makedirs(folder, exist_ok=True)\n",    "\n",    "# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–∏–ª—é –≥—Ä–∞—Ñ—ñ–∫—ñ–≤\n",    "sns.set_style(\"whitegrid\")\n",    "\n",    "def detect_encoding(file_path):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î –∫–æ–¥—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—É.\"\"\"\n",    "    try:\n",    "        with open(file_path, 'rb') as f:\n",    "            return chardet.detect(f.read(10000))['encoding'] or 'utf-8'\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–æ–¥—É–≤–∞–Ω–Ω—è –¥–ª—è {file_path}: {e}\")\n",    "        return 'utf-8'\n",    "\n",    "def detect_separator(file_path, encoding):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫ —É CSV-—Ñ–∞–π–ª—ñ.\"\"\"\n",    "    try:\n",    "        with open(file_path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            return csv.Sniffer().sniff(sample).delimiter\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫–∞ –¥–ª—è {file_path}: {e}\")\n",    "        return ','\n",    "\n",    "def load_csv(file_path):\n",    "    \"\"\"–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î CSV-—Ñ–∞–π–ª.\"\"\"\n",    "    encoding = detect_encoding(file_path)\n",    "    sep = detect_separator(file_path, encoding)\n",    "    print(f\"   –ö–æ–¥—É–≤–∞–Ω–Ω—è: {encoding}, —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫: '{sep}'\")\n",    "    \n",    "    try:\n",    "        df = pd.read_csv(file_path, encoding=encoding, sep=sep, quotechar='\"', on_bad_lines='skip')\n",    "        print(f\"   –ü–µ—Ä—à—ñ 5 –∫–æ–ª–æ–Ω–æ–∫: {list(df.columns[:5])}\")\n",    "        return df\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è {file_path}: {e}\")\n",    "        return None\n",    "\n",    "def detect_dataset_type(filename):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É –∑–∞ –Ω–∞–∑–≤–æ—é —Ñ–∞–π–ª—É.\"\"\"\n",    "    match = re.search(r'(\\d{4})', filename)\n",    "    if match:\n",    "        year = int(match.group(1))\n",    "        return 'NMT' if year >= 2022 else 'ZNO'\n",    "    return None\n",    "\n",    "# –ó–±—ñ—Ä –¥–∞–Ω–∏—Ö\n",    "zno_dfs = []\n",    "nmt_dfs = []\n",    "all_gender_results = []\n",    "all_abroad_results = []\n",    "all_correlation_results = []\n",    "all_subjects_results = []\n",    "all_age_results = []\n",    "\n",    "# –û—Å–Ω–æ–≤–Ω–∏–π —Ü–∏–∫–ª\n",    "for filename in os.listdir(INPUT_FOLDER):\n",    "    if not filename.endswith(\".csv\"):\n",    "        continue\n",    "    \n",    "    path = os.path.join(INPUT_FOLDER, filename)\n",    "    print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename}...\")\n",    "    \n",    "    try:\n",    "        df = load_csv(path)\n",    "        if df is None or df.empty:\n",    "            print(f\"‚ö†Ô∏è –§–∞–π–ª {filename} –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏\")\n",    "            continue\n",    "        \n",    "        dataset_type = detect_dataset_type(filename)\n",    "        if not dataset_type:\n",    "            print(f\"‚ö†Ô∏è –ù–µ–≤—ñ–¥–æ–º–∏–π —Ç–∏–ø –¥–∞–Ω–∏—Ö: {filename}\")\n",    "            continue\n",    "        \n",    "        print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "        \n",    "        # –ê–Ω–∞–ª—ñ–∑ –ø–∏—Ç–∞–Ω—å\n",    "        gender_male, gender_female = analyze_gender_math(df, dataset_type, filename, all_gender_results)\n",    "        abroad_abroad, abroad_ukraine = analyze_abroad_results(df, dataset_type, filename, all_abroad_results)\n",    "        subjects_df = analyze_subject_correlation(df, dataset_type, filename, all_correlation_results)\n",    "        subjects_counts = analyze_additional_subjects(df, dataset_type, filename, all_subjects_results)\n",    "        age_17, age_18 = analyze_age_groups(df, dataset_type, filename, all_age_results)\n",    "        \n",    "        # –ó–±—ñ—Ä –¥–∞–Ω–∏—Ö –¥–ª—è –æ–±'—î–¥–Ω–∞–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É\n",    "        if dataset_type == 'ZNO':\n",    "            zno_dfs.append((df, gender_male, gender_female, subjects_df, age_17, age_18))\n",    "        else:\n",    "            nmt_dfs.append((df, gender_male, gender_female, abroad_abroad, abroad_ukraine, subjects_df, subjects_counts, age_17, age_18))\n",    "    \n",    "    except Exception as e:\n",    "        print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "        import traceback\n",    "        traceback.print_exc()\n",    "\n",    "# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ —Ä–æ–∫–∞—Ö\n",    "pd.DataFrame(all_gender_results).to_csv(os.path.join(RESULTS_FOLDER, 'gender_math_analysis.csv'), index=False)\n",    "pd.DataFrame(all_abroad_results).to_csv(os.path.join(RESULTS_FOLDER, 'abroad_results_analysis.csv'), index=False)\n",    "pd.DataFrame(all_correlation_results).to_csv(os.path.join(RESULTS_FOLDER, 'subject_correlation_analysis.csv'), index=False)\n",    "pd.DataFrame(all_subjects_results).to_csv(os.path.join(RESULTS_FOLDER, 'additional_subjects_analysis.csv'), index=False)\n",    "pd.DataFrame(all_age_results).to_csv(os.path.join(RESULTS_FOLDER, 'age_groups_analysis.csv'), index=False)\n",    "\n",    "# –û–±'—î–¥–Ω–∞–Ω–∏–π –∞–Ω–∞–ª—ñ–∑\n",    "summary_gender = []\n",    "summary_abroad = []\n",    "summary_correlation = []\n",    "summary_subjects = []\n",    "summary_age = []\n",    "\n",    "for dataset_type, dfs_data in [\n",    "    ('ZNO', zno_dfs),\n",    "    ('NMT', nmt_dfs)\n",    "]:\n",    "    if dfs_data:\n",    "        print(f\"\\nüîÑ –û–±'—î–¥–Ω—É—î–º–æ –¥–∞–Ω—ñ –¥–ª—è {dataset_type}...\")\n",    "        try:\n",    "            dfs = [d[0] for d in dfs_data]\n",    "            combined_df = pd.concat(dfs, ignore_index=True)\n",    "            \n",    "            # –ü–∏—Ç–∞–Ω–Ω—è 1: –ì–µ–Ω–¥–µ—Ä\n",    "            male_scores = pd.concat([d[1] for d in dfs_data if not d[1].empty], ignore_index=True)\n",    "            female_scores = pd.concat([d[2] for d in dfs_data if not d[2].empty], ignore_index=True)\n",    "            if len(male_scores) >= 30 and len(female_scores) >= 30:\n",    "                t_stat, p_value = ttest_ind(male_scores, female_scores, equal_var=False)\n",    "                summary_gender.append({\n",    "                    'dataset_type': dataset_type,\n",    "                    'male_count': len(male_scores), 'female_count': len(female_scores),\n",    "                    'male_avg': male_scores.mean(), 'female_avg': female_scores.mean(),\n",    "                    't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05\n",    "                })\n",    "            \n",    "            # –ü–∏—Ç–∞–Ω–Ω—è 2: –ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º (–ª–∏—à–µ –ù–ú–¢)\n",    "            if dataset_type == 'NMT':\n",    "                abroad_scores = pd.concat([d[3] for d in dfs_data if not d[3].empty], ignore_index=True)\n",    "                ukraine_scores = pd.concat([d[4] for d in dfs_data if not d[4].empty], ignore_index=True)\n",    "                if len(abroad_scores) >= 30 and len(ukraine_scores) >= 30:\n",    "                    t_stat, p_value = ttest_ind(abroad_scores, ukraine_scores, equal_var=False)\n",    "                    summary_abroad.append({\n",    "                        'dataset_type': dataset_type,\n",    "                        'abroad_count': len(abroad_scores), 'ukraine_count': len(ukraine_scores),\n",    "                        'abroad_avg': abroad_scores.mean(), 'ukraine_avg': ukraine_scores.mean(),\n",    "                        't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05\n",    "                    })\n",    "            \n",    "            # –ü–∏—Ç–∞–Ω–Ω—è 3: –ö–æ—Ä–µ–ª—è—Ü—ñ—è\n",    "            subjects_dfs = [d[3 if dataset_type == 'ZNO' else 5] for d in dfs_data if not d[3 if dataset_type == 'ZNO' else 5].empty]\n",    "            if subjects_dfs:\n",    "                combined_subjects = pd.concat(subjects_dfs, ignore_index=True)\n",    "                if len(combined_subjects) >= 30:\n",    "                    corr_matrix = combined_subjects.corr(method='pearson').round(2)\n",    "                    result = {'dataset_type': dataset_type, 'corr_matrix': corr_matrix}\n",    "                    available_subjects = combined_subjects.columns\n",    "                    for i, s1 in enumerate(available_subjects):\n",    "                        for s2 in available_subjects[i+1:]:\n",    "                            result[f'{s1.replace(\"_score_100\", \"\")}_{s2.replace(\"_score_100\", \"\")}_corr'] = \\\n",    "                                corr_matrix.loc[s1, s2]\n",    "                    summary_correlation.append(result)\n",    "            \n",    "            # –ü–∏—Ç–∞–Ω–Ω—è 4: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø—Ä–µ–¥–º–µ—Ç–∏\n",    "            subjects_counts = [d[6 if dataset_type == 'NMT' else 3] for d in dfs_data]\n",    "            combined_counts = {}\n",    "            for counts in subjects_counts:\n",    "                for subject, count in counts.items():\n",    "                    if isinstance(count, (int, float)) and count > 0:\n",    "                        combined_counts[subject] = combined_counts.get(subject, 0) + count\n",    "            if combined_counts:\n",    "                summary_subjects.append({'dataset_type': dataset_type, **combined_counts})\n",    "            \n",    "            # –ü–∏—Ç–∞–Ω–Ω—è 5: –í—ñ–∫–æ–≤—ñ –≥—Ä—É–ø–∏\n",    "            age_17_scores = pd.concat([d[4 if dataset_type == 'ZNO' else 7] for d in dfs_data if not d[4 if dataset_type == 'ZNO' else 7].empty], ignore_index=True)\n",    "            age_18_scores = pd.concat([d[5 if dataset_type == 'ZNO' else 8] for d in dfs_data if not d[5 if dataset_type == 'ZNO' else 8].empty], ignore_index=True)\n",    "            if len(age_17_scores) >= 30 and len(age_18_scores) >= 30:\n",    "                t_stat, p_value = ttest_ind(age_17_scores, age_18_scores, equal_var=False)\n",    "                summary_age.append({\n",    "                    'dataset_type': dataset_type,\n",    "                    'age_17_count': len(age_17_scores), 'age_17_count': len(age_17_scores),\n",    "                    'age_17_avg': age_17_scores.mean(), 'age_18_avg': age_18_scores.mean(),\n",    "                    't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05\n",    "                })\n",    "        \n",    "        except Exception as e:\n",    "            print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –æ–±'—î–¥–Ω–∞–Ω–æ–º—É –∞–Ω–∞–ª—ñ–∑—ñ {dataset_type}: {e}\")\n",    "\n",    "# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –æ–±'—î–¥–Ω–∞–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤\n",    "pd.DataFrame(summary_gender).to_csv(os.path.join(RESULTS_FOLDER, 'gender_math_summary.csv'), index=False)\n",    "pd.DataFrame(summary_abroad).to_csv(os.path.join(RESULTS_FOLDER, 'abroad_results_summary.csv'), index=False)\n",    "pd.DataFrame(summary_correlation).to_csv(os.path.join(RESULTS_FOLDER, 'subject_correlation_summary.csv'), index=False)\n",    "pd.DataFrame(summary_subjects).to_csv(os.path.join(RESULTS_FOLDER, 'additional_subjects_summary.csv'), index=False)\n",    "pd.DataFrame(summary_age).to_csv(os.path.join(RESULTS_FOLDER, 'age_groups_summary.csv'), index=False)\n",    "\n",    "# –í—Å—Ç–∞–≤—Ç–µ —Å–µ–∫—Ü—ñ—é –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ —Ç—É—Ç\n",    "\n",    "print(f\"\\nüéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{RESULTS_FOLDER}'\")"   ],   "id": "c5a6be50dbd063b8",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤\n",    "print(\"\\nüîÑ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤...\")\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 1: –ì–µ–Ω–¥–µ—Ä (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_gender_results:\n",    "    if 'male_avg' in result and 'female_avg' in result:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.bar(['–ß–æ–ª–æ–≤—ñ–∫–∏', '–ñ—ñ–Ω–∫–∏'], [result['male_avg'], result['female_avg']],\n",    "                color=['#36A2EB', '#FF6384'], edgecolor=['#2E8B57', '#C71585'])\n",    "        plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ —Å—Ç–∞—Ç—Ç—é ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'gender_math_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 1: –ì–µ–Ω–¥–µ—Ä (–æ–±'—î–¥–Ω–∞–Ω—ñ)\n",    "for result in summary_gender:\n",    "    plt.figure(figsize=(8, 6))\n",    "    plt.bar(['–ß–æ–ª–æ–≤—ñ–∫–∏', '–ñ—ñ–Ω–∫–∏'], [result['male_avg'], result['female_avg']],\n",    "            color=['#36A2EB', '#FF6384'], edgecolor=['#2E8B57', '#C71585'])\n",    "    plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ —Å—Ç–∞—Ç—Ç—é ({result[\"dataset_type\"]}, Combined)')\n",    "    plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "    plt.savefig(os.path.join(GRAPHS_FOLDER, f'gender_math_{result[\"dataset_type\"]}_combined.png'), dpi=300, bbox_inches='tight')\n",    "    plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 2: –ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º (–ø–æ —Ä–æ–∫–∞—Ö, –ª–∏—à–µ –ù–ú–¢)\n",    "for result in all_abroad_results:\n",    "    if 'abroad_avg' in result and 'ukraine_avg' in result:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.bar(['–ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º', '–£–∫—Ä–∞—ó–Ω–∞'], [result['abroad_avg'], result['ukraine_avg']],\n",    "                color=['#FFCE56', '#4BC0C0'], edgecolor=['#FFD700', '#20B2AA'])\n",    "        plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ –º—ñ—Å—Ü–µ–º —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è (–ù–ú–¢, {result[\"file\"]})')\n",    "        plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'abroad_results_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 2: –ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º (–æ–±'—î–¥–Ω–∞–Ω—ñ, –ª–∏—à–µ –ù–ú–¢)\n",    "for result in summary_abroad:\n",    "    plt.figure(figsize=(8, 6))\n",    "    plt.bar(['–ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º', '–£–∫—Ä–∞—ó–Ω–∞'], [result['abroad_avg'], result['ukraine_avg']],\n",    "            color=['#FFCE56', '#4BC0C0'], edgecolor=['#FFD700', '#20B2AA'])\n",    "    plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ –º—ñ—Å—Ü–µ–º —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è (–ù–ú–¢, Combined)')\n",    "    plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "    plt.savefig(os.path.join(GRAPHS_FOLDER, f'abroad_results_NMT_combined.png'), dpi=300, bbox_inches='tight')\n",    "    plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 3: –ö–æ—Ä–µ–ª—è—Ü—ñ—è (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_correlation_results:\n",    "    if 'corr_matrix' in result:\n",    "        corr_matrix = result['corr_matrix']\n",    "        subjects = [s.replace('_score_100', '') for s in corr_matrix.columns]\n",    "        plt.figure(figsize=(10, 8))\n",    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",    "                    xticklabels=subjects, yticklabels=subjects)\n",    "        plt.title(f'–ö–æ—Ä–µ–ª—è—Ü—ñ—è –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'subject_correlation_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 3: –ö–æ—Ä–µ–ª—è—Ü—ñ—è (–æ–±'—î–¥–Ω–∞–Ω—ñ)\n",    "for result in summary_correlation:\n",    "    if 'corr_matrix' in result:\n",    "        corr_matrix = result['corr_matrix']\n",    "        subjects = [s.replace('_score_100', '') for s in corr_matrix.columns]\n",    "        plt.figure(figsize=(10, 8))\n",    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",    "                    xticklabels=subjects, yticklabels=subjects)\n",    "        plt.title(f'–ö–æ—Ä–µ–ª—è—Ü—ñ—è –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({result[\"dataset_type\"]}, Combined)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'subject_correlation_{result[\"dataset_type\"]}_combined.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 4: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø—Ä–µ–¥–º–µ—Ç–∏ (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_subjects_results:\n",    "    counts = {k: v for k, v in result.items() if k not in ['file', 'dataset_type'] and isinstance(v, (int, float)) and v > 0}\n",    "    if counts:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.pie(list(counts.values()), labels=list(counts.keys()), colors=sns.color_palette('pastel'),\n",    "                autopct='%1.1f%%')\n",    "        plt.title(f'–ü–æ–ø—É–ª—è—Ä–Ω—ñ—Å—Ç—å –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'additional_subjects_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "    else:\n",    "        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –≥—Ä–∞—Ñ—ñ–∫ –¥–ª—è {result['file']}: –Ω–µ–º–∞—î –∫–æ—Ä–µ–∫—Ç–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({counts})\")\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 4: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø—Ä–µ–¥–º–µ—Ç–∏ (–æ–±'—î–¥–Ω–∞–Ω—ñ)\n",    "for result in summary_subjects:\n",    "    counts = {k: v for k, v in result.items() if k != 'dataset_type' and isinstance(v, (int, float)) and v > 0}\n",    "    if counts:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.pie(list(counts.values()), labels=list(counts.keys()), colors=sns.color_palette('pastel'),\n",    "                autopct='%1.1f%%')\n",    "        plt.title(f'–ü–æ–ø—É–ª—è—Ä–Ω—ñ—Å—Ç—å –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({result[\"dataset_type\"]}, Combined)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'additional_subjects_{result[\"dataset_type\"]}_combined.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "    else:\n",    "        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –≥—Ä–∞—Ñ—ñ–∫ –¥–ª—è {result['dataset_type']}_combined: –Ω–µ–º–∞—î –∫–æ—Ä–µ–∫—Ç–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({counts})\")\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 5: –í—ñ–∫–æ–≤—ñ –≥—Ä—É–ø–∏ (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_age_results:\n",    "    if 'age_17_avg' in result and 'age_18_avg' in result:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.bar(['17 —Ä–æ–∫—ñ–≤', '18 —Ä–æ–∫—ñ–≤'], [result['age_17_avg'], result['age_18_avg']],\n",    "                color=['#FF6384', '#36A2EB'], edgecolor=['#DC143C', '#1E90FF'])\n",    "        plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ –≤—ñ–∫–æ–º ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'age_groups_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 5: –í—ñ–∫–æ–≤—ñ –≥—Ä—É–ø–∏ (–æ–±'—î–¥–Ω–∞–Ω—ñ)\n",    "for result in summary_age:\n",    "    plt.figure(figsize=(8, 6))\n",    "    plt.bar(['17 —Ä–æ–∫—ñ–≤', '18 —Ä–æ–∫—ñ–≤'], [result['age_17_avg'], result['age_18_avg']],\n",    "            color=['#FF6384', '#36A2EB'], edgecolor=['#DC143C', '#1E90FF'])\n",    "    plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ –≤—ñ–∫–æ–º ({result[\"dataset_type\"]}, Combined)')\n",    "    plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "    plt.savefig(os.path.join(GRAPHS_FOLDER, f'age_groups_{result[\"dataset_type\"]}_combined.png'), dpi=300, bbox_inches='tight')\n",    "    plt.close()\n",    "\n",    "print(f\"\\nüéâ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ì—Ä–∞—Ñ—ñ–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{GRAPHS_FOLDER}'\")\n"   ],   "id": "edaa416af057e110",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": "",   "id": "48589a22555b48a2",   "outputs": [],   "execution_count": null  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}