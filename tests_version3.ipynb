{ "cells": [  {   "metadata": {},   "cell_type": "markdown",   "source": [    "**–ù—É–ª—å–æ–≤–∞ –≥—ñ–ø–æ—Ç–µ–∑–∞ (H‚ÇÄ):**\n",    "–°–µ—Ä–µ–¥–Ω—ñ–π –±–∞–ª –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ —É —á–æ–ª–æ–≤—ñ–∫—ñ–≤ —ñ –∂—ñ–Ω–æ–∫ –Ω–µ –≤—ñ–¥—Ä—ñ–∑–Ω—è—î—Ç—å—Å—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ –∑–Ω–∞—á—É—â–æ.\n",    "\n",    "**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞ –≥—ñ–ø–æ—Ç–µ–∑–∞ (H‚ÇÅ):**\n",    "–°–µ—Ä–µ–¥–Ω—ñ–π –±–∞–ª –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ —É —á–æ–ª–æ–≤—ñ–∫—ñ–≤ —ñ –∂—ñ–Ω–æ–∫ –≤—ñ–¥—Ä—ñ–∑–Ω—è—î—Ç—å—Å—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ –∑–Ω–∞—á—É—â–æ."   ],   "id": "d833a390c38f5a10"  },  {   "cell_type": "code",   "id": "initial_id",   "metadata": {    "collapsed": true   },   "source": [    "def analyze_gender_math(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î —Ä—ñ–∑–Ω–∏—Ü—é –≤ –æ—Ü—ñ–Ω–∫–∞—Ö –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∑–∞ —Å—Ç–∞—Ç—Ç—é.\"\"\"\n",    "    required_cols = ['math_score_100', 'gender']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "\n",    "    df_math = df[df['math_score_100'].notna() & df['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])]\n",    "    male_scores = df_math[df_math['gender'] == '—á–æ–ª–æ–≤—ñ—á–∞']['math_score_100']\n",    "    female_scores = df_math[df_math['gender'] == '–∂—ñ–Ω–æ—á–∞']['math_score_100']\n",    "\n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(male_scores) >= 30 and len(female_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(male_scores, female_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(male_scores, female_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((male_scores.std() ** 2) + (female_scores.std() ** 2)) / 2)\n",    "        cohen_d = (male_scores.mean() - female_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'male_count': len(male_scores), 'female_count': len(female_scores),\n",    "            'male_avg': male_scores.mean(), 'female_avg': female_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05,'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: —á–æ–ª–æ–≤—ñ–∫—ñ–≤={len(male_scores)}, –∂—ñ–Ω–æ–∫={len(female_scores)}'\n",    "\n",    "    all_results.append(result)\n",    "    return male_scores, female_scores"   ],   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_gender_ukrainian(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î —Ä—ñ–∑–Ω–∏—Ü—é –≤ –æ—Ü—ñ–Ω–∫–∞—Ö –∑ —É–∫—Ä–∞—ó—Å—å–Ω–∫–æ—ó –∑–∞ —Å—Ç–∞—Ç—Ç—é.\"\"\"\n",    "    required_cols = ['ukrainian_score_100', 'gender']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_math = df[df['ukrainian_score_100'].notna() & df['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])]\n",    "    male_scores = df_math[df_math['gender'] == '—á–æ–ª–æ–≤—ñ—á–∞']['ukrainian_score_100']\n",    "    female_scores = df_math[df_math['gender'] == '–∂—ñ–Ω–æ—á–∞']['ukrainian_score_100']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(male_scores) >= 30 and len(female_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(male_scores, female_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(male_scores, female_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((male_scores.std() ** 2) + (female_scores.std() ** 2)) / 2)\n",    "        cohen_d = (male_scores.mean() - female_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'male_count': len(male_scores), 'female_count': len(female_scores),\n",    "            'male_avg': male_scores.mean(), 'female_avg': female_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: —á–æ–ª–æ–≤—ñ–∫—ñ–≤={len(male_scores)}, –∂—ñ–Ω–æ–∫={len(female_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return male_scores, female_scores"   ],   "id": "ed9bca1241bfdc2",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_gender_history(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î —Ä—ñ–∑–Ω–∏—Ü—é –≤ –æ—Ü—ñ–Ω–∫–∞—Ö –∑ —É–∫—Ä–∞—ó—Å—å–Ω–∫–æ—ó –∑–∞ —Å—Ç–∞—Ç—Ç—é.\"\"\"\n",    "    required_cols = ['history_score_100', 'gender']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_math = df[df['history_score_100'].notna() & df['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])]\n",    "    male_scores = df_math[df_math['gender'] == '—á–æ–ª–æ–≤—ñ—á–∞']['history_score_100']\n",    "    female_scores = df_math[df_math['gender'] == '–∂—ñ–Ω–æ—á–∞']['history_score_100']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(male_scores) >= 30 and len(female_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(male_scores, female_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(male_scores, female_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((male_scores.std() ** 2) + (female_scores.std() ** 2)) / 2)\n",    "        cohen_d = (male_scores.mean() - female_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'male_count': len(male_scores), 'female_count': len(female_scores),\n",    "            'male_avg': male_scores.mean(), 'female_avg': female_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: —á–æ–ª–æ–≤—ñ–∫—ñ–≤={len(male_scores)}, –∂—ñ–Ω–æ–∫={len(female_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return male_scores, female_scores"   ],   "id": "dc63dc7dc1286f67",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_gender_english(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î —Ä—ñ–∑–Ω–∏—Ü—é –≤ –æ—Ü—ñ–Ω–∫–∞—Ö –∑ —É–∫—Ä–∞—ó—Å—å–Ω–∫–æ—ó –∑–∞ —Å—Ç–∞—Ç—Ç—é.\"\"\"\n",    "    required_cols = ['english_score_100', 'gender']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_math = df[df['english_score_100'].notna() & df['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])]\n",    "    male_scores = df_math[df_math['gender'] == '—á–æ–ª–æ–≤—ñ—á–∞']['english_score_100']\n",    "    female_scores = df_math[df_math['gender'] == '–∂—ñ–Ω–æ—á–∞']['english_score_100']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(male_scores) >= 30 and len(female_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(male_scores, female_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(male_scores, female_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((male_scores.std() ** 2) + (female_scores.std() ** 2)) / 2)\n",    "        cohen_d = (male_scores.mean() - female_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'male_count': len(male_scores), 'female_count': len(female_scores),\n",    "            'male_avg': male_scores.mean(), 'female_avg': female_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: —á–æ–ª–æ–≤—ñ–∫—ñ–≤={len(male_scores)}, –∂—ñ–Ω–æ–∫={len(female_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return male_scores, female_scores"   ],   "id": "9200f81604f722db",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import seaborn as sns\n",    "import matplotlib.pyplot as plt\n",    "\n",    "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö\n",    "df_2020 = pd.read_csv('filtered_data/2020.csv')\n",    "df_2023 = pd.read_csv('filtered_data/2023.csv')\n",    "\n",    "# –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è: —Ç—ñ–ª—å–∫–∏ —Ç—ñ, —Ö—Ç–æ –º–∞—î –æ—Ü—ñ–Ω–∫—É –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ —ñ –∑–∞–∑–Ω–∞—á–µ–Ω–∏–π –≥–µ–Ω–¥–µ—Ä\n",    "df_2020_math = df_2020[df_2020['math_score_100'].notna() & df_2020['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])].copy()\n",    "df_2023_math = df_2023[df_2023['math_score_100'].notna() & df_2023['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])].copy()\n",    "\n",    "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤\n",    "plt.figure(figsize=(14, 6))\n",    "\n",    "# 2020\n",    "plt.subplot(1, 2, 1)\n",    "sns.histplot(\n",    "    data=df_2020_math,\n",    "    x='math_score_100',\n",    "    hue='gender',\n",    "    bins=50,\n",    "    element='step',\n",    "    stat='density',\n",    "    common_norm=False,\n",    "    palette='Set2'\n",    ")\n",    "plt.title('–†–æ–∑–ø–æ–¥—ñ–ª –±–∞–ª—ñ–≤ –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ (2020)')\n",    "plt.xlabel('–ë–∞–ª–∏')\n",    "plt.ylabel('–©—ñ–ª—å–Ω—ñ—Å—Ç—å')\n",    "\n",    "# 2023\n",    "plt.subplot(1, 2, 2)\n",    "sns.histplot(\n",    "    data=df_2023_math,\n",    "    x='math_score_100',\n",    "    hue='gender',\n",    "    bins=50,\n",    "    element='step',\n",    "    stat='density',\n",    "    common_norm=False,\n",    "    palette='Set2'\n",    ")\n",    "plt.title('–†–æ–∑–ø–æ–¥—ñ–ª –±–∞–ª—ñ–≤ –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ (2023)')\n",    "plt.xlabel('–ë–∞–ª–∏')\n",    "plt.ylabel('–©—ñ–ª—å–Ω—ñ—Å—Ç—å')\n",    "\n",    "# –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è\n",    "plt.tight_layout()\n",    "plt.show()\n"   ],   "id": "4ad9670f513f77bb",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "from scipy.stats import ttest_ind, mannwhitneyu\n",    "def analyze_abroad_results(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ü–æ—Ä—ñ–≤–Ω—é—î –æ—Ü—ñ–Ω–∫–∏ –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∑–∞ –∫–æ—Ä–¥–æ–Ω–æ–º —ñ –≤ –£–∫—Ä–∞—ó–Ω—ñ (–ª–∏—à–µ –¥–ª—è –ù–ú–¢).\"\"\"\n",    "    if dataset_type != 'NMT':\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    required_cols = ['math_score_100', 'region_flag']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_scores = df[df['average_score'].notna() & df['region_flag'].notna()]\n",    "    df_scores['location'] = np.where(df_scores['region_flag'] == 'other', '–ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º', '–£–∫—Ä–∞—ó–Ω–∞')\n",    "\n",    "    abroad_scores = df_scores[df_scores['location'] == '–ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º']['average_score']\n",    "    ukraine_scores = df_scores[df_scores['location'] == '–£–∫—Ä–∞—ó–Ω–∞']['average_score']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(abroad_scores) >= 30 and len(ukraine_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(abroad_scores, ukraine_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(abroad_scores, ukraine_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((abroad_scores.std() ** 2) + (ukraine_scores.std() ** 2)) / 2)\n",    "        cohen_d = (abroad_scores.mean() - ukraine_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'abroad_count': len(abroad_scores), 'ukraine_count': len(ukraine_scores),\n",    "            'abroad_avg': abroad_scores.mean(), 'ukraine_avg': ukraine_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: –∑–∞ –∫–æ—Ä–¥–æ–Ω–æ–º={len(abroad_scores)}, –£–∫—Ä–∞—ó–Ω–∞={len(ukraine_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return abroad_scores, ukraine_scores"   ],   "id": "6d63d1bd06b88360",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "# –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞\n",    "import pandas as pd\n",    "df = pd.read_csv(\"filtered_data/2023.csv\", low_memory=False)\n",    "df_foreign = df[df['region_name'].str.contains(\"–Ü–Ω—à—ñ –∫—Ä–∞—ó–Ω–∏\", case=False, na=False)]\n",    "print(df_foreign)\n",    "df_foreign.to_csv(\"results/2023_foreign_testers.csv\", index=False, encoding='utf-8')"   ],   "id": "1e46dfbf65ea610f",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "# from scipy.stats import spearmanr\n",    "# import pandas as pd\n",    "# import seaborn as sns\n",    "# import matplotlib.pyplot as plt\n",    "# import os\n",    "# \n",    "# def analyze_subject_correlation(df, dataset_type, filename, all_results):\n",    "#     \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î –∫–æ—Ä–µ–ª—è—Ü—ñ—é –º—ñ–∂ –ø—Ä–µ–¥–º–µ—Ç–∞–º–∏, –æ–∫—Ä–µ–º–æ –¥–ª—è 2022 —ñ —ñ–Ω—à–∏—Ö —Ä–æ–∫—ñ–≤.\"\"\"\n",    "# \n",    "#     all_subjects = [\n",    "#         'ukrainian_score_100', 'math_score_100',\n",    "#         'biology_score_100', 'chemistry_score_100', 'physics_score_100',\n",    "#         'english_score_100', 'geography_score_100', 'ukrainian_literature_score_100',\n",    "#         'history_score_100', 'french_score_100', 'german_score_100', 'spanish_score_100'\n",    "#     ]\n",    "# \n",    "#     nmt_2022_subjects = ['ukrainian_score_100', 'math_score_100', 'history_score_100']\n",    "#     \n",    "#     if '2022' in filename and dataset_type == 'NMT':\n",    "#         subjects = nmt_2022_subjects\n",    "#     else:\n",    "#         subjects = all_subjects\n",    "#     \n",    "# \n",    "#     available_subjects = [s for s in subjects if s in df.columns]\n",    "#     print(f\"–î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ —É {filename}: {df.columns.tolist()}\")\n",    "#     print(f\"–ó–Ω–∞–π–¥–µ–Ω—ñ –ø—Ä–µ–¥–º–µ—Ç–∏: {available_subjects}\")\n",    "#     print(f\"–¢–∏–ø–∏ –¥–∞–Ω–∏—Ö: {df[available_subjects].dtypes}\")\n",    "#     \n",    "#     if len(available_subjects) < 2:\n",    "#         print(f\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ –¥–ª—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —É {filename}: {available_subjects}\")\n",    "#         result = {'file': filename, 'dataset_type': dataset_type, 'error': '–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –ø—Ä–µ–¥–º–µ—Ç—ñ–≤'}\n",    "#         all_results.append(result)\n",    "#         return pd.DataFrame()\n",    "#     \n",    "#     result = {'file': filename, 'dataset_type': dataset_type}\n",    "#     \n",    "#     corr_matrix = df[available_subjects].corr(method='spearman').round(2)\n",    "#     if len(df[available_subjects].dropna(how='all')) >= 30:\n",    "#         for i, s1 in enumerate(available_subjects):\n",    "#             for s2 in available_subjects[i+1:]:\n",    "#                 valid_data = df[[s1, s2]].dropna()\n",    "#                 if len(valid_data) >= 10:  \n",    "#                     corr, pval = spearmanr(valid_data[s1], valid_data[s2])\n",    "#                     result[f'{s1.replace(\"_score_100\", \"\")}_{s2.replace(\"_score_100\", \"\")}_corr'] = corr\n",    "#                     result[f'{s1.replace(\"_score_100\", \"\")}_{s2.replace(\"_score_100\", \"\")}_pval'] = pval\n",    "#                 else:\n",    "#                     result[f'{s1.replace(\"_score_100\", \"\")}_{s2.replace(\"_score_100\", \"\")}_corr'] = None\n",    "#                     result[f'{s1.replace(\"_score_100\", \"\")}_{s2.replace(\"_score_100\", \"\")}_pval'] = None\n",    "#         result['corr_matrix'] = corr_matrix\n",    "#         \n",    "#         # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–µ–ø–ª–æ–≤–æ—ó –∫–∞—Ä—Ç–∏\n",    "#         plt.figure(figsize=(10, 8))\n",    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",    "#         plt.title(f'–ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è ({dataset_type}, {filename})')\n",    "#         plt.savefig(os.path.join('results/graphs', f'corr_matrix_{filename}.png'), dpi=300)\n",    "#         plt.close()\n",    "#     else:\n",    "#         result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: {len(df[available_subjects].dropna(how=\"all\"))} –∑–∞–ø–∏—Å—ñ–≤'\n",    "#     \n",    "#     all_results.append(result)\n",    "#     return df[available_subjects]"   ],   "id": "e74124edcc9ef533",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "# def analyze_additional_subjects(df, dataset_type, filename, all_results):\n",    "#     \"\"\"–í–∏–∑–Ω–∞—á–∞—î —á–∞—Å—Ç–æ—Ç—É –≤–∏–±–æ—Ä—É –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –ø—Ä–µ–¥–º–µ—Ç—ñ–≤.\"\"\"\n",    "#     subjects = [\n",    "#         'biology_score_100', 'chemistry_score_100', 'physics_score_100',\n",    "#         'english_score_100', 'geography_score_100', 'ukrainian_literature_score_100',\n",    "#         'history_score_100', 'french_score_100', 'german_score_100', 'spanish_score_100',\n",    "#     ]\n",    "#     counts = {}\n",    "#     for subject in subjects:\n",    "#         if subject in df.columns:\n",    "#             counts[subject.replace('_score_100', '')] = df[subject].notna().sum()\n",    "#     \n",    "#     result = {'file': filename, 'dataset_type': dataset_type, **counts}\n",    "#     all_results.append(result)\n",    "#     return counts"   ],   "id": "ac139e29b8764ce0",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_age_groups(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ü–æ—Ä—ñ–≤–Ω—é—î –æ—Ü—ñ–Ω–∫–∏ –∑ average_score –∑–∞ –≤—ñ–∫–æ–º (17/18).\"\"\"\n",    "    required_cols = ['average_score', 'student_age']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_age = df[df['average_score'].notna() & df['student_age'].isin([17, 18])]\n",    "    age_17_scores = df_age[df_age['student_age'] == 17]['average_score']\n",    "    age_18_scores = df_age[df_age['student_age'] == 18]['average_score']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(age_17_scores) >= 30 and len(age_18_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(age_17_scores, age_18_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(age_17_scores, age_18_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((age_17_scores.std() ** 2) + (age_18_scores.std() ** 2)) / 2)\n",    "        cohen_d = (age_17_scores.mean() - age_18_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'age_17_count': len(age_17_scores), 'age_18_count': len(age_18_scores),\n",    "            'age_17_avg': age_17_scores.mean(), 'age_18_avg': age_18_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: 17={len(age_17_scores)}, 18={len(age_18_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return age_17_scores, age_18_scores"   ],   "id": "beeaac2b5d68e837",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "# def analyze_age_group(df, dataset_type, filename, all_results):\n",    "#     \"\"\"–ü–æ—Ä—ñ–≤–Ω—é—î –æ—Ü—ñ–Ω–∫–∏ –∑ average_score –∑–∞ –≤—ñ–∫–æ–º (17/18).\"\"\"\n",    "#     required_cols = ['average_score', 'student_age']\n",    "#     if not all(col in df.columns for col in required_cols):\n",    "#         print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "#         return pd.Series(), pd.Series()\n",    "#     \n",    "#     df_age = df[df['average_score'].notna() & df['student_age'].isin([16, 19])]\n",    "#     age_16_scores = df_age[df_age['student_age'] == 16]['average_score']\n",    "#     age_17_scores = df_age[df_age['student_age'] == 19]['average_score']\n",    "#     \n",    "#     result = {'file': filename, 'dataset_type': dataset_type}\n",    "#     if len(age_16_scores) >= 30 and len(age_17_scores) >= 30:\n",    "#         t_stat, p_value = ttest_ind(age_16_scores, age_17_scores, equal_var=False, nan_policy='omit')\n",    "#         u_stat, u_pval = mannwhitneyu(age_16_scores, age_17_scores, alternative='two-sided')\n",    "#         pooled_std = np.sqrt(((age_16_scores.std() ** 2) + (age_17_scores.std() ** 2)) / 2)\n",    "#         cohen_d = (age_16_scores.mean() - age_17_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "#         result.update({\n",    "#             'age_17_count': len(age_16_scores), 'age_18_count': len(age_17_scores),\n",    "#             'age_17_avg': age_16_scores.mean(), 'age_18_avg': age_17_scores.mean(),\n",    "#             't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "#             'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "#         })\n",    "#     else:\n",    "#         result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: 17={len(age_16_scores)}, 18={len(age_17_scores)}'\n",    "#     \n",    "#     all_results.append(result)\n",    "#     return age_16_scores, age_17_scores"   ],   "id": "1731e635801443ae",   "outputs": [],   "execution_count": null  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-07-01T09:25:17.244141Z",     "start_time": "2025-07-01T09:25:17.166276Z"    }   },   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import numpy as np\n",    "from scipy.stats import kruskal\n",    "from scipy.stats import rankdata\n",    "\n",    "def analyze_education_org_type(df, dataset_type, filename, all_results):\n",    "    \"\"\"\n",    "    –ê–Ω–∞–ª—ñ–∑—É—î —Ç–∏–ø–∏ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –∑–∞–∫–ª–∞–¥—ñ–≤, –≥—Ä—É–ø—É—î —Ç–æ–ø-6 (2019-2021) –∞–±–æ —Ç–æ–ø-5 (2022-2024) —Ç–∏–ø—ñ–≤,\n",    "    —ñ –≤–∏–∫–æ–Ω—É—î –Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–∏–π —Ç–µ—Å—Ç –ö—Ä—É—Å–∫–∞–ª–∞-–í–∞–ª–ª—ñ—Å–∞ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö –æ—Ü—ñ–Ω–æ–∫.\n",    "    \"\"\"\n",    "    # –í–∏—Ç—è–≥—É—î–º–æ —Ä—ñ–∫ —ñ–∑ –Ω–∞–∑–≤–∏ —Ñ–∞–π–ª—É –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ç–æ–ø—É\n",    "    year = int(filename.split('.')[0])\n",    "\n",    "    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",    "    required_cols = ['education_org_type', 'average_score']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "\n",    "    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ —Ä—è–¥–∫–∏ –∑ –≤–∞–ª—ñ–¥–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏\n",    "    df_scores = df[df['average_score'].notna() & df['education_org_type'].notna()].copy()\n",    "\n",    "    # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ç–æ–ø –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—é –∑–∞–ø–∏—Å—ñ–≤\n",    "    if 2019 <= year <= 2021:\n",    "        top_n = 6\n",    "    else:  # 2022 <= year <= 2024\n",    "        top_n = 5\n",    "\n",    "    # –ì—Ä—É–ø—É—î–º–æ –∑–∞ education_org_type —ñ –æ–±—á–∏—Å–ª—é—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",    "    type_summary = df_scores.groupby('education_org_type')['average_score'].agg(['count', 'mean']).reset_index()\n",    "    top_types = type_summary.sort_values('count', ascending=False).head(top_n)['education_org_type'].tolist()\n",    "\n",    "    # –î–æ–¥–∞—î–º–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—é \"—ñ–Ω—à—ñ\"\n",    "    df_scores['education_org_type_grouped'] = df_scores['education_org_type'].apply(\n",    "        lambda x: x if x in top_types else '—ñ–Ω—à—ñ'\n",    "    )\n",    "\n",    "    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –≥—Ä—É–ø –¥–ª—è —Ç–µ—Å—Ç—É\n",    "    groups = {}\n",    "    for name, group in df_scores.groupby('education_org_type_grouped'):\n",    "        groups[name] = group['average_score'].dropna().values\n",    "    group_names = list(groups.keys())\n",    "    group_data = [groups[name] for name in group_names]\n",    "\n",    "    # –†–µ–∑—É–ª—å—Ç–∞—Ç–∏\n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "\n",    "    if all(len(data) >= 30 for data in group_data):  # –ú—ñ–Ω—ñ–º—É–º 30 –∑–∞–ø–∏—Å—ñ–≤ –Ω–∞ –≥—Ä—É–ø—É\n",    "        # –¢–µ—Å—Ç –ö—Ä—É—Å–∫–∞–ª–∞-–í–∞–ª–ª—ñ—Å–∞\n",    "        stat, p_value = kruskal(*group_data)\n",    "        result.update({\n",    "            'stat': stat, 'p_value': p_value, 'significant': p_value < 0.05\n",    "        })\n",    "\n",    "        # –ï—Ñ–µ–∫—Ç —Ä–æ–∑–º—ñ—Ä—É (–∞–Ω–∞–ª–æ–≥ Cohen's d –¥–ª—è —Ä–∞–Ω–≥—ñ–≤, —Å–ø—Ä–æ—â–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è)\n",    "        all_ranks = rankdata(np.concatenate(group_data))\n",    "        group_ranks = [rankdata(data) for data in group_data]\n",    "        n_total = len(all_ranks)\n",    "        rank_sums = [sum(ranks) for ranks in group_ranks]\n",    "        n_groups = len(group_data)\n",    "        h_adjusted = stat * (n_total - 1) / (n_total - n_groups)\n",    "        epsilon_squared = h_adjusted / (n_total * (n_groups - 1))  # –ï—Ñ–µ–∫—Ç —Ä–æ–∑–º—ñ—Ä—É\n",    "        result['epsilon_squared'] = epsilon_squared\n",    "\n",    "        # –í–∏–∑–Ω–∞—á–∞—î–º–æ \"–∫—Ä–∞—â–∏–π\" —Ç–∏–ø (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —Å–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ —Å–µ—Ä–µ–¥ —Ç–æ–ø-–≥—Ä—É–ø)\n",    "        top_group_means = {name: np.mean(data) for name, data in groups.items() if name != '—ñ–Ω—à—ñ'}\n",    "        if top_group_means:\n",    "            best_type = max(top_group_means, key=top_group_means.get)\n",    "            best_mean = top_group_means[best_type]\n",    "            result.update({\n",    "                'best_type': best_type,\n",    "                'best_mean': best_mean\n",    "            })\n",    "            print(f\"üîπ –ù–∞–π–∫—Ä–∞—â–∏–π —Ç–∏–ø –Ω–∞–≤—á–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–ª–∞–¥—É: {best_type} (—Å–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞: {best_mean:.2f})\")\n",    "        else:\n",    "            print(\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ —Ç–∏–ø—É.\")\n",    "\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: {[len(data) for data in group_data]} –∑–∞–ø–∏—Å—ñ–≤ —É –≥—Ä—É–ø–∞—Ö'\n",    "\n",    "    all_results.append(result)\n",    "    return df_scores['education_org_type_grouped'], df_scores['average_score']"   ],   "id": "80a399b71781bff2",   "outputs": [],   "execution_count": 69  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-07-01T09:25:46.932360Z",     "start_time": "2025-07-01T09:25:21.847671Z"    }   },   "cell_type": "code",   "source": [    "import os\n",    "import pandas as pd\n",    "import numpy as np\n",    "from scipy.stats import ttest_ind, mannwhitneyu\n",    "import chardet\n",    "import re\n",    "import csv\n",    "import matplotlib.pyplot as plt\n",    "import seaborn as sns\n",    "from pathlib import Path\n",    "\n",    "# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–∞–ø–æ–∫\n",    "INPUT_FOLDER = \"filtered_data\"\n",    "RESULTS_FOLDER = \"results\"\n",    "GRAPHS_FOLDER = os.path.join(RESULTS_FOLDER, \"graphs\")\n",    "for folder in [RESULTS_FOLDER, GRAPHS_FOLDER]:\n",    "    os.makedirs(folder, exist_ok=True)\n",    "\n",    "sns.set_style(\"whitegrid\")\n",    "\n",    "def detect_encoding(file_path):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î –∫–æ–¥—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—É.\"\"\"\n",    "    try:\n",    "        with open(file_path, 'rb') as f:\n",    "            return chardet.detect(f.read(10000))['encoding'] or 'utf-8'\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–æ–¥—É–≤–∞–Ω–Ω—è –¥–ª—è {file_path}: {e}\")\n",    "        return 'utf-8'\n",    "\n",    "def detect_separator(file_path, encoding):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫ —É CSV-—Ñ–∞–π–ª—ñ.\"\"\"\n",    "    try:\n",    "        with open(file_path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            return csv.Sniffer().sniff(sample).delimiter\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫–∞ –¥–ª—è {file_path}: {e}\")\n",    "        return ','\n",    "\n",    "def load_csv(file_path):\n",    "    \"\"\"–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î CSV-—Ñ–∞–π–ª.\"\"\"\n",    "    encoding = detect_encoding(file_path)\n",    "    sep = detect_separator(file_path, encoding)\n",    "    print(f\"   –ö–æ–¥—É–≤–∞–Ω–Ω—è: {encoding}, —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫: '{sep}'\")\n",    "    \n",    "    try:\n",    "        df = pd.read_csv(file_path, encoding=encoding, sep=sep, quotechar='\"', on_bad_lines='skip')\n",    "        print(f\"   –ü–µ—Ä—à—ñ 5 –∫–æ–ª–æ–Ω–æ–∫: {list(df.columns[:5])}\")\n",    "        return df\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è {file_path}: {e}\")\n",    "        return None\n",    "\n",    "def detect_dataset_type(filename):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É –∑–∞ –Ω–∞–∑–≤–æ—é —Ñ–∞–π–ª—É.\"\"\"\n",    "    match = re.search(r'(\\d{4})', filename)\n",    "    if match:\n",    "        year = int(match.group(1))\n",    "        return 'NMT' if year >= 2022 else 'ZNO'\n",    "    return None\n",    "\n",    "# –ó–±—ñ—Ä –¥–∞–Ω–∏—Ö\n",    "all_gender_results = []\n",    "all_gender_results2 = []\n",    "all_gender_results3 = []\n",    "all_gender_results4 = []\n",    "all_abroad_results = []\n",    "all_correlation_results = []\n",    "all_subjects_results = []\n",    "all_age_results = []\n",    "\n",    "age_results = []\n",    "education_results = []\n",    "\n",    "for filename in os.listdir(INPUT_FOLDER):\n",    "    if not filename.endswith(\".csv\"):\n",    "        continue\n",    "    \n",    "    path = os.path.join(INPUT_FOLDER, filename)\n",    "    print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename}...\")\n",    "    \n",    "    try:\n",    "        df = load_csv(path)\n",    "        if df is None or df.empty:\n",    "            print(f\"‚ö†Ô∏è –§–∞–π–ª {filename} –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏\")\n",    "            continue\n",    "        \n",    "        dataset_type = detect_dataset_type(filename)\n",    "        if not dataset_type:\n",    "            print(f\"‚ö†Ô∏è –ù–µ–≤—ñ–¥–æ–º–∏–π —Ç–∏–ø –¥–∞–Ω–∏—Ö: {filename}\")\n",    "            continue\n",    "        \n",    "        print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "        \n",    "        gender_male, gender_female = analyze_gender_math(df, dataset_type, filename, all_gender_results)\n",    "        gender_male2, gender_female2 = analyze_gender_ukrainian(df, dataset_type, filename, all_gender_results2)\n",    "        gender_male3, gender_female3 = analyze_gender_history(df, dataset_type, filename, all_gender_results3)\n",    "        gender_male4, gender_female4 = analyze_gender_english(df, dataset_type, filename, all_gender_results4)\n",    "        abroad_abroad, abroad_ukraine = analyze_abroad_results(df, dataset_type, filename, all_abroad_results)\n",    "        # subjects_df = analyze_subject_correlation(df, dataset_type, filename, all_correlation_results)\n",    "        # subjects_counts = analyze_additional_subjects(df, dataset_type, filename, all_subjects_results)\n",    "        age_17, age_18 = analyze_age_groups(df, dataset_type, filename, all_age_results)\n",    "        # age_16, age2_17 = analyze_age_group(df, dataset_type, filename, age_results)\n",    "        education_org_type = analyze_education_org_type(df, dataset_type, filename, education_results)\n",    "      \n",    "    except Exception as e:\n",    "        print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "        import traceback\n",    "        traceback.print_exc()\n",    "\n",    "# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ —Ä–æ–∫–∞—Ö\n",    "pd.DataFrame(all_gender_results).to_csv(os.path.join(RESULTS_FOLDER, 'gender_math_analysis.csv'), index=False)\n",    "pd.DataFrame(all_gender_results2).to_csv(os.path.join(RESULTS_FOLDER, 'gender_ukrainian_analysis.csv'), index=False)\n",    "pd.DataFrame(all_gender_results3).to_csv(os.path.join(RESULTS_FOLDER, 'gender_history_analysis.csv'), index=False)\n",    "pd.DataFrame(all_gender_results4).to_csv(os.path.join(RESULTS_FOLDER, 'gender_english_analysis.csv'), index=False)\n",    "pd.DataFrame(all_abroad_results).to_csv(os.path.join(RESULTS_FOLDER, 'abroad_results_analysis.csv'), index=False)\n",    "# pd.DataFrame(all_correlation_results).to_csv(os.path.join(RESULTS_FOLDER, 'subject_correlation_analysis.csv'), index=False)\n",    "# pd.DataFrame(all_subjects_results).to_csv(os.path.join(RESULTS_FOLDER, 'additional_subjects_analysis.csv'), index=False)\n",    "pd.DataFrame(all_age_results).to_csv(os.path.join(RESULTS_FOLDER, 'age_groups_analysis.csv'), index=False)\n",    "pd.DataFrame(education_results).to_csv(os.path.join(RESULTS_FOLDER, 'education_type_analysis.csv'), index=False)\n",    "# pd.DataFrame(age_results).to_csv(os.path.join(RESULTS_FOLDER, 'age_group(16, 17)_analysis.csv'), index=False)\n",    "print(f\"\\nüéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{RESULTS_FOLDER}'\")"   ],   "id": "c5a6be50dbd063b8",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîÑ –û–±—Ä–æ–±–∫–∞ 2020.csv...\n",      "   –ö–æ–¥—É–≤–∞–Ω–Ω—è: utf-8, —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫: ','\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/4066528127.py:47: DtypeWarning: Columns (96,97,100,102,103,104,105,116,117,120,122,123,124,125) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(file_path, encoding=encoding, sep=sep, quotechar='\"', on_bad_lines='skip')\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "   –ü–µ—Ä—à—ñ 5 –∫–æ–ª–æ–Ω–æ–∫: ['id', 'birth_year', 'gender', 'region_name', 'area_name']\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 201212 —Ä—è–¥–∫—ñ–≤, 131 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "üîπ –ù–∞–π–∫—Ä–∞—â–∏–π —Ç–∏–ø –Ω–∞–≤—á–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–ª–∞–¥—É: –≥—ñ–º–Ω–∞–∑—ñ—è (—Å–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞: 157.60)\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2021.csv...\n",      "   –ö–æ–¥—É–≤–∞–Ω–Ω—è: utf-8, —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫: ','\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/4066528127.py:47: DtypeWarning: Columns (117,118,121,123,124,125,126,137,138,141,143,144,145,146) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(file_path, encoding=encoding, sep=sep, quotechar='\"', on_bad_lines='skip')\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "   –ü–µ—Ä—à—ñ 5 –∫–æ–ª–æ–Ω–æ–∫: ['id', 'birth_year', 'gender', 'region_name', 'area_name']\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 188609 —Ä—è–¥–∫—ñ–≤, 152 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "üîπ –ù–∞–π–∫—Ä–∞—â–∏–π —Ç–∏–ø –Ω–∞–≤—á–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–ª–∞–¥—É: –≥—ñ–º–Ω–∞–∑—ñ—è (—Å–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞: 158.68)\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2023.csv...\n",      "   –ö–æ–¥—É–≤–∞–Ω–Ω—è: utf-8, —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫: ','\n",      "   –ü–µ—Ä—à—ñ 5 –∫–æ–ª–æ–Ω–æ–∫: ['id', 'birth_year', 'gender', 'region_name', 'area_name']\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 256313 —Ä—è–¥–∫—ñ–≤, 64 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "üîπ –ù–∞–π–∫—Ä–∞—â–∏–π —Ç–∏–ø –Ω–∞–≤—á–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–ª–∞–¥—É: –≥—ñ–º–Ω–∞–∑—ñ—è (—Å–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞: 153.54)\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2022.csv...\n",      "   –ö–æ–¥—É–≤–∞–Ω–Ω—è: utf-8, —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫: ','\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/4066528127.py:47: DtypeWarning: Columns (8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(file_path, encoding=encoding, sep=sep, quotechar='\"', on_bad_lines='skip')\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "   –ü–µ—Ä—à—ñ 5 –∫–æ–ª–æ–Ω–æ–∫: ['id', 'birth_year', 'gender', 'region_name', 'area_name']\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 213647 —Ä—è–¥–∫—ñ–≤, 36 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ ['english_score_100', 'gender'] —É 2022.csv\n",      "üîπ –ù–∞–π–∫—Ä–∞—â–∏–π —Ç–∏–ø –Ω–∞–≤—á–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–ª–∞–¥—É: —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞ (—Å–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞: 157.51)\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2019.csv...\n",      "   –ö–æ–¥—É–≤–∞–Ω–Ω—è: utf-8, —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫: ','\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/4066528127.py:47: DtypeWarning: Columns (100,116,117,120,122,123,124,125) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(file_path, encoding=encoding, sep=sep, quotechar='\"', on_bad_lines='skip')\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "   –ü–µ—Ä—à—ñ 5 –∫–æ–ª–æ–Ω–æ–∫: ['id', 'birth_year', 'gender', 'region_name', 'area_name']\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 172734 —Ä—è–¥–∫—ñ–≤, 131 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "üîπ –ù–∞–π–∫—Ä–∞—â–∏–π —Ç–∏–ø –Ω–∞–≤—á–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–ª–∞–¥—É: –≥—ñ–º–Ω–∞–∑—ñ—è (—Å–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞: 159.02)\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2024.csv...\n",      "   –ö–æ–¥—É–≤–∞–Ω–Ω—è: utf-8, —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫: ','\n",      "   –ü–µ—Ä—à—ñ 5 –∫–æ–ª–æ–Ω–æ–∫: ['id', 'birth_year', 'gender', 'region_name', 'area_name']\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 264164 —Ä—è–¥–∫—ñ–≤, 78 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "üîπ –ù–∞–π–∫—Ä–∞—â–∏–π —Ç–∏–ø –Ω–∞–≤—á–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–ª–∞–¥—É: –≥—ñ–º–Ω–∞–∑—ñ—è (—Å–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞: 147.18)\n",      "\n",      "üéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ 'results'\n"     ]    }   ],   "execution_count": 70  },  {   "metadata": {},   "cell_type": "code",   "source": [    "print(\"\\nüîÑ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤...\")\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 1: –ì–µ–Ω–¥–µ—Ä (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_gender_results:\n",    "    if 'male_avg' in result and 'female_avg' in result:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.bar(['–ß–æ–ª–æ–≤—ñ–∫–∏', '–ñ—ñ–Ω–∫–∏'], [result['male_avg'], result['female_avg']],\n",    "                color=['#36A2EB', '#FF6384'], edgecolor=['#2E8B57', '#C71585'])\n",    "        plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ —Å—Ç–∞—Ç—Ç—é ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'gender_math_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 2: –ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º (–ø–æ —Ä–æ–∫–∞—Ö, –ª–∏—à–µ –ù–ú–¢)\n",    "for result in all_abroad_results:\n",    "    if 'abroad_avg' in result and 'ukraine_avg' in result:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.bar(['–ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º', '–£–∫—Ä–∞—ó–Ω–∞'], [result['abroad_avg'], result['ukraine_avg']],\n",    "                color=['#FFCE56', '#4BC0C0'], edgecolor=['#FFD700', '#20B2AA'])\n",    "        plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ –º—ñ—Å—Ü–µ–º —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è (–ù–ú–¢, {result[\"file\"]})')\n",    "        plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'abroad_results_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 3: –ö–æ—Ä–µ–ª—è—Ü—ñ—è (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_correlation_results:\n",    "    if 'corr_matrix' in result:\n",    "        corr_matrix = result['corr_matrix']\n",    "        subjects = [s.replace('_score_100', '') for s in corr_matrix.columns]\n",    "        plt.figure(figsize=(10, 8))\n",    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",    "                    xticklabels=subjects, yticklabels=subjects)\n",    "        plt.title(f'–ö–æ—Ä–µ–ª—è—Ü—ñ—è –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'subject_correlation_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 4: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø—Ä–µ–¥–º–µ—Ç–∏ (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_subjects_results:\n",    "    counts = {k: v for k, v in result.items() if k not in ['file', 'dataset_type'] and isinstance(v, (int, float)) and v > 0}\n",    "    if counts:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.pie(list(counts.values()), labels=list(counts.keys()), colors=sns.color_palette('pastel'),\n",    "                autopct='%1.1f%%')\n",    "        plt.title(f'–ü–æ–ø—É–ª—è—Ä–Ω—ñ—Å—Ç—å –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'additional_subjects_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "    else:\n",    "        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –≥—Ä–∞—Ñ—ñ–∫ –¥–ª—è {result['file']}: –Ω–µ–º–∞—î –∫–æ—Ä–µ–∫—Ç–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({counts})\")\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 5: –í—ñ–∫–æ–≤—ñ –≥—Ä—É–ø–∏ (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_age_results:\n",    "    if 'age_17_avg' in result and 'age_18_avg' in result:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.bar(['17 —Ä–æ–∫—ñ–≤', '18 —Ä–æ–∫—ñ–≤'], [result['age_17_avg'], result['age_18_avg']],\n",    "                color=['#FF6384', '#36A2EB'], edgecolor=['#DC143C', '#1E90FF'])\n",    "        plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ –≤—ñ–∫–æ–º ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'age_groups_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "print(f\"\\nüéâ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ì—Ä–∞—Ñ—ñ–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{GRAPHS_FOLDER}'\")"   ],   "id": "edaa416af057e110",   "outputs": [],   "execution_count": null  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-07-01T07:52:21.623354Z",     "start_time": "2025-07-01T07:51:42.192705Z"    }   },   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import numpy as np\n",    "import os\n",    "from sklearn.model_selection import train_test_split\n",    "from sklearn.linear_model import LinearRegression\n",    "from sklearn.preprocessing import OneHotEncoder\n",    "from sklearn.metrics import r2_score, mean_squared_error\n",    "import matplotlib.pyplot as plt\n",    "\n",    "# –ü–∞–ø–∫–∏\n",    "DATA_FOLDER = \"filtered_data\"\n",    "GRAPHS_FOLDER = \"results/graphs\"\n",    "os.makedirs(GRAPHS_FOLDER, exist_ok=True)\n",    "\n",    "# –ü–µ—Ä–µ–ª—ñ–∫ —Ñ–∞–π–ª—ñ–≤ CSV\n",    "csv_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(\".csv\")]\n",    "\n",    "# –ü–µ—Ä–µ–ª—ñ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ—Ü—ñ–Ω–æ–∫\n",    "score_columns = ['math_score_100', 'ukrainian_score_100', 'history_score_100']\n",    "\n",    "# –ü—Ä–æ—Ö–æ–¥–∏–º–æ –≤—Å—ñ —Ñ–∞–π–ª–∏\n",    "for file in csv_files:\n",    "    path = os.path.join(DATA_FOLDER, file)\n",    "    print(f\"\\nüìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: {file}\")\n",    "\n",    "    # –ß–∏—Ç–∞–Ω–Ω—è CSV\n",    "    df = pd.read_csv(path)\n",    "\n",    "    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞, —á–∏ —î –ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏\n",    "    required_features = ['territory_type', 'region_name', 'education_org_type', 'gender']\n",    "    missing_features = [c for c in required_features if c not in df.columns]\n",    "    missing_scores = [c for c in score_columns if c not in df.columns]\n",    "\n",    "    if missing_features:\n",    "        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª {file}, –±–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {missing_features}\")\n",    "        continue\n",    "\n",    "    if len(missing_scores) == len(score_columns):\n",    "        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª {file}, –±–æ –Ω–µ–º–∞—î –∂–æ–¥–Ω–æ—ó –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ü—ñ–Ω–æ–∫\")\n",    "        continue\n",    "\n",    "    # –û–±—á–∏—Å–ª—é—î–º–æ —Å–µ—Ä–µ–¥–Ω—é –æ—Ü—ñ–Ω–∫—É, —è–∫—â–æ average_score –≤—ñ–¥—Å—É—Ç–Ω—è\n",    "    if 'average_score' not in df.columns:\n",    "        available_scores = [c for c in score_columns if c in df.columns]\n",    "        df['average_score'] = df[available_scores].mean(axis=1)\n",    "\n",    "    # –í–∏–¥–∞–ª—è—î–º–æ —Ä—è–¥–∫–∏ –±–µ–∑ —Å–µ—Ä–µ–¥–Ω—å–æ—ó –æ—Ü—ñ–Ω–∫–∏\n",    "    df = df.dropna(subset=['average_score'])\n",    "\n",    "    # –¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞\n",    "    y = df['average_score']\n",    "\n",    "    # –û–∑–Ω–∞–∫–∏\n",    "    X_raw = df[required_features]\n",    "\n",    "    # One-hot encoding\n",    "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",    "    X_encoded = encoder.fit_transform(X_raw)\n",    "    feature_names = encoder.get_feature_names_out(required_features)\n",    "    X = pd.DataFrame(X_encoded, columns=feature_names)\n",    "\n",    "    # –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train/test\n",    "    X_train, X_test, y_train, y_test = train_test_split(\n",    "        X, y, test_size=0.2, random_state=42\n",    "    )\n",    "\n",    "    # –ú–æ–¥–µ–ª—å\n",    "    model = LinearRegression()\n",    "    model.fit(X_train, y_train)\n",    "    y_pred = model.predict(X_test)\n",    "\n",    "    # –ú–µ—Ç—Ä–∏–∫–∏\n",    "    r2 = r2_score(y_test, y_pred)\n",    "    mse = mean_squared_error(y_test, y_pred)\n",    "\n",    "    print(f\"üîπ R¬≤ Score: {r2:.3f}\")\n",    "    print(f\"üîπ Mean Squared Error: {mse:.2f}\")\n",    "\n",    "    # –ì—Ä–∞—Ñ—ñ–∫\n",    "    plt.figure(figsize=(8, 6))\n",    "    plt.scatter(y_test, y_pred, alpha=0.6, color=\"blue\", label=\"–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ vs –†–µ–∞–ª—å–Ω—ñ\")\n",    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label=\"–Ü–¥–µ–∞–ª—å–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å\")\n",    "    plt.xlabel(\"–†–µ–∞–ª—å–Ω—ñ –æ—Ü—ñ–Ω–∫–∏\")\n",    "    plt.ylabel(\"–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ –æ—Ü—ñ–Ω–∫–∏\")222\n",    "    plt.title(f\"–ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö –æ—Ü—ñ–Ω–æ–∫ {file}\")\n",    "    plt.legend()\n",    "    graph_path = os.path.join(GRAPHS_FOLDER, f\"prediction_scatter_{file.replace('.csv','')}.png\")\n",    "    plt.savefig(graph_path, dpi=300, bbox_inches=\"tight\")\n",    "    plt.close()\n",    "\n",    "    print(f\"‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {graph_path}\")\n"   ],   "id": "48589a22555b48a2",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2020.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/3938085748.py:27: DtypeWarning: Columns (96,97,100,102,103,104,105,116,117,120,122,123,124,125) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score: 0.169\n",      "üîπ Mean Squared Error: 443.08\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2020.png\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2021.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/3938085748.py:27: DtypeWarning: Columns (117,118,121,123,124,125,126,137,138,141,143,144,145,146) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score: 0.144\n",      "üîπ Mean Squared Error: 463.88\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2021.png\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2023.csv\n",      "üîπ R¬≤ Score: 0.161\n",      "üîπ Mean Squared Error: 201.97\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2023.png\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2022.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/3938085748.py:27: DtypeWarning: Columns (8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score: 0.153\n",      "üîπ Mean Squared Error: 214.73\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2022.png\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2019.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/3938085748.py:27: DtypeWarning: Columns (100,116,117,120,122,123,124,125) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score: 0.169\n",      "üîπ Mean Squared Error: 424.28\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2019.png\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2024.csv\n",      "üîπ R¬≤ Score: 0.133\n",      "üîπ Mean Squared Error: 261.14\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2024.png\n"     ]    }   ],   "execution_count": 66  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-07-01T09:00:17.601855Z",     "start_time": "2025-07-01T08:52:12.121875Z"    }   },   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import numpy as np\n",    "import os\n",    "from sklearn.model_selection import train_test_split, cross_val_score\n",    "from sklearn.ensemble import RandomForestRegressor\n",    "from sklearn.preprocessing import OneHotEncoder\n",    "from sklearn.metrics import r2_score, mean_squared_error\n",    "import matplotlib.pyplot as plt\n",    "\n",    "DATA_FOLDER = \"filtered_data\"\n",    "GRAPHS_FOLDER = \"results/graphs\"\n",    "os.makedirs(GRAPHS_FOLDER, exist_ok=True)\n",    "\n",    "csv_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(\".csv\")]\n",    "\n",    "score_columns = ['math_score_100', 'ukrainian_score_100', 'history_score_100']\n",    "\n",    "for file in csv_files:\n",    "    path = os.path.join(DATA_FOLDER, file)\n",    "    print(f\"\\nüìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: {file}\")\n",    "\n",    "    df = pd.read_csv(path)\n",    "\n",    "    required_features = ['territory_type', 'region_name', 'education_org_type', 'gender']\n",    "    missing_features = [c for c in required_features if c not in df.columns]\n",    "    missing_scores = [c for c in score_columns if c not in df.columns]\n",    "\n",    "    if missing_features:\n",    "        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª {file}, –±–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {missing_features}\")\n",    "        continue\n",    "\n",    "    if len(missing_scores) == len(score_columns):\n",    "        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª {file}, –±–æ –Ω–µ–º–∞—î –∂–æ–¥–Ω–æ—ó –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ü—ñ–Ω–æ–∫\")\n",    "        continue\n",    "\n",    "    if 'average_score' not in df.columns:\n",    "        available_scores = [c for c in score_columns if c in df.columns]\n",    "        df['average_score'] = df[available_scores].mean(axis=1)\n",    "\n",    "    df = df.dropna(subset=['average_score'])\n",    "\n",    "    y = df['average_score']\n",    "\n",    "    X_raw = df[required_features]\n",    "\n",    "    encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",    "    X_encoded = encoder.fit_transform(X_raw)\n",    "    feature_names = encoder.get_feature_names_out(required_features)\n",    "    X = pd.DataFrame(X_encoded, columns=feature_names)\n",    "\n",    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",    "\n",    "    model = RandomForestRegressor(\n",    "        n_estimators=100, \n",    "        max_depth=10,    \n",    "        min_samples_split=5,  \n",    "        random_state=42   \n",    "    )\n",    "    model.fit(X_train, y_train)\n",    "    y_pred = model.predict(X_test)\n",    "\n",    "    r2 = r2_score(y_test, y_pred)\n",    "    mse = mean_squared_error(y_test, y_pred)\n",    "\n",    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",    "    print(f\"üîπ R¬≤ Score (—Ç–µ—Å—Ç): {r2:.3f}\")\n",    "    print(f\"üîπ Mean Squared Error: {mse:.2f}\")\n",    "    print(f\"üîπ –ö—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—è R¬≤ (—Å–µ—Ä–µ–¥–Ω—î ¬± —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è): {cv_scores.mean():.3f} ¬± {cv_scores.std() * 2:.3f}\")\n",    "\n",    "    # –ì—Ä–∞—Ñ—ñ–∫\n",    "    plt.figure(figsize=(8, 6))\n",    "    plt.scatter(y_test, y_pred, alpha=0.6, color=\"blue\", label=\"–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ vs –†–µ–∞–ª—å–Ω—ñ\")\n",    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label=\"–Ü–¥–µ–∞–ª—å–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å\")\n",    "    plt.xlabel(\"–†–µ–∞–ª—å–Ω—ñ –æ—Ü—ñ–Ω–∫–∏\")\n",    "    plt.ylabel(\"–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ –æ—Ü—ñ–Ω–∫–∏\")\n",    "    plt.title(f\"–ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö –æ—Ü—ñ–Ω–æ–∫ {file} (Random Forest)\")\n",    "    plt.legend()\n",    "    graph_path = os.path.join(GRAPHS_FOLDER, f\"prediction_scatter_{file.replace('.csv','')}.png\")\n",    "    plt.savefig(graph_path, dpi=300, bbox_inches=\"tight\")\n",    "    plt.close()\n",    "\n",    "    print(f\"‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {graph_path}\")\n",    "\n",    "    feature_importance = pd.DataFrame({\n",    "        'feature': feature_names,\n",    "        'importance': model.feature_importances_\n",    "    }).sort_values('importance', ascending=False)\n",    "    print(\"\\nüîπ –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫:\")\n",    "    print(feature_importance)"   ],   "id": "39a26e8d41f018d3",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2020.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/2145906790.py:27: DtypeWarning: Columns (96,97,100,102,103,104,105,116,117,120,122,123,124,125) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score (—Ç–µ—Å—Ç): 0.165\n",      "üîπ Mean Squared Error: 445.13\n",      "üîπ –ö—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—è R¬≤ (—Å–µ—Ä–µ–¥–Ω—î ¬± —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è): 0.163 ¬± 0.006\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2020.png\n",      "\n",      "üîπ –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫:\n",      "                                              feature    importance\n",      "29             education_org_type_–∑–∞–∫–ª–∞–¥ –≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏  2.475990e-01\n",      "0                                 territory_type_—Å–µ–ª–æ  1.870304e-01\n",      "33                           education_org_type_–ª—ñ—Ü–µ–π  1.001866e-01\n",      "27                        education_org_type_–≥—ñ–º–Ω–∞–∑—ñ—è  8.647428e-02\n",      "43            education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞  6.808663e-02\n",      "49                                    gender_—á–æ–ª–æ–≤—ñ—á–∞  5.775765e-02\n",      "25         education_org_type_–≤–∏—â–µ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–µ —É—á–∏–ª–∏—â–µ  4.309927e-02\n",      "24                                 region_name_–º.–ö–∏—ó–≤  3.771475e-02\n",      "48                             education_org_type_nan  3.690146e-02\n",      "37  education_org_type_–ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π –ª—ñ—Ü–µ–π –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω...  3.678611e-02\n",      "11                      region_name_–õ—å–≤—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.645744e-02\n",      "35     education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å  1.575806e-02\n",      "38  education_org_type_–ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ-—Ç–µ—Ö–Ω—ñ—á–Ω–µ —É—á–∏–ª–∏—â–µ...  9.951300e-03\n",      "39   education_org_type_—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞  4.357580e-03\n",      "10                      region_name_–õ—É–≥–∞–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.703292e-03\n",      "23                   region_name_–ß–µ—Ä–Ω—ñ–≥—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.677223e-03\n",      "7                      region_name_–ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.649728e-03\n",      "6                    region_name_–ó–∞–∫–∞—Ä–ø–∞—Ç—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.595287e-03\n",      "17                  region_name_–¢–µ—Ä–Ω–æ–ø—ñ–ª—å—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.293218e-03\n",      "1                       region_name_–í–æ–ª–∏–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.263060e-03\n",      "5                     region_name_–ñ–∏—Ç–æ–º–∏—Ä—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.013434e-03\n",      "3                region_name_–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.011549e-03\n",      "18                     region_name_–•–∞—Ä–∫—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.792336e-03\n",      "16                        region_name_–°—É–º—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.686914e-03\n",      "20                    region_name_–•–º–µ–ª—å–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.678322e-03\n",      "4                        region_name_–î–æ–Ω–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.442556e-03\n",      "30                        education_org_type_–∫–æ–ª–µ–≥—ñ—É–º  1.383618e-03\n",      "14                     region_name_–ü–æ–ª—Ç–∞–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.280847e-03\n",      "19                     region_name_–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.193315e-03\n",      "12                   region_name_–ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.036127e-03\n",      "8                        region_name_–ö–∏—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.031664e-03\n",      "22                    region_name_–ß–µ—Ä–Ω—ñ–≤–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  8.845214e-04\n",      "21                      region_name_–ß–µ—Ä–∫–∞—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  8.024856e-04\n",      "13                        region_name_–û–¥–µ—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  7.772882e-04\n",      "9                  region_name_–ö—ñ—Ä–æ–≤–æ–≥—Ä–∞–¥—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  6.637037e-04\n",      "15                     region_name_–†—ñ–≤–Ω–µ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  6.334974e-04\n",      "34    education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–µ –æ–±'—î–¥–Ω–∞–Ω–Ω—è  5.401112e-04\n",      "2                       region_name_–í—ñ–Ω–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  4.363741e-04\n",      "46        education_org_type_—Ü–µ–Ω—Ç—Ä –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ—ó –æ—Å–≤—ñ—Ç–∏  2.307585e-04\n",      "28  education_org_type_–∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —Å–∞–Ω–∞—Ç–æ—Ä–Ω–∞ —à...  1.024321e-04\n",      "45  education_org_type_—Ü–µ–Ω—Ç—Ä –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ-—Ç–µ—Ö–Ω—ñ—á–Ω–æ—ó ...  2.271994e-05\n",      "40  education_org_type_—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ...  6.643562e-06\n",      "44   education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞-—ñ–Ω—Ç–µ—Ä–Ω–∞—Ç  6.467492e-06\n",      "36  education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-—Ä–µ–∞–±—ñ–ª—ñ—Ç–∞—Ü—ñ–π–Ω–∏–π —Ü...  6.116704e-08\n",      "32                           education_org_type_–∫–æ–ª–µ–∂  0.000000e+00\n",      "31                          education_org_type_–∫–æ–ª–µ–¥–∂  0.000000e+00\n",      "41  education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è ...  0.000000e+00\n",      "42  education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è ...  0.000000e+00\n",      "47  education_org_type_—Ü–µ–Ω—Ç—Ä –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∏ —ñ –ø–µ—Ä–µ–ø—ñ–¥–≥...  0.000000e+00\n",      "26  education_org_type_–≤–∏—â–µ —Ö—É–¥–æ–∂–Ω—î –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ-—Ç–µ—Ö...  0.000000e+00\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2021.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/2145906790.py:27: DtypeWarning: Columns (117,118,121,123,124,125,126,137,138,141,143,144,145,146) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score (—Ç–µ—Å—Ç): 0.150\n",      "üîπ Mean Squared Error: 460.99\n",      "üîπ –ö—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—è R¬≤ (—Å–µ—Ä–µ–¥–Ω—î ¬± —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è): 0.153 ¬± 0.007\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2021.png\n",      "\n",      "üîπ –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫:\n",      "                                              feature  importance\n",      "32                           education_org_type_–ª—ñ—Ü–µ–π    0.151861\n",      "26                        education_org_type_–≥—ñ–º–Ω–∞–∑—ñ—è    0.147621\n",      "1                         territory_type_—Å–µ–ª–∏—â–µ, —Å–µ–ª–æ    0.109799\n",      "38            education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞    0.108896\n",      "30  education_org_type_–∑–∞–∫–ª–∞–¥ —Ñ–∞—Ö–æ–≤–æ—ó –ø–µ—Ä–µ–¥–≤–∏—â–æ—ó –æ...    0.074058\n",      "39                             education_org_type_nan    0.065628\n",      "29  education_org_type_–∑–∞–∫–ª–∞–¥ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ—ó (–ø—Ä–æ—Ñ–µ—Å—ñ...    0.061861\n",      "28             education_org_type_–∑–∞–∫–ª–∞–¥ –≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏    0.061489\n",      "0                 territory_type_—Å–µ–ª–∏—â–µ –º—ñ—Å—å–∫–æ–≥–æ —Ç–∏–ø—É    0.039188\n",      "34     education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å    0.031354\n",      "25                                 region_name_–º.–ö–∏—ó–≤    0.030387\n",      "36   education_org_type_—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞    0.026362\n",      "40                                    gender_—á–æ–ª–æ–≤—ñ—á–∞    0.026227\n",      "12                      region_name_–õ—å–≤—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.025945\n",      "9                        region_name_–ö–∏—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.003555\n",      "8                      region_name_–ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002727\n",      "18                  region_name_–¢–µ—Ä–Ω–æ–ø—ñ–ª—å—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002476\n",      "11                      region_name_–õ—É–≥–∞–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002388\n",      "21                    region_name_–•–º–µ–ª—å–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002284\n",      "15                     region_name_–ü–æ–ª—Ç–∞–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002265\n",      "24                   region_name_–ß–µ—Ä–Ω—ñ–≥—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002154\n",      "7                    region_name_–ó–∞–∫–∞—Ä–ø–∞—Ç—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001923\n",      "4                region_name_–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001840\n",      "17                        region_name_–°—É–º—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001746\n",      "23                    region_name_–ß–µ—Ä–Ω—ñ–≤–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001713\n",      "19                     region_name_–•–∞—Ä–∫—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001679\n",      "16                     region_name_–†—ñ–≤–Ω–µ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001660\n",      "2                       region_name_–í–æ–ª–∏–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001566\n",      "20                     region_name_–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001268\n",      "31                  education_org_type_–∫–æ–ª–µ–≥—ñ—É–º/–∫–æ–ª–µ–∂    0.001256\n",      "13                   region_name_–ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001051\n",      "3                       region_name_–í—ñ–Ω–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001039\n",      "33    education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–µ –æ–±'—î–¥–Ω–∞–Ω–Ω—è    0.000977\n",      "6                     region_name_–ñ–∏—Ç–æ–º–∏—Ä—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.000840\n",      "5                        region_name_–î–æ–Ω–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.000816\n",      "10                 region_name_–ö—ñ—Ä–æ–≤–æ–≥—Ä–∞–¥—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.000716\n",      "14                        region_name_–û–¥–µ—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.000702\n",      "22                      region_name_–ß–µ—Ä–∫–∞—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.000655\n",      "27  education_org_type_–∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —Å–∞–Ω–∞—Ç–æ—Ä–Ω–∞ —à...    0.000029\n",      "35  education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-—Ä–µ–∞–±—ñ–ª—ñ—Ç–∞—Ü—ñ–π–Ω–∏–π —Ü...    0.000002\n",      "37  education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è ...    0.000000\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2023.csv\n",      "üîπ R¬≤ Score (—Ç–µ—Å—Ç): 0.160\n",      "üîπ Mean Squared Error: 202.03\n",      "üîπ –ö—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—è R¬≤ (—Å–µ—Ä–µ–¥–Ω—î ¬± —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è): 0.162 ¬± 0.004\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2023.png\n",      "\n",      "üîπ –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫:\n",      "                                              feature    importance\n",      "1                         territory_type_—Å–µ–ª–∏—â–µ, —Å–µ–ª–æ  2.000378e-01\n",      "34  education_org_type_–∑–∞–∫–ª–∞–¥ —Ñ–∞—Ö–æ–≤–æ—ó –ø–µ—Ä–µ–¥–≤–∏—â–æ—ó –æ...  1.729704e-01\n",      "33  education_org_type_–∑–∞–∫–ª–∞–¥ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ—ó (–ø—Ä–æ—Ñ–µ—Å—ñ...  1.568087e-01\n",      "49                             education_org_type_nan  1.365119e-01\n",      "14                      region_name_–õ—å–≤—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  5.636265e-02\n",      "0                 territory_type_—Å–µ–ª–∏—â–µ –º—ñ—Å—å–∫–æ–≥–æ —Ç–∏–ø—É  5.295687e-02\n",      "32             education_org_type_–∑–∞–∫–ª–∞–¥ –≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏  5.293562e-02\n",      "27                                 region_name_–º.–ö–∏—ó–≤  3.830454e-02\n",      "44   education_org_type_—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞  3.472610e-02\n",      "50                                    gender_—á–æ–ª–æ–≤—ñ—á–∞  3.088597e-02\n",      "42                  education_org_type_–Ω–∞—É–∫–æ–≤–∏–π –ª—ñ—Ü–µ–π  1.741108e-02\n",      "47            education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞  6.667517e-03\n",      "2                          territory_type_—ñ–Ω—à–∞ –∫—Ä–∞—ó–Ω–∞  5.659909e-03\n",      "30                        education_org_type_–≥—ñ–º–Ω–∞–∑—ñ—è  5.049460e-03\n",      "3                             region_name_–Ü–Ω—à—ñ –∫—Ä–∞—ó–Ω–∏  4.995515e-03\n",      "25                    region_name_–ß–µ—Ä–Ω—ñ–≤–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.730487e-03\n",      "20                  region_name_–¢–µ—Ä–Ω–æ–ø—ñ–ª—å—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.511063e-03\n",      "11                       region_name_–ö–∏—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.319907e-03\n",      "36                           education_org_type_–ª—ñ—Ü–µ–π  2.454514e-03\n",      "4                       region_name_–í–æ–ª–∏–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.272274e-03\n",      "6                region_name_–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.827038e-03\n",      "9                    region_name_–ó–∞–∫–∞—Ä–ø–∞—Ç—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.346614e-03\n",      "21                     region_name_–•–∞—Ä–∫—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.163145e-03\n",      "12                 region_name_–ö—ñ—Ä–æ–≤–æ–≥—Ä–∞–¥—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  9.536940e-04\n",      "5                       region_name_–í—ñ–Ω–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  9.383372e-04\n",      "31  education_org_type_–∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —Å–∞–Ω–∞—Ç–æ—Ä–Ω–∞ —à...  8.552679e-04\n",      "18                     region_name_–†—ñ–≤–Ω–µ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  8.474322e-04\n",      "40     education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å  7.425362e-04\n",      "23                    region_name_–•–º–µ–ª—å–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  7.194112e-04\n",      "17                     region_name_–ü–æ–ª—Ç–∞–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  6.588994e-04\n",      "24                      region_name_–ß–µ—Ä–∫–∞—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  5.809613e-04\n",      "16                        region_name_–û–¥–µ—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  4.545154e-04\n",      "8                     region_name_–ñ–∏—Ç–æ–º–∏—Ä—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.123170e-04\n",      "19                        region_name_–°—É–º—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.204964e-04\n",      "15                   region_name_–ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.125238e-04\n",      "43                 education_org_type_–ø–æ—á–∞—Ç–∫–æ–≤–∞ —à–∫–æ–ª–∞  1.410674e-04\n",      "48                education_org_type_—Å–ø–æ—Ä—Ç–∏–≤–Ω–∏–π –ª—ñ—Ü–µ–π  1.272219e-04\n",      "45  education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è ...  7.439112e-05\n",      "26                   region_name_–ß–µ—Ä–Ω—ñ–≥—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  7.294336e-05\n",      "10                     region_name_–ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  6.788959e-05\n",      "13                      region_name_–õ—É–≥–∞–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  4.637313e-05\n",      "22                     region_name_–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.148127e-05\n",      "39    education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–µ –æ–±'—î–¥–Ω–∞–Ω–Ω—è  2.091815e-05\n",      "7                        region_name_–î–æ–Ω–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.724299e-05\n",      "37  education_org_type_–ª—ñ—Ü–µ–π —ñ–∑ –ø–æ—Å–∏–ª–µ–Ω–æ—é –≤—ñ–π—Å—å–∫–æ–≤...  3.498269e-06\n",      "38                education_org_type_–º–∏—Å—Ç–µ—Ü—å–∫–∏–π –ª—ñ—Ü–µ–π  1.481741e-06\n",      "46                education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ —à–∫–æ–ª–∞  1.088066e-07\n",      "29  education_org_type_–≤—ñ–π—Å—å–∫–æ–≤–∏–π (–≤—ñ–π—Å—å–∫–æ–≤–æ-–º–æ—Ä—Å—å...  0.000000e+00\n",      "28          education_org_type_–≤–µ—á—ñ—Ä–Ω—è (–∑–º—ñ–Ω–Ω–∞) —à–∫–æ–ª–∞  0.000000e+00\n",      "35                  education_org_type_–∫–æ–ª–µ–≥—ñ—É–º/–∫–æ–ª–µ–∂  0.000000e+00\n",      "41  education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-—Ä–µ–∞–±—ñ–ª—ñ—Ç–∞—Ü—ñ–π–Ω–∏–π —Ü...  0.000000e+00\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2022.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/2145906790.py:27: DtypeWarning: Columns (8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score (—Ç–µ—Å—Ç): 0.155\n",      "üîπ Mean Squared Error: 214.11\n",      "üîπ –ö—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—è R¬≤ (—Å–µ—Ä–µ–¥–Ω—î ¬± —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è): 0.131 ¬± 0.029\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2022.png\n",      "\n",      "üîπ –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫:\n",      "                                              feature    importance\n",      "47                             education_org_type_nan  2.462740e-01\n",      "32  education_org_type_–∑–∞–∫–ª–∞–¥ —Ñ–∞—Ö–æ–≤–æ—ó –ø–µ—Ä–µ–¥–≤–∏—â–æ—ó –æ...  1.487559e-01\n",      "31  education_org_type_–∑–∞–∫–ª–∞–¥ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ—ó (–ø—Ä–æ—Ñ–µ—Å—ñ...  1.470918e-01\n",      "1                         territory_type_—Å–µ–ª–∏—â–µ, —Å–µ–ª–æ  1.225448e-01\n",      "42   education_org_type_—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞  5.954062e-02\n",      "30             education_org_type_–∑–∞–∫–ª–∞–¥ –≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏  5.616217e-02\n",      "12                      region_name_–õ—å–≤—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  5.575063e-02\n",      "0                 territory_type_—Å–µ–ª–∏—â–µ –º—ñ—Å—å–∫–æ–≥–æ —Ç–∏–ø—É  4.370548e-02\n",      "48                                    gender_—á–æ–ª–æ–≤—ñ—á–∞  4.059650e-02\n",      "25                                 region_name_–º.–ö–∏—ó–≤  2.511906e-02\n",      "45            education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞  1.166178e-02\n",      "28                        education_org_type_–≥—ñ–º–Ω–∞–∑—ñ—è  4.701150e-03\n",      "4                region_name_–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  4.594974e-03\n",      "16                     region_name_–†—ñ–≤–Ω–µ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  4.454672e-03\n",      "18                  region_name_–¢–µ—Ä–Ω–æ–ø—ñ–ª—å—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  4.339373e-03\n",      "2                       region_name_–í–æ–ª–∏–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.424297e-03\n",      "7                    region_name_–ó–∞–∫–∞—Ä–ø–∞—Ç—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.823850e-03\n",      "10                 region_name_–ö—ñ—Ä–æ–≤–æ–≥—Ä–∞–¥—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.454326e-03\n",      "3                       region_name_–í—ñ–Ω–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.227418e-03\n",      "6                     region_name_–ñ–∏—Ç–æ–º–∏—Ä—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.047404e-03\n",      "34                           education_org_type_–ª—ñ—Ü–µ–π  1.929602e-03\n",      "23                    region_name_–ß–µ—Ä–Ω—ñ–≤–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.569696e-03\n",      "21                    region_name_–•–º–µ–ª—å–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.273371e-03\n",      "13                   region_name_–ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.029867e-03\n",      "22                      region_name_–ß–µ—Ä–∫–∞—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  7.869741e-04\n",      "38     education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å  6.919639e-04\n",      "8                      region_name_–ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  6.678768e-04\n",      "19                     region_name_–•–∞—Ä–∫—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  5.566959e-04\n",      "24                   region_name_–ß–µ—Ä–Ω—ñ–≥—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  5.056543e-04\n",      "20                     region_name_–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  4.883657e-04\n",      "14                        region_name_–û–¥–µ—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.578566e-04\n",      "26          education_org_type_–≤–µ—á—ñ—Ä–Ω—è (–∑–º—ñ–Ω–Ω–∞) —à–∫–æ–ª–∞  3.443084e-04\n",      "9                        region_name_–ö–∏—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.550545e-04\n",      "15                     region_name_–ü–æ–ª—Ç–∞–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.485185e-04\n",      "5                        region_name_–î–æ–Ω–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.448231e-04\n",      "17                        region_name_–°—É–º—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.363813e-04\n",      "35  education_org_type_–ª—ñ—Ü–µ–π —ñ–∑ –ø–æ—Å–∏–ª–µ–Ω–æ—é –≤—ñ–π—Å—å–∫–æ–≤...  2.048551e-04\n",      "29  education_org_type_–∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —Å–∞–Ω–∞—Ç–æ—Ä–Ω–∞ —à...  1.213144e-04\n",      "37    education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–µ –æ–±'—î–¥–Ω–∞–Ω–Ω—è  8.523601e-05\n",      "36                education_org_type_–º–∏—Å—Ç–µ—Ü—å–∫–∏–π –ª—ñ—Ü–µ–π  7.060011e-05\n",      "11                      region_name_–õ—É–≥–∞–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  5.993762e-05\n",      "43  education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è ...  4.625998e-07\n",      "33                  education_org_type_–∫–æ–ª–µ–≥—ñ—É–º/–∫–æ–ª–µ–∂  3.842879e-07\n",      "27  education_org_type_–≤—ñ–π—Å—å–∫–æ–≤–∏–π (–≤—ñ–π—Å—å–∫–æ–≤–æ-–º–æ—Ä—Å—å...  0.000000e+00\n",      "39  education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-—Ä–µ–∞–±—ñ–ª—ñ—Ç–∞—Ü—ñ–π–Ω–∏–π —Ü...  0.000000e+00\n",      "40                  education_org_type_–Ω–∞—É–∫–æ–≤–∏–π –ª—ñ—Ü–µ–π  0.000000e+00\n",      "41  education_org_type_–ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π –∫–æ–ª–µ–¥–∂ (–∫–æ–ª–µ–¥–∂)...  0.000000e+00\n",      "44                education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ —à–∫–æ–ª–∞  0.000000e+00\n",      "46                education_org_type_—Å–ø–æ—Ä—Ç–∏–≤–Ω–∏–π –ª—ñ—Ü–µ–π  0.000000e+00\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2019.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/2145906790.py:27: DtypeWarning: Columns (100,116,117,120,122,123,124,125) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score (—Ç–µ—Å—Ç): 0.170\n",      "üîπ Mean Squared Error: 423.27\n",      "üîπ –ö—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—è R¬≤ (—Å–µ—Ä–µ–¥–Ω—î ¬± —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è): 0.169 ¬± 0.006\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2019.png\n",      "\n",      "üîπ –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫:\n",      "                                              feature  importance\n",      "0                                 territory_type_—Å–µ–ª–æ    0.271430\n",      "27                        education_org_type_–≥—ñ–º–Ω–∞–∑—ñ—è    0.125276\n",      "33                           education_org_type_–ª—ñ—Ü–µ–π    0.116772\n",      "43            education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞    0.095371\n",      "39   education_org_type_—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞    0.081669\n",      "35     education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å    0.057331\n",      "49                                    gender_—á–æ–ª–æ–≤—ñ—á–∞    0.053375\n",      "11                      region_name_–õ—å–≤—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.041799\n",      "24                                 region_name_–º.–ö–∏—ó–≤    0.031830\n",      "30                        education_org_type_–∫–æ–ª–µ–≥—ñ—É–º    0.019651\n",      "25         education_org_type_–≤–∏—â–µ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–µ —É—á–∏–ª–∏—â–µ    0.015247\n",      "37  education_org_type_–ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π –ª—ñ—Ü–µ–π –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω...    0.013800\n",      "7                      region_name_–ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.009880\n",      "6                    region_name_–ó–∞–∫–∞—Ä–ø–∞—Ç—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.008111\n",      "23                   region_name_–ß–µ—Ä–Ω—ñ–≥—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.006423\n",      "34    education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–µ –æ–±'—î–¥–Ω–∞–Ω–Ω—è    0.004837\n",      "44   education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞-—ñ–Ω—Ç–µ—Ä–Ω–∞—Ç    0.004249\n",      "19                     region_name_–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.003709\n",      "48                             education_org_type_nan    0.003594\n",      "1                       region_name_–í–æ–ª–∏–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.003243\n",      "17                  region_name_–¢–µ—Ä–Ω–æ–ø—ñ–ª—å—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.003112\n",      "2                       region_name_–í—ñ–Ω–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.003110\n",      "5                     region_name_–ñ–∏—Ç–æ–º–∏—Ä—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002908\n",      "3                region_name_–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002908\n",      "21                      region_name_–ß–µ—Ä–∫–∞—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002810\n",      "10                      region_name_–õ—É–≥–∞–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002328\n",      "14                     region_name_–ü–æ–ª—Ç–∞–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002294\n",      "20                    region_name_–•–º–µ–ª—å–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.002044\n",      "16                        region_name_–°—É–º—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001862\n",      "9                  region_name_–ö—ñ—Ä–æ–≤–æ–≥—Ä–∞–¥—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001274\n",      "12                   region_name_–ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001209\n",      "15                     region_name_–†—ñ–≤–Ω–µ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001134\n",      "8                        region_name_–ö–∏—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001091\n",      "18                     region_name_–•–∞—Ä–∫—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.001089\n",      "22                    region_name_–ß–µ—Ä–Ω—ñ–≤–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.000909\n",      "29             education_org_type_–∑–∞–∫–ª–∞–¥ –≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏    0.000670\n",      "4                        region_name_–î–æ–Ω–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.000473\n",      "38  education_org_type_–ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ-—Ç–µ—Ö–Ω—ñ—á–Ω–µ —É—á–∏–ª–∏—â–µ...    0.000421\n",      "13                        region_name_–û–¥–µ—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å    0.000372\n",      "42  education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è ...    0.000208\n",      "40  education_org_type_—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ...    0.000085\n",      "28  education_org_type_–∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —Å–∞–Ω–∞—Ç–æ—Ä–Ω–∞ —à...    0.000071\n",      "45  education_org_type_—Ü–µ–Ω—Ç—Ä –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ-—Ç–µ—Ö–Ω—ñ—á–Ω–æ—ó ...    0.000018\n",      "36  education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-—Ä–µ–∞–±—ñ–ª—ñ—Ç–∞—Ü—ñ–π–Ω–∏–π —Ü...    0.000004\n",      "41  education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è ...    0.000000\n",      "32                           education_org_type_–∫–æ–ª–µ–∂    0.000000\n",      "46        education_org_type_—Ü–µ–Ω—Ç—Ä –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ—ó –æ—Å–≤—ñ—Ç–∏    0.000000\n",      "47  education_org_type_—Ü–µ–Ω—Ç—Ä –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∏ —ñ –ø–µ—Ä–µ–ø—ñ–¥–≥...    0.000000\n",      "26  education_org_type_–≤–∏—â–µ —Ö—É–¥–æ–∂–Ω—î –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ-—Ç–µ—Ö...    0.000000\n",      "31                          education_org_type_–∫–æ–ª–µ–¥–∂    0.000000\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2024.csv\n",      "üîπ R¬≤ Score (—Ç–µ—Å—Ç): 0.137\n",      "üîπ Mean Squared Error: 259.97\n",      "üîπ –ö—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—è R¬≤ (—Å–µ—Ä–µ–¥–Ω—î ¬± —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è): 0.140 ¬± 0.003\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2024.png\n",      "\n",      "üîπ –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫:\n",      "                                              feature    importance\n",      "49                             education_org_type_nan  2.431250e-01\n",      "0                         territory_type_—Å–µ–ª–∏—â–µ, —Å–µ–ª–æ  2.294053e-01\n",      "34  education_org_type_–∑–∞–∫–ª–∞–¥ —Ñ–∞—Ö–æ–≤–æ—ó –ø–µ—Ä–µ–¥–≤–∏—â–æ—ó –æ...  1.642281e-01\n",      "33  education_org_type_–∑–∞–∫–ª–∞–¥ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ—ó (–ø—Ä–æ—Ñ–µ—Å—ñ...  1.419600e-01\n",      "13                      region_name_–õ—å–≤—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  4.392647e-02\n",      "26                                 region_name_–º.–ö–∏—ó–≤  3.778468e-02\n",      "42                  education_org_type_–Ω–∞—É–∫–æ–≤–∏–π –ª—ñ—Ü–µ–π  2.281127e-02\n",      "32             education_org_type_–∑–∞–∫–ª–∞–¥ –≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏  2.175135e-02\n",      "44   education_org_type_—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞  2.077575e-02\n",      "36                           education_org_type_–ª—ñ—Ü–µ–π  9.642940e-03\n",      "50                                    gender_—á–æ–ª–æ–≤—ñ—á–∞  9.216326e-03\n",      "30                        education_org_type_–≥—ñ–º–Ω–∞–∑—ñ—è  8.325178e-03\n",      "37  education_org_type_–ª—ñ—Ü–µ–π —ñ–∑ –ø–æ—Å–∏–ª–µ–Ω–æ—é –≤—ñ–π—Å—å–∫–æ–≤...  6.563624e-03\n",      "1                          territory_type_—ñ–Ω—à–∞ –∫—Ä–∞—ó–Ω–∞  5.663780e-03\n",      "2                             region_name_–Ü–Ω—à—ñ –∫—Ä–∞—ó–Ω–∏  4.756917e-03\n",      "19                  region_name_–¢–µ—Ä–Ω–æ–ø—ñ–ª—å—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.996073e-03\n",      "3                       region_name_–í–æ–ª–∏–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.430984e-03\n",      "10                       region_name_–ö–∏—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.323049e-03\n",      "29  education_org_type_–≤—ñ–π—Å—å–∫–æ–≤–∏–π (–≤—ñ–π—Å—å–∫–æ–≤–æ-–º–æ—Ä—Å—å...  2.764738e-03\n",      "47            education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞  2.200635e-03\n",      "5                region_name_–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.001691e-03\n",      "15                        region_name_–û–¥–µ—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.001605e-03\n",      "8                    region_name_–ó–∞–∫–∞—Ä–ø–∞—Ç—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.944565e-03\n",      "17                     region_name_–†—ñ–≤–Ω–µ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  9.869253e-04\n",      "11                 region_name_–ö—ñ—Ä–æ–≤–æ–≥—Ä–∞–¥—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  7.955956e-04\n",      "20                     region_name_–•–∞—Ä–∫—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  7.388760e-04\n",      "9                      region_name_–ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  6.480597e-04\n",      "7                     region_name_–ñ–∏—Ç–æ–º–∏—Ä—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  6.445929e-04\n",      "4                       region_name_–í—ñ–Ω–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  5.878128e-04\n",      "48                education_org_type_—Å–ø–æ—Ä—Ç–∏–≤–Ω–∏–π –ª—ñ—Ü–µ–π  5.427092e-04\n",      "40     education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å  5.187371e-04\n",      "27          education_org_type_–≤–µ—á—ñ—Ä–Ω—è (–∑–º—ñ–Ω–Ω–∞) —à–∫–æ–ª–∞  4.854147e-04\n",      "14                   region_name_–ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  4.841387e-04\n",      "31  education_org_type_–∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —Å–∞–Ω–∞—Ç–æ—Ä–Ω–∞ —à...  3.745386e-04\n",      "16                     region_name_–ü–æ–ª—Ç–∞–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  3.541609e-04\n",      "25                   region_name_–ß–µ—Ä–Ω—ñ–≥—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.818592e-04\n",      "18                        region_name_–°—É–º—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.716971e-04\n",      "23                      region_name_–ß–µ—Ä–∫–∞—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.230469e-04\n",      "22                    region_name_–•–º–µ–ª—å–Ω–∏—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.779604e-04\n",      "21                     region_name_–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.218998e-04\n",      "6                        region_name_–î–æ–Ω–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  1.119802e-04\n",      "24                    region_name_–ß–µ—Ä–Ω—ñ–≤–µ—Ü—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  4.215138e-05\n",      "45  education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è ...  5.028620e-06\n",      "12                      region_name_–õ—É–≥–∞–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å  2.701061e-06\n",      "43                 education_org_type_–ø–æ—á–∞—Ç–∫–æ–≤–∞ —à–∫–æ–ª–∞  7.578504e-08\n",      "38                education_org_type_–º–∏—Å—Ç–µ—Ü—å–∫–∏–π –ª—ñ—Ü–µ–π  0.000000e+00\n",      "39    education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–µ –æ–±'—î–¥–Ω–∞–Ω–Ω—è  0.000000e+00\n",      "41  education_org_type_–Ω–∞–≤—á–∞–ª—å–Ω–æ-—Ä–µ–∞–±—ñ–ª—ñ—Ç–∞—Ü—ñ–π–Ω–∏–π —Ü...  0.000000e+00\n",      "35                  education_org_type_–∫–æ–ª–µ–≥—ñ—É–º/–∫–æ–ª–µ–∂  0.000000e+00\n",      "46                education_org_type_—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ —à–∫–æ–ª–∞  0.000000e+00\n",      "28  education_org_type_–≤–∏—â–∏–π –Ω–∞–≤—á–∞–ª—å–Ω–∏–π –∑–∞–∫–ª–∞–¥ III...  0.000000e+00\n"     ]    }   ],   "execution_count": 67  },  {   "metadata": {},   "cell_type": "code",   "outputs": [],   "execution_count": null,   "source": "",   "id": "94dd9e8609e690d5"  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}