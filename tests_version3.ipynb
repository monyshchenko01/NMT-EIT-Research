{ "cells": [  {   "metadata": {},   "cell_type": "markdown",   "source": [    "**–ù—É–ª—å–æ–≤–∞ –≥—ñ–ø–æ—Ç–µ–∑–∞ (H‚ÇÄ):**\n",    "–°–µ—Ä–µ–¥–Ω—ñ–π –±–∞–ª –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ —É —á–æ–ª–æ–≤—ñ–∫—ñ–≤ —ñ –∂—ñ–Ω–æ–∫ –Ω–µ –≤—ñ–¥—Ä—ñ–∑–Ω—è—î—Ç—å—Å—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ –∑–Ω–∞—á—É—â–æ.\n",    "\n",    "**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞ –≥—ñ–ø–æ—Ç–µ–∑–∞ (H‚ÇÅ):**\n",    "–°–µ—Ä–µ–¥–Ω—ñ–π –±–∞–ª –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ —É —á–æ–ª–æ–≤—ñ–∫—ñ–≤ —ñ –∂—ñ–Ω–æ–∫ –≤—ñ–¥—Ä—ñ–∑–Ω—è—î—Ç—å—Å—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ –∑–Ω–∞—á—É—â–æ."   ],   "id": "d833a390c38f5a10"  },  {   "cell_type": "code",   "id": "initial_id",   "metadata": {    "collapsed": true   },   "source": [    "def analyze_gender_math(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î —Ä—ñ–∑–Ω–∏—Ü—é –≤ –æ—Ü—ñ–Ω–∫–∞—Ö –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∑–∞ —Å—Ç–∞—Ç—Ç—é.\"\"\"\n",    "    required_cols = ['math_score_100', 'gender']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "\n",    "    df_math = df[df['math_score_100'].notna() & df['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])]\n",    "    male_scores = df_math[df_math['gender'] == '—á–æ–ª–æ–≤—ñ—á–∞']['math_score_100']\n",    "    female_scores = df_math[df_math['gender'] == '–∂—ñ–Ω–æ—á–∞']['math_score_100']\n",    "\n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(male_scores) >= 30 and len(female_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(male_scores, female_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(male_scores, female_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((male_scores.std() ** 2) + (female_scores.std() ** 2)) / 2)\n",    "        cohen_d = (male_scores.mean() - female_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'male_count': len(male_scores), 'female_count': len(female_scores),\n",    "            'male_avg': male_scores.mean(), 'female_avg': female_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05,'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: —á–æ–ª–æ–≤—ñ–∫—ñ–≤={len(male_scores)}, –∂—ñ–Ω–æ–∫={len(female_scores)}'\n",    "\n",    "    all_results.append(result)\n",    "    return male_scores, female_scores"   ],   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_gender_ukrainian(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î —Ä—ñ–∑–Ω–∏—Ü—é –≤ –æ—Ü—ñ–Ω–∫–∞—Ö –∑ —É–∫—Ä–∞—ó—Å—å–Ω–∫–æ—ó –∑–∞ —Å—Ç–∞—Ç—Ç—é.\"\"\"\n",    "    required_cols = ['ukrainian_score_100', 'gender']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_math = df[df['ukrainian_score_100'].notna() & df['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])]\n",    "    male_scores = df_math[df_math['gender'] == '—á–æ–ª–æ–≤—ñ—á–∞']['ukrainian_score_100']\n",    "    female_scores = df_math[df_math['gender'] == '–∂—ñ–Ω–æ—á–∞']['ukrainian_score_100']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(male_scores) >= 30 and len(female_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(male_scores, female_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(male_scores, female_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((male_scores.std() ** 2) + (female_scores.std() ** 2)) / 2)\n",    "        cohen_d = (male_scores.mean() - female_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'male_count': len(male_scores), 'female_count': len(female_scores),\n",    "            'male_avg': male_scores.mean(), 'female_avg': female_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: —á–æ–ª–æ–≤—ñ–∫—ñ–≤={len(male_scores)}, –∂—ñ–Ω–æ–∫={len(female_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return male_scores, female_scores"   ],   "id": "ed9bca1241bfdc2",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_gender_history(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î —Ä—ñ–∑–Ω–∏—Ü—é –≤ –æ—Ü—ñ–Ω–∫–∞—Ö –∑ —É–∫—Ä–∞—ó—Å—å–Ω–∫–æ—ó –∑–∞ —Å—Ç–∞—Ç—Ç—é.\"\"\"\n",    "    required_cols = ['history_score_100', 'gender']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_math = df[df['history_score_100'].notna() & df['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])]\n",    "    male_scores = df_math[df_math['gender'] == '—á–æ–ª–æ–≤—ñ—á–∞']['history_score_100']\n",    "    female_scores = df_math[df_math['gender'] == '–∂—ñ–Ω–æ—á–∞']['history_score_100']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(male_scores) >= 30 and len(female_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(male_scores, female_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(male_scores, female_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((male_scores.std() ** 2) + (female_scores.std() ** 2)) / 2)\n",    "        cohen_d = (male_scores.mean() - female_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'male_count': len(male_scores), 'female_count': len(female_scores),\n",    "            'male_avg': male_scores.mean(), 'female_avg': female_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: —á–æ–ª–æ–≤—ñ–∫—ñ–≤={len(male_scores)}, –∂—ñ–Ω–æ–∫={len(female_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return male_scores, female_scores"   ],   "id": "dc63dc7dc1286f67",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_gender_english(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î —Ä—ñ–∑–Ω–∏—Ü—é –≤ –æ—Ü—ñ–Ω–∫–∞—Ö –∑ —É–∫—Ä–∞—ó—Å—å–Ω–∫–æ—ó –∑–∞ —Å—Ç–∞—Ç—Ç—é.\"\"\"\n",    "    required_cols = ['english_score_100', 'gender']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_math = df[df['english_score_100'].notna() & df['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])]\n",    "    male_scores = df_math[df_math['gender'] == '—á–æ–ª–æ–≤—ñ—á–∞']['english_score_100']\n",    "    female_scores = df_math[df_math['gender'] == '–∂—ñ–Ω–æ—á–∞']['english_score_100']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(male_scores) >= 30 and len(female_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(male_scores, female_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(male_scores, female_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((male_scores.std() ** 2) + (female_scores.std() ** 2)) / 2)\n",    "        cohen_d = (male_scores.mean() - female_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'male_count': len(male_scores), 'female_count': len(female_scores),\n",    "            'male_avg': male_scores.mean(), 'female_avg': female_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: —á–æ–ª–æ–≤—ñ–∫—ñ–≤={len(male_scores)}, –∂—ñ–Ω–æ–∫={len(female_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return male_scores, female_scores"   ],   "id": "9200f81604f722db",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import seaborn as sns\n",    "import matplotlib.pyplot as plt\n",    "\n",    "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö\n",    "df_2020 = pd.read_csv('filtered_data/2020.csv')\n",    "df_2023 = pd.read_csv('filtered_data/2023.csv')\n",    "\n",    "# –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è: —Ç—ñ–ª—å–∫–∏ —Ç—ñ, —Ö—Ç–æ –º–∞—î –æ—Ü—ñ–Ω–∫—É –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ —ñ –∑–∞–∑–Ω–∞—á–µ–Ω–∏–π –≥–µ–Ω–¥–µ—Ä\n",    "df_2020_math = df_2020[df_2020['math_score_100'].notna() & df_2020['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])].copy()\n",    "df_2023_math = df_2023[df_2023['math_score_100'].notna() & df_2023['gender'].isin(['—á–æ–ª–æ–≤—ñ—á–∞', '–∂—ñ–Ω–æ—á–∞'])].copy()\n",    "\n",    "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤\n",    "plt.figure(figsize=(14, 6))\n",    "\n",    "# 2020\n",    "plt.subplot(1, 2, 1)\n",    "sns.histplot(\n",    "    data=df_2020_math,\n",    "    x='math_score_100',\n",    "    hue='gender',\n",    "    bins=50,\n",    "    element='step',\n",    "    stat='density',\n",    "    common_norm=False,\n",    "    palette='Set2'\n",    ")\n",    "plt.title('–†–æ–∑–ø–æ–¥—ñ–ª –±–∞–ª—ñ–≤ –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ (2020)')\n",    "plt.xlabel('–ë–∞–ª–∏')\n",    "plt.ylabel('–©—ñ–ª—å–Ω—ñ—Å—Ç—å')\n",    "\n",    "# 2023\n",    "plt.subplot(1, 2, 2)\n",    "sns.histplot(\n",    "    data=df_2023_math,\n",    "    x='math_score_100',\n",    "    hue='gender',\n",    "    bins=50,\n",    "    element='step',\n",    "    stat='density',\n",    "    common_norm=False,\n",    "    palette='Set2'\n",    ")\n",    "plt.title('–†–æ–∑–ø–æ–¥—ñ–ª –±–∞–ª—ñ–≤ –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ (2023)')\n",    "plt.xlabel('–ë–∞–ª–∏')\n",    "plt.ylabel('–©—ñ–ª—å–Ω—ñ—Å—Ç—å')\n",    "\n",    "# –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è\n",    "plt.tight_layout()\n",    "plt.show()\n"   ],   "id": "4ad9670f513f77bb",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "from scipy.stats import ttest_ind, mannwhitneyu\n",    "def analyze_abroad_results(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ü–æ—Ä—ñ–≤–Ω—é—î –æ—Ü—ñ–Ω–∫–∏ –∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∑–∞ –∫–æ—Ä–¥–æ–Ω–æ–º —ñ –≤ –£–∫—Ä–∞—ó–Ω—ñ (–ª–∏—à–µ –¥–ª—è –ù–ú–¢).\"\"\"\n",    "    if dataset_type != 'NMT':\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    required_cols = ['math_score_100', 'region_flag']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_scores = df[df['average_score'].notna() & df['region_flag'].notna()]\n",    "    df_scores['location'] = np.where(df_scores['region_flag'] == 'other', '–ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º', '–£–∫—Ä–∞—ó–Ω–∞')\n",    "\n",    "    abroad_scores = df_scores[df_scores['location'] == '–ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º']['average_score']\n",    "    ukraine_scores = df_scores[df_scores['location'] == '–£–∫—Ä–∞—ó–Ω–∞']['average_score']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(abroad_scores) >= 30 and len(ukraine_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(abroad_scores, ukraine_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(abroad_scores, ukraine_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((abroad_scores.std() ** 2) + (ukraine_scores.std() ** 2)) / 2)\n",    "        cohen_d = (abroad_scores.mean() - ukraine_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'abroad_count': len(abroad_scores), 'ukraine_count': len(ukraine_scores),\n",    "            'abroad_avg': abroad_scores.mean(), 'ukraine_avg': ukraine_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: –∑–∞ –∫–æ—Ä–¥–æ–Ω–æ–º={len(abroad_scores)}, –£–∫—Ä–∞—ó–Ω–∞={len(ukraine_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return abroad_scores, ukraine_scores"   ],   "id": "6d63d1bd06b88360",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "# –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞\n",    "import pandas as pd\n",    "df = pd.read_csv(\"filtered_data/2023.csv\", low_memory=False)\n",    "df_foreign = df[df['region_name'].str.contains(\"–Ü–Ω—à—ñ –∫—Ä–∞—ó–Ω–∏\", case=False, na=False)]\n",    "print(df_foreign)\n",    "df_foreign.to_csv(\"results/2023_foreign_testers.csv\", index=False, encoding='utf-8')"   ],   "id": "1e46dfbf65ea610f",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "# from scipy.stats import spearmanr\n",    "# import pandas as pd\n",    "# import seaborn as sns\n",    "# import matplotlib.pyplot as plt\n",    "# import os\n",    "# \n",    "# def analyze_subject_correlation(df, dataset_type, filename, all_results):\n",    "#     \"\"\"–ê–Ω–∞–ª—ñ–∑—É—î –∫–æ—Ä–µ–ª—è—Ü—ñ—é –º—ñ–∂ –ø—Ä–µ–¥–º–µ—Ç–∞–º–∏, –æ–∫—Ä–µ–º–æ –¥–ª—è 2022 —ñ —ñ–Ω—à–∏—Ö —Ä–æ–∫—ñ–≤.\"\"\"\n",    "# \n",    "#     all_subjects = [\n",    "#         'ukrainian_score_100', 'math_score_100',\n",    "#         'biology_score_100', 'chemistry_score_100', 'physics_score_100',\n",    "#         'english_score_100', 'geography_score_100', 'ukrainian_literature_score_100',\n",    "#         'history_score_100', 'french_score_100', 'german_score_100', 'spanish_score_100'\n",    "#     ]\n",    "# \n",    "#     nmt_2022_subjects = ['ukrainian_score_100', 'math_score_100', 'history_score_100']\n",    "#     \n",    "#     if '2022' in filename and dataset_type == 'NMT':\n",    "#         subjects = nmt_2022_subjects\n",    "#     else:\n",    "#         subjects = all_subjects\n",    "#     \n",    "# \n",    "#     available_subjects = [s for s in subjects if s in df.columns]\n",    "#     print(f\"–î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ —É {filename}: {df.columns.tolist()}\")\n",    "#     print(f\"–ó–Ω–∞–π–¥–µ–Ω—ñ –ø—Ä–µ–¥–º–µ—Ç–∏: {available_subjects}\")\n",    "#     print(f\"–¢–∏–ø–∏ –¥–∞–Ω–∏—Ö: {df[available_subjects].dtypes}\")\n",    "#     \n",    "#     if len(available_subjects) < 2:\n",    "#         print(f\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ –¥–ª—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —É {filename}: {available_subjects}\")\n",    "#         result = {'file': filename, 'dataset_type': dataset_type, 'error': '–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –ø—Ä–µ–¥–º–µ—Ç—ñ–≤'}\n",    "#         all_results.append(result)\n",    "#         return pd.DataFrame()\n",    "#     \n",    "#     result = {'file': filename, 'dataset_type': dataset_type}\n",    "#     \n",    "#     corr_matrix = df[available_subjects].corr(method='spearman').round(2)\n",    "#     if len(df[available_subjects].dropna(how='all')) >= 30:\n",    "#         for i, s1 in enumerate(available_subjects):\n",    "#             for s2 in available_subjects[i+1:]:\n",    "#                 valid_data = df[[s1, s2]].dropna()\n",    "#                 if len(valid_data) >= 10:  \n",    "#                     corr, pval = spearmanr(valid_data[s1], valid_data[s2])\n",    "#                     result[f'{s1.replace(\"_score_100\", \"\")}_{s2.replace(\"_score_100\", \"\")}_corr'] = corr\n",    "#                     result[f'{s1.replace(\"_score_100\", \"\")}_{s2.replace(\"_score_100\", \"\")}_pval'] = pval\n",    "#                 else:\n",    "#                     result[f'{s1.replace(\"_score_100\", \"\")}_{s2.replace(\"_score_100\", \"\")}_corr'] = None\n",    "#                     result[f'{s1.replace(\"_score_100\", \"\")}_{s2.replace(\"_score_100\", \"\")}_pval'] = None\n",    "#         result['corr_matrix'] = corr_matrix\n",    "#         \n",    "#         # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–µ–ø–ª–æ–≤–æ—ó –∫–∞—Ä—Ç–∏\n",    "#         plt.figure(figsize=(10, 8))\n",    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",    "#         plt.title(f'–ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è ({dataset_type}, {filename})')\n",    "#         plt.savefig(os.path.join('results/graphs', f'corr_matrix_{filename}.png'), dpi=300)\n",    "#         plt.close()\n",    "#     else:\n",    "#         result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: {len(df[available_subjects].dropna(how=\"all\"))} –∑–∞–ø–∏—Å—ñ–≤'\n",    "#     \n",    "#     all_results.append(result)\n",    "#     return df[available_subjects]"   ],   "id": "e74124edcc9ef533",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "# def analyze_additional_subjects(df, dataset_type, filename, all_results):\n",    "#     \"\"\"–í–∏–∑–Ω–∞—á–∞—î —á–∞—Å—Ç–æ—Ç—É –≤–∏–±–æ—Ä—É –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –ø—Ä–µ–¥–º–µ—Ç—ñ–≤.\"\"\"\n",    "#     subjects = [\n",    "#         'biology_score_100', 'chemistry_score_100', 'physics_score_100',\n",    "#         'english_score_100', 'geography_score_100', 'ukrainian_literature_score_100',\n",    "#         'history_score_100', 'french_score_100', 'german_score_100', 'spanish_score_100',\n",    "#     ]\n",    "#     counts = {}\n",    "#     for subject in subjects:\n",    "#         if subject in df.columns:\n",    "#             counts[subject.replace('_score_100', '')] = df[subject].notna().sum()\n",    "#     \n",    "#     result = {'file': filename, 'dataset_type': dataset_type, **counts}\n",    "#     all_results.append(result)\n",    "#     return counts"   ],   "id": "ac139e29b8764ce0",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def analyze_age_groups(df, dataset_type, filename, all_results):\n",    "    \"\"\"–ü–æ—Ä—ñ–≤–Ω—é—î –æ—Ü—ñ–Ω–∫–∏ –∑ average_score –∑–∞ –≤—ñ–∫–æ–º (17/18).\"\"\"\n",    "    required_cols = ['average_score', 'student_age']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "        return pd.Series(), pd.Series()\n",    "    \n",    "    df_age = df[df['average_score'].notna() & df['student_age'].isin([17, 18])]\n",    "    age_17_scores = df_age[df_age['student_age'] == 17]['average_score']\n",    "    age_18_scores = df_age[df_age['student_age'] == 18]['average_score']\n",    "    \n",    "    result = {'file': filename, 'dataset_type': dataset_type}\n",    "    if len(age_17_scores) >= 30 and len(age_18_scores) >= 30:\n",    "        t_stat, p_value = ttest_ind(age_17_scores, age_18_scores, equal_var=False, nan_policy='omit')\n",    "        u_stat, u_pval = mannwhitneyu(age_17_scores, age_18_scores, alternative='two-sided')\n",    "        pooled_std = np.sqrt(((age_17_scores.std() ** 2) + (age_18_scores.std() ** 2)) / 2)\n",    "        cohen_d = (age_17_scores.mean() - age_18_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "        result.update({\n",    "            'age_17_count': len(age_17_scores), 'age_18_count': len(age_18_scores),\n",    "            'age_17_avg': age_17_scores.mean(), 'age_18_avg': age_18_scores.mean(),\n",    "            't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "            'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "        })\n",    "    else:\n",    "        result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: 17={len(age_17_scores)}, 18={len(age_18_scores)}'\n",    "    \n",    "    all_results.append(result)\n",    "    return age_17_scores, age_18_scores"   ],   "id": "beeaac2b5d68e837",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "# def analyze_age_group(df, dataset_type, filename, all_results):\n",    "#     \"\"\"–ü–æ—Ä—ñ–≤–Ω—é—î –æ—Ü—ñ–Ω–∫–∏ –∑ average_score –∑–∞ –≤—ñ–∫–æ–º (17/18).\"\"\"\n",    "#     required_cols = ['average_score', 'student_age']\n",    "#     if not all(col in df.columns for col in required_cols):\n",    "#         print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {required_cols} —É {filename}\")\n",    "#         return pd.Series(), pd.Series()\n",    "#     \n",    "#     df_age = df[df['average_score'].notna() & df['student_age'].isin([16, 19])]\n",    "#     age_16_scores = df_age[df_age['student_age'] == 16]['average_score']\n",    "#     age_17_scores = df_age[df_age['student_age'] == 19]['average_score']\n",    "#     \n",    "#     result = {'file': filename, 'dataset_type': dataset_type}\n",    "#     if len(age_16_scores) >= 30 and len(age_17_scores) >= 30:\n",    "#         t_stat, p_value = ttest_ind(age_16_scores, age_17_scores, equal_var=False, nan_policy='omit')\n",    "#         u_stat, u_pval = mannwhitneyu(age_16_scores, age_17_scores, alternative='two-sided')\n",    "#         pooled_std = np.sqrt(((age_16_scores.std() ** 2) + (age_17_scores.std() ** 2)) / 2)\n",    "#         cohen_d = (age_16_scores.mean() - age_17_scores.mean()) / pooled_std if pooled_std > 0 else np.nan\n",    "#         result.update({\n",    "#             'age_17_count': len(age_16_scores), 'age_18_count': len(age_17_scores),\n",    "#             'age_17_avg': age_16_scores.mean(), 'age_18_avg': age_17_scores.mean(),\n",    "#             't_stat': t_stat, 'p_value': p_value, 'significant': p_value < 0.05, 'u_stat': u_stat,\n",    "#             'u_pval': u_pval, 'u_significant': u_pval < 0.05, 'cohen_d': cohen_d\n",    "#         })\n",    "#     else:\n",    "#         result['error'] = f'–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: 17={len(age_16_scores)}, 18={len(age_17_scores)}'\n",    "#     \n",    "#     all_results.append(result)\n",    "#     return age_16_scores, age_17_scores"   ],   "id": "1731e635801443ae",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "import os\n",    "import pandas as pd\n",    "import numpy as np\n",    "from scipy.stats import ttest_ind, mannwhitneyu\n",    "import chardet\n",    "import re\n",    "import csv\n",    "import matplotlib.pyplot as plt\n",    "import seaborn as sns\n",    "from pathlib import Path\n",    "\n",    "# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–∞–ø–æ–∫\n",    "INPUT_FOLDER = \"filtered_data\"\n",    "RESULTS_FOLDER = \"results\"\n",    "GRAPHS_FOLDER = os.path.join(RESULTS_FOLDER, \"graphs\")\n",    "for folder in [RESULTS_FOLDER, GRAPHS_FOLDER]:\n",    "    os.makedirs(folder, exist_ok=True)\n",    "\n",    "sns.set_style(\"whitegrid\")\n",    "\n",    "def detect_encoding(file_path):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î –∫–æ–¥—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—É.\"\"\"\n",    "    try:\n",    "        with open(file_path, 'rb') as f:\n",    "            return chardet.detect(f.read(10000))['encoding'] or 'utf-8'\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–æ–¥—É–≤–∞–Ω–Ω—è –¥–ª—è {file_path}: {e}\")\n",    "        return 'utf-8'\n",    "\n",    "def detect_separator(file_path, encoding):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫ —É CSV-—Ñ–∞–π–ª—ñ.\"\"\"\n",    "    try:\n",    "        with open(file_path, encoding=encoding) as f:\n",    "            sample = f.read(2048)\n",    "            return csv.Sniffer().sniff(sample).delimiter\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫–∞ –¥–ª—è {file_path}: {e}\")\n",    "        return ','\n",    "\n",    "def load_csv(file_path):\n",    "    \"\"\"–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î CSV-—Ñ–∞–π–ª.\"\"\"\n",    "    encoding = detect_encoding(file_path)\n",    "    sep = detect_separator(file_path, encoding)\n",    "    print(f\"   –ö–æ–¥—É–≤–∞–Ω–Ω—è: {encoding}, —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫: '{sep}'\")\n",    "    \n",    "    try:\n",    "        df = pd.read_csv(file_path, encoding=encoding, sep=sep, quotechar='\"', on_bad_lines='skip')\n",    "        print(f\"   –ü–µ—Ä—à—ñ 5 –∫–æ–ª–æ–Ω–æ–∫: {list(df.columns[:5])}\")\n",    "        return df\n",    "    except Exception as e:\n",    "        print(f\"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è {file_path}: {e}\")\n",    "        return None\n",    "\n",    "def detect_dataset_type(filename):\n",    "    \"\"\"–í–∏–∑–Ω–∞—á–∞—î —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç—É –∑–∞ –Ω–∞–∑–≤–æ—é —Ñ–∞–π–ª—É.\"\"\"\n",    "    match = re.search(r'(\\d{4})', filename)\n",    "    if match:\n",    "        year = int(match.group(1))\n",    "        return 'NMT' if year >= 2022 else 'ZNO'\n",    "    return None\n",    "\n",    "# –ó–±—ñ—Ä –¥–∞–Ω–∏—Ö\n",    "all_gender_results = []\n",    "all_gender_results2 = []\n",    "all_gender_results3 = []\n",    "all_gender_results4 = []\n",    "all_abroad_results = []\n",    "all_correlation_results = []\n",    "all_subjects_results = []\n",    "all_age_results = []\n",    "\n",    "age_results = []\n",    "\n",    "\n",    "for filename in os.listdir(INPUT_FOLDER):\n",    "    if not filename.endswith(\".csv\"):\n",    "        continue\n",    "    \n",    "    path = os.path.join(INPUT_FOLDER, filename)\n",    "    print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename}...\")\n",    "    \n",    "    try:\n",    "        df = load_csv(path)\n",    "        if df is None or df.empty:\n",    "            print(f\"‚ö†Ô∏è –§–∞–π–ª {filename} –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏\")\n",    "            continue\n",    "        \n",    "        dataset_type = detect_dataset_type(filename)\n",    "        if not dataset_type:\n",    "            print(f\"‚ö†Ô∏è –ù–µ–≤—ñ–¥–æ–º–∏–π —Ç–∏–ø –¥–∞–Ω–∏—Ö: {filename}\")\n",    "            continue\n",    "        \n",    "        print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "        \n",    "        gender_male, gender_female = analyze_gender_math(df, dataset_type, filename, all_gender_results)\n",    "        gender_male2, gender_female2 = analyze_gender_ukrainian(df, dataset_type, filename, all_gender_results2)\n",    "        gender_male3, gender_female3 = analyze_gender_history(df, dataset_type, filename, all_gender_results3)\n",    "        gender_male4, gender_female4 = analyze_gender_english(df, dataset_type, filename, all_gender_results4)\n",    "        abroad_abroad, abroad_ukraine = analyze_abroad_results(df, dataset_type, filename, all_abroad_results)\n",    "        # subjects_df = analyze_subject_correlation(df, dataset_type, filename, all_correlation_results)\n",    "        # subjects_counts = analyze_additional_subjects(df, dataset_type, filename, all_subjects_results)\n",    "        age_17, age_18 = analyze_age_groups(df, dataset_type, filename, all_age_results)\n",    "        # age_16, age2_17 = analyze_age_group(df, dataset_type, filename, age_results)\n",    "      \n",    "    except Exception as e:\n",    "        print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "        import traceback\n",    "        traceback.print_exc()\n",    "\n",    "# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ —Ä–æ–∫–∞—Ö\n",    "pd.DataFrame(all_gender_results).to_csv(os.path.join(RESULTS_FOLDER, 'gender_math_analysis.csv'), index=False)\n",    "pd.DataFrame(all_gender_results2).to_csv(os.path.join(RESULTS_FOLDER, 'gender_ukrainian_analysis.csv'), index=False)\n",    "pd.DataFrame(all_gender_results3).to_csv(os.path.join(RESULTS_FOLDER, 'gender_history_analysis.csv'), index=False)\n",    "pd.DataFrame(all_gender_results4).to_csv(os.path.join(RESULTS_FOLDER, 'gender_english_analysis.csv'), index=False)\n",    "pd.DataFrame(all_abroad_results).to_csv(os.path.join(RESULTS_FOLDER, 'abroad_results_analysis.csv'), index=False)\n",    "# pd.DataFrame(all_correlation_results).to_csv(os.path.join(RESULTS_FOLDER, 'subject_correlation_analysis.csv'), index=False)\n",    "# pd.DataFrame(all_subjects_results).to_csv(os.path.join(RESULTS_FOLDER, 'additional_subjects_analysis.csv'), index=False)\n",    "pd.DataFrame(all_age_results).to_csv(os.path.join(RESULTS_FOLDER, 'age_groups_analysis.csv'), index=False)\n",    "# pd.DataFrame(age_results).to_csv(os.path.join(RESULTS_FOLDER, 'age_group(16, 17)_analysis.csv'), index=False)\n",    "print(f\"\\nüéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{RESULTS_FOLDER}'\")"   ],   "id": "c5a6be50dbd063b8",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "print(\"\\nüîÑ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤...\")\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 1: –ì–µ–Ω–¥–µ—Ä (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_gender_results:\n",    "    if 'male_avg' in result and 'female_avg' in result:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.bar(['–ß–æ–ª–æ–≤—ñ–∫–∏', '–ñ—ñ–Ω–∫–∏'], [result['male_avg'], result['female_avg']],\n",    "                color=['#36A2EB', '#FF6384'], edgecolor=['#2E8B57', '#C71585'])\n",    "        plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ —Å—Ç–∞—Ç—Ç—é ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'gender_math_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 2: –ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º (–ø–æ —Ä–æ–∫–∞—Ö, –ª–∏—à–µ –ù–ú–¢)\n",    "for result in all_abroad_results:\n",    "    if 'abroad_avg' in result and 'ukraine_avg' in result:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.bar(['–ó–∞ –∫–æ—Ä–¥–æ–Ω–æ–º', '–£–∫—Ä–∞—ó–Ω–∞'], [result['abroad_avg'], result['ukraine_avg']],\n",    "                color=['#FFCE56', '#4BC0C0'], edgecolor=['#FFD700', '#20B2AA'])\n",    "        plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ –º—ñ—Å—Ü–µ–º —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è (–ù–ú–¢, {result[\"file\"]})')\n",    "        plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'abroad_results_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 3: –ö–æ—Ä–µ–ª—è—Ü—ñ—è (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_correlation_results:\n",    "    if 'corr_matrix' in result:\n",    "        corr_matrix = result['corr_matrix']\n",    "        subjects = [s.replace('_score_100', '') for s in corr_matrix.columns]\n",    "        plt.figure(figsize=(10, 8))\n",    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",    "                    xticklabels=subjects, yticklabels=subjects)\n",    "        plt.title(f'–ö–æ—Ä–µ–ª—è—Ü—ñ—è –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'subject_correlation_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 4: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø—Ä–µ–¥–º–µ—Ç–∏ (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_subjects_results:\n",    "    counts = {k: v for k, v in result.items() if k not in ['file', 'dataset_type'] and isinstance(v, (int, float)) and v > 0}\n",    "    if counts:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.pie(list(counts.values()), labels=list(counts.keys()), colors=sns.color_palette('pastel'),\n",    "                autopct='%1.1f%%')\n",    "        plt.title(f'–ü–æ–ø—É–ª—è—Ä–Ω—ñ—Å—Ç—å –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'additional_subjects_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "    else:\n",    "        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –≥—Ä–∞—Ñ—ñ–∫ –¥–ª—è {result['file']}: –Ω–µ–º–∞—î –∫–æ—Ä–µ–∫—Ç–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ ({counts})\")\n",    "\n",    "# –ü–∏—Ç–∞–Ω–Ω—è 5: –í—ñ–∫–æ–≤—ñ –≥—Ä—É–ø–∏ (–ø–æ —Ä–æ–∫–∞—Ö)\n",    "for result in all_age_results:\n",    "    if 'age_17_avg' in result and 'age_18_avg' in result:\n",    "        plt.figure(figsize=(8, 6))\n",    "        plt.bar(['17 —Ä–æ–∫—ñ–≤', '18 —Ä–æ–∫—ñ–≤'], [result['age_17_avg'], result['age_18_avg']],\n",    "                color=['#FF6384', '#36A2EB'], edgecolor=['#DC143C', '#1E90FF'])\n",    "        plt.title(f'–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ –≤—ñ–∫–æ–º ({result[\"dataset_type\"]}, {result[\"file\"]})')\n",    "        plt.ylabel('–°–µ—Ä–µ–¥–Ω—è –æ—Ü—ñ–Ω–∫–∞ (0-200)')\n",    "        plt.savefig(os.path.join(GRAPHS_FOLDER, f'age_groups_{result[\"file\"]}.png'), dpi=300, bbox_inches='tight')\n",    "        plt.close()\n",    "\n",    "print(f\"\\nüéâ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ì—Ä–∞—Ñ—ñ–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{GRAPHS_FOLDER}'\")"   ],   "id": "edaa416af057e110",   "outputs": [],   "execution_count": null  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-07-01T07:52:21.623354Z",     "start_time": "2025-07-01T07:51:42.192705Z"    }   },   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import numpy as np\n",    "import os\n",    "from sklearn.model_selection import train_test_split\n",    "from sklearn.linear_model import LinearRegression\n",    "from sklearn.preprocessing import OneHotEncoder\n",    "from sklearn.metrics import r2_score, mean_squared_error\n",    "import matplotlib.pyplot as plt\n",    "\n",    "# –ü–∞–ø–∫–∏\n",    "DATA_FOLDER = \"filtered_data\"\n",    "GRAPHS_FOLDER = \"results/graphs\"\n",    "os.makedirs(GRAPHS_FOLDER, exist_ok=True)\n",    "\n",    "# –ü–µ—Ä–µ–ª—ñ–∫ —Ñ–∞–π–ª—ñ–≤ CSV\n",    "csv_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(\".csv\")]\n",    "\n",    "# –ü–µ—Ä–µ–ª—ñ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ—Ü—ñ–Ω–æ–∫\n",    "score_columns = ['math_score_100', 'ukrainian_score_100', 'history_score_100']\n",    "\n",    "# –ü—Ä–æ—Ö–æ–¥–∏–º–æ –≤—Å—ñ —Ñ–∞–π–ª–∏\n",    "for file in csv_files:\n",    "    path = os.path.join(DATA_FOLDER, file)\n",    "    print(f\"\\nüìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: {file}\")\n",    "\n",    "    # –ß–∏—Ç–∞–Ω–Ω—è CSV\n",    "    df = pd.read_csv(path)\n",    "\n",    "    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞, —á–∏ —î –ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏\n",    "    required_features = ['territory_type', 'region_name', 'education_org_type', 'gender']\n",    "    missing_features = [c for c in required_features if c not in df.columns]\n",    "    missing_scores = [c for c in score_columns if c not in df.columns]\n",    "\n",    "    if missing_features:\n",    "        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª {file}, –±–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {missing_features}\")\n",    "        continue\n",    "\n",    "    if len(missing_scores) == len(score_columns):\n",    "        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª {file}, –±–æ –Ω–µ–º–∞—î –∂–æ–¥–Ω–æ—ó –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ü—ñ–Ω–æ–∫\")\n",    "        continue\n",    "\n",    "    # –û–±—á–∏—Å–ª—é—î–º–æ —Å–µ—Ä–µ–¥–Ω—é –æ—Ü—ñ–Ω–∫—É, —è–∫—â–æ average_score –≤—ñ–¥—Å—É—Ç–Ω—è\n",    "    if 'average_score' not in df.columns:\n",    "        available_scores = [c for c in score_columns if c in df.columns]\n",    "        df['average_score'] = df[available_scores].mean(axis=1)\n",    "\n",    "    # –í–∏–¥–∞–ª—è—î–º–æ —Ä—è–¥–∫–∏ –±–µ–∑ —Å–µ—Ä–µ–¥–Ω—å–æ—ó –æ—Ü—ñ–Ω–∫–∏\n",    "    df = df.dropna(subset=['average_score'])\n",    "\n",    "    # –¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞\n",    "    y = df['average_score']\n",    "\n",    "    # –û–∑–Ω–∞–∫–∏\n",    "    X_raw = df[required_features]\n",    "\n",    "    # One-hot encoding\n",    "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",    "    X_encoded = encoder.fit_transform(X_raw)\n",    "    feature_names = encoder.get_feature_names_out(required_features)\n",    "    X = pd.DataFrame(X_encoded, columns=feature_names)\n",    "\n",    "    # –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train/test\n",    "    X_train, X_test, y_train, y_test = train_test_split(\n",    "        X, y, test_size=0.2, random_state=42\n",    "    )\n",    "\n",    "    # –ú–æ–¥–µ–ª—å\n",    "    model = LinearRegression()\n",    "    model.fit(X_train, y_train)\n",    "    y_pred = model.predict(X_test)\n",    "\n",    "    # –ú–µ—Ç—Ä–∏–∫–∏\n",    "    r2 = r2_score(y_test, y_pred)\n",    "    mse = mean_squared_error(y_test, y_pred)\n",    "\n",    "    print(f\"üîπ R¬≤ Score: {r2:.3f}\")\n",    "    print(f\"üîπ Mean Squared Error: {mse:.2f}\")\n",    "\n",    "    # –ì—Ä–∞—Ñ—ñ–∫\n",    "    plt.figure(figsize=(8, 6))\n",    "    plt.scatter(y_test, y_pred, alpha=0.6, color=\"blue\", label=\"–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ vs –†–µ–∞–ª—å–Ω—ñ\")\n",    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label=\"–Ü–¥–µ–∞–ª—å–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å\")\n",    "    plt.xlabel(\"–†–µ–∞–ª—å–Ω—ñ –æ—Ü—ñ–Ω–∫–∏\")\n",    "    plt.ylabel(\"–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ –æ—Ü—ñ–Ω–∫–∏\")222\n",    "    plt.title(f\"–ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö –æ—Ü—ñ–Ω–æ–∫ {file}\")\n",    "    plt.legend()\n",    "    graph_path = os.path.join(GRAPHS_FOLDER, f\"prediction_scatter_{file.replace('.csv','')}.png\")\n",    "    plt.savefig(graph_path, dpi=300, bbox_inches=\"tight\")\n",    "    plt.close()\n",    "\n",    "    print(f\"‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {graph_path}\")\n"   ],   "id": "48589a22555b48a2",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2020.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/3938085748.py:27: DtypeWarning: Columns (96,97,100,102,103,104,105,116,117,120,122,123,124,125) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score: 0.169\n",      "üîπ Mean Squared Error: 443.08\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2020.png\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2021.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/3938085748.py:27: DtypeWarning: Columns (117,118,121,123,124,125,126,137,138,141,143,144,145,146) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score: 0.144\n",      "üîπ Mean Squared Error: 463.88\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2021.png\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2023.csv\n",      "üîπ R¬≤ Score: 0.161\n",      "üîπ Mean Squared Error: 201.97\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2023.png\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2022.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/3938085748.py:27: DtypeWarning: Columns (8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score: 0.153\n",      "üîπ Mean Squared Error: 214.73\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2022.png\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2019.csv\n"     ]    },    {     "name": "stderr",     "output_type": "stream",     "text": [      "/var/folders/gh/9jz8pwfn5cv995vfm04sql_40000gn/T/ipykernel_56086/3938085748.py:27: DtypeWarning: Columns (100,116,117,120,122,123,124,125) have mixed types. Specify dtype option on import or set low_memory=False.\n",      "  df = pd.read_csv(path)\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîπ R¬≤ Score: 0.169\n",      "üîπ Mean Squared Error: 424.28\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2019.png\n",      "\n",      "üìÇ –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É: 2024.csv\n",      "üîπ R¬≤ Score: 0.133\n",      "üîπ Mean Squared Error: 261.14\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/graphs/prediction_scatter_2024.png\n"     ]    }   ],   "execution_count": 66  },  {   "metadata": {},   "cell_type": "code",   "outputs": [],   "execution_count": null,   "source": "",   "id": "39a26e8d41f018d3"  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}