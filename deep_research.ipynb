{ "cells": [  {   "cell_type": "code",   "id": "initial_id",   "metadata": {    "collapsed": true   },   "source": [    "import pandas as pd\n",    "import os\n",    "\n",    "\n",    "INPUT_FOLDER = \"filtered_data\"\n",    "RESULTS_FOLDER = \"results\"\n",    "os.makedirs(RESULTS_FOLDER, exist_ok=True)\n",    "\n",    "\n",    "selected_types = [\"–ª—ñ—Ü–µ–π\", \"–≥—ñ–º–Ω–∞–∑—ñ—è\", \"–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å\", \n",    "                  \"—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞\", \"–∑–∞–∫–ª–∞–¥ —Ñ–∞—Ö–æ–≤–æ—ó –ø–µ—Ä–µ–¥–≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏\", \"—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞\"]\n",    "\n",    "def count_education_types_by_location(df, year):\n",    "    required_cols = ['education_org_type', 'territory_type']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: education_org_type –∞–±–æ territory_type —É —Ñ–∞–π–ª—ñ –¥–ª—è {year}\")\n",    "        return None\n",    "    \n",    "    df_filtered = df[df['education_org_type'].isin(selected_types)].copy()\n",    "    \n",    "    valid_locations = df_filtered['territory_type'].dropna().unique().tolist()\n",    "    if not valid_locations:\n",    "        print(f\"‚ö†Ô∏è –ñ–æ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö –ø—Ä–æ territory_type –¥–ª—è {year}\")\n",    "        return None\n",    "\n",    "    result = df_filtered.groupby(['territory_type', 'education_org_type']).size().unstack(fill_value=0)\n",    "\n",    "    result = result.loc[valid_locations]\n",    "    \n",    "    return result\n",    "\n",    "\n",    "all_results = {}\n",    "for filename in os.listdir(INPUT_FOLDER):\n",    "    if not filename.endswith(\".csv\"):\n",    "        continue\n",    "    \n",    "    file_path = os.path.join(INPUT_FOLDER, filename)\n",    "    year = filename.split('.')[0]  \n",    "    print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename} ({year})...\")\n",    "    \n",    "    try:\n",    "        df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip', low_memory=False)\n",    "        print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "        \n",    "        result = count_education_types_by_location(df, year)\n",    "        if result is not None:\n",    "            all_results[year] = result\n",    "            print(f\"‚úÖ –î–∞–Ω—ñ –¥–ª—è {filename} ({year}) –æ–±—Ä–æ–±–ª–µ–Ω–æ\")\n",    "    \n",    "    except Exception as e:\n",    "        print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "        import traceback\n",    "        traceback.print_exc()\n",    "\n",    "\n",    "if all_results:\n",    "    for year, result in all_results.items():\n",    "        output_path = os.path.join(RESULTS_FOLDER, f\"education_types_by_location_{year}.csv\")\n",    "        result.to_csv(output_path)\n",    "        print(f\"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è {year} –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: {output_path}\")\n",    "else:\n",    "    print(\"‚ö†Ô∏è –ñ–æ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö –Ω–µ –æ–±—Ä–æ–±–ª–µ–Ω–æ\")\n",    "\n",    "print(f\"\\nüéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{RESULTS_FOLDER}'\")"   ],   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import matplotlib.pyplot as plt\n",    "import seaborn as sns\n",    "import os\n",    "\n",    "\n",    "INPUT_FOLDER = \"filtered_data\"\n",    "RESULTS_FOLDER = \"results\"\n",    "GRAPHS_FOLDER = os.path.join(RESULTS_FOLDER, \"graphs\")\n",    "for folder in [RESULTS_FOLDER, GRAPHS_FOLDER]:\n",    "    os.makedirs(folder, exist_ok=True)\n",    "\n",    "selected_types = [\"–ª—ñ—Ü–µ–π\", \"–≥—ñ–º–Ω–∞–∑—ñ—è\", \"–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å\", \n",    "                  \"—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞\", \"–∑–∞–∫–ª–∞–¥ —Ñ–∞—Ö–æ–≤–æ—ó –ø–µ—Ä–µ–¥–≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏\", \"—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞\"]\n",    "\n",    "def visualize_education_types_by_location_2022():\n",    "    filename = \"2022.csv\"\n",    "    file_path = os.path.join(INPUT_FOLDER, filename)\n",    "    \n",    "    print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename}...\")\n",    "    \n",    "    try:\n",    "        df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip', low_memory=False)\n",    "        print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "        \n",    "        required_cols = ['education_org_type', 'territory_type']\n",    "        if not all(col in df.columns for col in required_cols):\n",    "            print(\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: education_org_type –∞–±–æ territory_type\")\n",    "            return\n",    "        \n",    "        df_filtered = df[df['education_org_type'].isin(selected_types)].copy()\n",    "        \n",    "        locations = [\"—Å–µ–ª–∏—â–µ, —Å–µ–ª–æ\", \"—Å–µ–ª–∏—â–µ –º—ñ—Å—å–∫–æ–≥–æ —Ç–∏–ø—É\", \"–º—ñ—Å—Ç–æ\"]\n",    "        df_filtered = df_filtered[df_filtered['territory_type'].isin(locations)]\n",    "        \n",    "        if df_filtered.empty:\n",    "            print(\"‚ö†Ô∏è –ñ–æ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö –ø—Ä–æ territory_type —Å–µ—Ä–µ–¥ –∑–∞–¥–∞–Ω–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π\")\n",    "            return\n",    "        \n",    "        total_locations = df_filtered['territory_type'].value_counts().reindex(locations, fill_value=0)\n",    "        \n",    "        result = df_filtered.groupby(['territory_type', 'education_org_type']).size().unstack(fill_value=0)\n",    "        \n",    "        for edu_type in selected_types:\n",    "            if edu_type not in result.columns:\n",    "                result[edu_type] = 0\n",    "        \n",    "        result = result.reindex(index=locations)\n",    "        \n",    "        print(f\"   –ù–∞—è–≤–Ω—ñ —Ç–∏–ø–∏ –∑–∞–∫–ª–∞–¥—ñ–≤: {list(result.columns)}\")\n",    "        \n",    "        relative_result = result.div(total_locations, axis=0)\n",    "        \n",    "        relative_result_long = relative_result.reset_index().melt(\n",    "            id_vars='territory_type',\n",    "            var_name='education_org_type',\n",    "            value_name='relative_count'\n",    "        )\n",    "        \n",    "        sns.set_style(\"whitegrid\")\n",    "        plt.figure(figsize=(10, 6))\n",    "\n",    "        g = sns.catplot(\n",    "            x='territory_type',\n",    "            y='relative_count',\n",    "            hue='education_org_type',\n",    "            data=relative_result_long,\n",    "            kind='bar',\n",    "            height=6,\n",    "            aspect=1.5,\n",    "            palette='Set3',\n",    "            alpha=0.8\n",    "        )\n",    "        \n",    "        g.fig.suptitle(\"Relative distribution of types of establishments by type of settlement (2022)\", y=1.05)\n",    "        g.set_axis_labels(\"Type of settlement\", \"Relative number of establishments per settlement\")\n",    "        g.set_xticklabels(rotation=45, ha='right')\n",    "\n",    "        g._legend.set_bbox_to_anchor((1.05, 1.1)) \n",    "        g._legend.set_loc('upper right') \n",    "        \n",    "        graph_path = os.path.join(GRAPHS_FOLDER, \"education_types_by_location_2022_relative.png\")\n",    "        g.figure.tight_layout()\n",    "        g.figure.savefig(graph_path, dpi=300, bbox_inches=\"tight\")\n",    "        plt.close()\n",    "        print(f\"‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: {graph_path}\")\n",    "\n",    "    \n",    "    except Exception as e:\n",    "        print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "        import traceback\n",    "        traceback.print_exc()\n",    "\n",    "visualize_education_types_by_location_2022()\n",    "\n",    "print(f\"\\nüéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{RESULTS_FOLDER}'\")"   ],   "id": "61f31e64b10be968",   "outputs": [],   "execution_count": null  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-07-08T15:19:04.457279Z",     "start_time": "2025-07-08T15:18:44.101910Z"    }   },   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import os\n",    "import re\n",    "\n",    "INPUT_FOLDER = \"filtered_data\"\n",    "RESULTS_FOLDER = \"results\"\n",    "for folder in [RESULTS_FOLDER]:\n",    "    os.makedirs(folder, exist_ok=True)\n",    "\n",    "selected_types = [\"–ª—ñ—Ü–µ–π\", \"–≥—ñ–º–Ω–∞–∑—ñ—è\", \"–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å\", \n",    "                  \"—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞\", \"–∑–∞–∫–ª–∞–¥ —Ñ–∞—Ö–æ–≤–æ—ó –ø–µ—Ä–µ–¥–≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏\", \"—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞\"]\n",    "\n",    "def analyze_averages_by_year():\n",    "    for filename in os.listdir(INPUT_FOLDER):\n",    "        if not filename.endswith(\".csv\"):\n",    "            continue\n",    "        year = re.search(r'(\\d{4})', filename)\n",    "        if not year:\n",    "            print(f\"‚ö†Ô∏è –ù–µ–º–æ–∂–ª–∏–≤–æ –≤–∏–∑–Ω–∞—á–∏—Ç–∏ —Ä—ñ–∫ –¥–ª—è {filename}\")\n",    "            continue\n",    "        year = year.group(1)\n",    "        \n",    "        file_path = os.path.join(INPUT_FOLDER, filename)\n",    "        print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename} ({year})...\")\n",    "        \n",    "        try:\n",    "            df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip', low_memory=False)\n",    "            print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "\n",    "            required_cols = ['education_org_type', 'territory_type', 'average_score']\n",    "            if not all(col in df.columns for col in required_cols):\n",    "                print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(col for col in required_cols if col not in df.columns)} —É {filename}\")\n",    "                continue\n",    "\n",    "            df_filtered = df[df['education_org_type'].isin(selected_types)].copy()\n",    "\n",    "            locations = [\"—Å–µ–ª–∏—â–µ, —Å–µ–ª–æ\", \"—Å–µ–ª–∏—â–µ –º—ñ—Å—å–∫–æ–≥–æ —Ç–∏–ø—É\", \"–º—ñ—Å—Ç–æ\", \"—ñ–Ω—à–∞ –∫—Ä–∞—ó–Ω–∞\", \"—Å–µ–ª–æ\"]\n",    "            df_filtered = df_filtered[df_filtered['territory_type'].isin(locations)]\n",    "            \n",    "            if df_filtered.empty:\n",    "                print(f\"‚ö†Ô∏è –ñ–æ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –≤–∏–±—Ä–∞–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –∑–∞–∫–ª–∞–¥—ñ–≤ –∞–±–æ –ø–æ—Å–µ–ª–µ–Ω—å —É {filename}\")\n",    "                continue\n",    "                \n",    "            avg_result = df_filtered.groupby(['territory_type', 'education_org_type']).agg({\n",    "                'average_score': 'mean', \n",    "                'average_score': 'size'   \n",    "            }).reset_index()\n",    "            avg_result.rename(columns={'average_score': 'count'}, inplace=True)  \n",    "            avg_result['average_score'] = df_filtered.groupby(['territory_type', 'education_org_type'])['average_score'].mean().values \n",    "\n",    "            avg_result['year'] = year\n",    "\n",    "            output_path = os.path.join(RESULTS_FOLDER, f\"average_scores_{year}.csv\")\n",    "            avg_result.to_csv(output_path, index=False)\n",    "            print(f\"‚úÖ –¢–∞–±–ª–∏—á–∫–∞ –¥–ª—è {year} –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: {output_path}\")\n",    "        \n",    "        except Exception as e:\n",    "            print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "            import traceback\n",    "            traceback.print_exc()\n",    "\n",    "    print(f\"\\nüéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{RESULTS_FOLDER}'\")\n",    "\n",    "analyze_averages_by_year()"   ],   "id": "5ab28757896bd048",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîÑ –û–±—Ä–æ–±–∫–∞ 2020.csv (2020)...\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 201212 —Ä—è–¥–∫—ñ–≤, 131 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚úÖ –¢–∞–±–ª–∏—á–∫–∞ –¥–ª—è 2020 –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: results/average_scores_2020.csv\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2021.csv (2021)...\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 188609 —Ä—è–¥–∫—ñ–≤, 152 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚úÖ –¢–∞–±–ª–∏—á–∫–∞ –¥–ª—è 2021 –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: results/average_scores_2021.csv\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2023.csv (2023)...\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 256313 —Ä—è–¥–∫—ñ–≤, 64 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚úÖ –¢–∞–±–ª–∏—á–∫–∞ –¥–ª—è 2023 –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: results/average_scores_2023.csv\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2022.csv (2022)...\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 213647 —Ä—è–¥–∫—ñ–≤, 36 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚úÖ –¢–∞–±–ª–∏—á–∫–∞ –¥–ª—è 2022 –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: results/average_scores_2022.csv\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2019.csv (2019)...\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 172734 —Ä—è–¥–∫—ñ–≤, 131 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚úÖ –¢–∞–±–ª–∏—á–∫–∞ –¥–ª—è 2019 –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: results/average_scores_2019.csv\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2024.csv (2024)...\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 264164 —Ä—è–¥–∫—ñ–≤, 78 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚úÖ –¢–∞–±–ª–∏—á–∫–∞ –¥–ª—è 2024 –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: results/average_scores_2024.csv\n",      "\n",      "üéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ 'results'\n"     ]    }   ],   "execution_count": 31  },  {   "metadata": {},   "cell_type": "code",   "source": "",   "id": "caba2d0a5523a1c4",   "outputs": [],   "execution_count": null  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}