{ "cells": [  {   "cell_type": "code",   "id": "initial_id",   "metadata": {    "collapsed": true,    "ExecuteTime": {     "start_time": "2025-07-08T09:57:35.511939Z"    }   },   "source": [    "import pandas as pd\n",    "import os\n",    "\n",    "# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–∞–ø–æ–∫\n",    "INPUT_FOLDER = \"filtered_data\"\n",    "RESULTS_FOLDER = \"results\"\n",    "os.makedirs(RESULTS_FOLDER, exist_ok=True)\n",    "\n",    "# –í–∏–∑–Ω–∞—á–µ–Ω—ñ —Ç–∏–ø–∏ –∑–∞–∫–ª–∞–¥—ñ–≤\n",    "selected_types = [\"–ª—ñ—Ü–µ–π\", \"–≥—ñ–º–Ω–∞–∑—ñ—è\", \"–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å\", \n",    "                  \"—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞\", \"–∑–∞–∫–ª–∞–¥ —Ñ–∞—Ö–æ–≤–æ—ó –ø–µ—Ä–µ–¥–≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏\", \"—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞\"]\n",    "\n",    "def count_education_types_by_location(df, year):\n",    "    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",    "    required_cols = ['education_org_type', 'territory_type']\n",    "    if not all(col in df.columns for col in required_cols):\n",    "        print(f\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: education_org_type –∞–±–æ territory_type —É —Ñ–∞–π–ª—ñ –¥–ª—è {year}\")\n",    "        return None\n",    "    \n",    "    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ª–∏—à–µ –≤–∏–±—Ä–∞–Ω—ñ —Ç–∏–ø–∏\n",    "    df_filtered = df[df['education_org_type'].isin(selected_types)].copy()\n",    "    \n",    "    # –û—Ç—Ä–∏–º—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ —Ç–∏–ø–∏ –ø–æ—Å–µ–ª–µ–Ω—å –¥–ª—è —Ü—å–æ–≥–æ —Ä–æ–∫—É\n",    "    valid_locations = df_filtered['territory_type'].dropna().unique().tolist()\n",    "    if not valid_locations:\n",    "        print(f\"‚ö†Ô∏è –ñ–æ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö –ø—Ä–æ territory_type –¥–ª—è {year}\")\n",    "        return None\n",    "    \n",    "    # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ç–∏–ø—É –∑–∞–∫–ª–∞–¥—É –∑–∞ —Ç–∏–ø–æ–º –ø–æ—Å–µ–ª–µ–Ω–Ω—è\n",    "    result = df_filtered.groupby(['territory_type', 'education_org_type']).size().unstack(fill_value=0)\n",    "    \n",    "    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ª–∏—à–µ –∑–∞–¥–∞–Ω—ñ —Ç–∏–ø–∏ –ø–æ—Å–µ–ª–µ–Ω—å, —â–æ —î –≤ –¥–∞–Ω–∏—Ö\n",    "    result = result.loc[valid_locations]\n",    "    \n",    "    return result\n",    "\n",    "# –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—ñ–≤\n",    "all_results = {}\n",    "for filename in os.listdir(INPUT_FOLDER):\n",    "    if not filename.endswith(\".csv\"):\n",    "        continue\n",    "    \n",    "    file_path = os.path.join(INPUT_FOLDER, filename)\n",    "    year = filename.split('.')[0]  # –û—Ç—Ä–∏–º—É—î–º–æ —Ä—ñ–∫ —ñ–∑ –Ω–∞–∑–≤–∏ —Ñ–∞–π–ª—É\n",    "    print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename} ({year})...\")\n",    "    \n",    "    try:\n",    "        df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip', low_memory=False)\n",    "        print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "        \n",    "        result = count_education_types_by_location(df, year)\n",    "        if result is not None:\n",    "            all_results[year] = result\n",    "            print(f\"‚úÖ –î–∞–Ω—ñ –¥–ª—è {filename} ({year}) –æ–±—Ä–æ–±–ª–µ–Ω–æ\")\n",    "    \n",    "    except Exception as e:\n",    "        print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "        import traceback\n",    "        traceback.print_exc()\n",    "\n",    "# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä–æ–∫—É\n",    "if all_results:\n",    "    for year, result in all_results.items():\n",    "        output_path = os.path.join(RESULTS_FOLDER, f\"education_types_by_location_{year}.csv\")\n",    "        result.to_csv(output_path)\n",    "        print(f\"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è {year} –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: {output_path}\")\n",    "else:\n",    "    print(\"‚ö†Ô∏è –ñ–æ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö –Ω–µ –æ–±—Ä–æ–±–ª–µ–Ω–æ\")\n",    "\n",    "print(f\"\\nüéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{RESULTS_FOLDER}'\")"   ],   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîÑ –û–±—Ä–æ–±–∫–∞ 2020.csv (2020)...\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 201212 —Ä—è–¥–∫—ñ–≤, 131 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "‚úÖ –î–∞–Ω—ñ –¥–ª—è 2020.csv (2020) –æ–±—Ä–æ–±–ª–µ–Ω–æ\n",      "üîÑ –û–±—Ä–æ–±–∫–∞ 2021.csv (2021)...\n"     ]    },    {     "ename": "KeyboardInterrupt",     "evalue": "",     "output_type": "error",     "traceback": [      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",      "Cell \u001B[0;32mIn[14], line 48\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124müîÑ –û–±—Ä–æ–±–∫–∞ \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00myear\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon_bad_lines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mskip\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlow_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(df)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m —Ä—è–¥–∫—ñ–≤, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(df\u001B[38;5;241m.\u001B[39mcolumns)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m —Å—Ç–æ–≤–ø—Ü—ñ–≤\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     51\u001B[0m     result \u001B[38;5;241m=\u001B[39m count_education_types_by_location(df, year)\n",      "File \u001B[0;32m~/PycharmProjects/Ma_2/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",      "File \u001B[0;32m~/PycharmProjects/Ma_2/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",      "File \u001B[0;32m~/PycharmProjects/Ma_2/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     (\n\u001B[1;32m   1920\u001B[0m         index,\n\u001B[1;32m   1921\u001B[0m         columns,\n\u001B[1;32m   1922\u001B[0m         col_dict,\n\u001B[0;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",      "File \u001B[0;32m~/PycharmProjects/Ma_2/.venv/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:239\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 239\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_first_chunk:\n",      "File \u001B[0;32mparsers.pyx:820\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read\u001B[0;34m()\u001B[0m\n",      "File \u001B[0;32mparsers.pyx:921\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",      "File \u001B[0;32mparsers.pyx:1083\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[0;34m()\u001B[0m\n",      "File \u001B[0;32mparsers.pyx:1456\u001B[0m, in \u001B[0;36mpandas._libs.parsers._maybe_upcast\u001B[0;34m()\u001B[0m\n",      "File \u001B[0;32m~/PycharmProjects/Ma_2/.venv/lib/python3.12/site-packages/numpy/_core/multiarray.py:1148\u001B[0m, in \u001B[0;36mputmask\u001B[0;34m(a, mask, values)\u001B[0m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1101\u001B[0m \u001B[38;5;124;03m    copyto(dst, src, casting='same_kind', where=True)\u001B[39;00m\n\u001B[1;32m   1102\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1143\u001B[0m \n\u001B[1;32m   1144\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (dst, src, where)\n\u001B[0;32m-> 1148\u001B[0m \u001B[38;5;129m@array_function_from_c_func_and_dispatcher\u001B[39m(_multiarray_umath\u001B[38;5;241m.\u001B[39mputmask)\n\u001B[1;32m   1149\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mputmask\u001B[39m(a, \u001B[38;5;241m/\u001B[39m, mask, values):\n\u001B[1;32m   1150\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1151\u001B[0m \u001B[38;5;124;03m    putmask(a, mask, values)\u001B[39;00m\n\u001B[1;32m   1152\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1189\u001B[0m \n\u001B[1;32m   1190\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (a, mask, values)\n",      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "     ]    }   ],   "execution_count": 14  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2025-07-08T10:11:07.056970Z",     "start_time": "2025-07-08T10:11:04.961502Z"    }   },   "cell_type": "code",   "source": [    "import pandas as pd\n",    "import matplotlib.pyplot as plt\n",    "import seaborn as sns\n",    "import os\n",    "\n",    "# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–∞–ø–æ–∫\n",    "INPUT_FOLDER = \"filtered_data\"\n",    "RESULTS_FOLDER = \"results\"\n",    "GRAPHS_FOLDER = os.path.join(RESULTS_FOLDER, \"graphs\")\n",    "for folder in [RESULTS_FOLDER, GRAPHS_FOLDER]:\n",    "    os.makedirs(folder, exist_ok=True)\n",    "\n",    "# –í–∏–∑–Ω–∞—á–µ–Ω—ñ —Ç–∏–ø–∏ –∑–∞–∫–ª–∞–¥—ñ–≤\n",    "selected_types = [\"–ª—ñ—Ü–µ–π\", \"–≥—ñ–º–Ω–∞–∑—ñ—è\", \"–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å\", \n",    "                  \"—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞\", \"–∑–∞–∫–ª–∞–¥ —Ñ–∞—Ö–æ–≤–æ—ó –ø–µ—Ä–µ–¥–≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏\", \"—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞\"]\n",    "\n",    "def visualize_education_types_by_location_2022():\n",    "    # –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É 2022 —Ä–æ–∫—É\n",    "    filename = \"2022.csv\"\n",    "    file_path = os.path.join(INPUT_FOLDER, filename)\n",    "    \n",    "    print(f\"üîÑ –û–±—Ä–æ–±–∫–∞ {filename}...\")\n",    "    \n",    "    try:\n",    "        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ñ–∞–π–ª\n",    "        df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip', low_memory=False)\n",    "        print(f\"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤, {len(df.columns)} —Å—Ç–æ–≤–ø—Ü—ñ–≤\")\n",    "        \n",    "        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",    "        required_cols = ['education_org_type', 'territory_type']\n",    "        if not all(col in df.columns for col in required_cols):\n",    "            print(\"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: education_org_type –∞–±–æ territory_type\")\n",    "            return\n",    "        \n",    "        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ª–∏—à–µ –≤–∏–±—Ä–∞–Ω—ñ —Ç–∏–ø–∏\n",    "        df_filtered = df[df['education_org_type'].isin(selected_types)].copy()\n",    "        \n",    "        # –û—Ç—Ä–∏–º—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ —Ç–∏–ø–∏ –ø–æ—Å–µ–ª–µ–Ω—å —ñ —Ñ—ñ–∫—Å—É—î–º–æ –ø–æ—Ä—è–¥–æ–∫\n",    "        locations = [\"—Å–µ–ª–∏—â–µ, —Å–µ–ª–æ\", \"—Å–µ–ª–∏—â–µ –º—ñ—Å—å–∫–æ–≥–æ —Ç–∏–ø—É\", \"–º—ñ—Å—Ç–æ\"]\n",    "        df_filtered = df_filtered[df_filtered['territory_type'].isin(locations)]\n",    "        \n",    "        if df_filtered.empty:\n",    "            print(\"‚ö†Ô∏è –ñ–æ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö –ø—Ä–æ territory_type —Å–µ—Ä–µ–¥ –∑–∞–¥–∞–Ω–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π\")\n",    "            return\n",    "        \n",    "        # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–∂–Ω–æ–≥–æ —Ç–∏–ø—É –ø–æ—Å–µ–ª–µ–Ω–Ω—è\n",    "        total_locations = df_filtered['territory_type'].value_counts().reindex(locations, fill_value=0)\n",    "        \n",    "        # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ç–∏–ø—É –∑–∞–∫–ª–∞–¥—É –∑–∞ —Ç–∏–ø–æ–º –ø–æ—Å–µ–ª–µ–Ω–Ω—è\n",    "        result = df_filtered.groupby(['territory_type', 'education_org_type']).size().unstack(fill_value=0)\n",    "        \n",    "        # –î–æ–¥–∞—î–º–æ –≤—Å—ñ selected_types, –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ —ó—Ö –Ω–µ–º–∞—î –≤ –¥–∞–Ω–∏—Ö\n",    "        for edu_type in selected_types:\n",    "            if edu_type not in result.columns:\n",    "                result[edu_type] = 0\n",    "        \n",    "        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ª–∏—à–µ –∑–∞–¥–∞–Ω—ñ —Ç–∏–ø–∏ –ø–æ—Å–µ–ª–µ–Ω—å —É –∑–∞–¥–∞–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É\n",    "        result = result.reindex(index=locations)\n",    "        \n",    "        # –í–∏–≤–æ–¥–∏–º–æ –Ω–∞—è–≤–Ω—ñ —Ç–∏–ø–∏ –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\n",    "        print(f\"   –ù–∞—è–≤–Ω—ñ —Ç–∏–ø–∏ –∑–∞–∫–ª–∞–¥—ñ–≤: {list(result.columns)}\")\n",    "        \n",    "        # –û–±—á–∏—Å–ª—é—î–º–æ –≤—ñ–¥–Ω–æ—Å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–∫–ª–∞–¥—É / –∑–∞–≥–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ—Å–µ–ª–µ–Ω–Ω—è\n",    "        relative_result = result.div(total_locations, axis=0)\n",    "        \n",    "        # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –≤ –¥–æ–≤–≥–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è seaborn\n",    "        relative_result_long = relative_result.reset_index().melt(\n",    "            id_vars='territory_type',\n",    "            var_name='education_org_type',\n",    "            value_name='relative_count'\n",    "        )\n",    "        \n",    "        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–∏–ª—é seaborn\n",    "        sns.set_style(\"whitegrid\")\n",    "        plt.figure(figsize=(10, 6))\n",    "        \n",    "        # –°—Ç–≤–æ—Ä—é—î–º–æ stacked bar chart –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é seaborn\n",    "        sns.catplot(\n",    "            x='territory_type',\n",    "            y='relative_count',\n",    "            hue='education_org_type',\n",    "            data=relative_result_long,\n",    "            kind='bar',\n",    "            height=6,\n",    "            aspect=1.5,\n",    "            palette='Set3',\n",    "            alpha=0.8\n",    "        )\n",    "        \n",    "        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤ —ñ –º—ñ—Ç–æ–∫\n",    "        plt.title(\"–í—ñ–¥–Ω–æ—Å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª —Ç–∏–ø—ñ–≤ –∑–∞–∫–ª–∞–¥—ñ–≤ –∑–∞ —Ç–∏–ø–∞–º–∏ –ø–æ—Å–µ–ª–µ–Ω—å (2022 —Ä—ñ–∫)\")\n",    "        plt.xlabel(\"–¢–∏–ø –ø–æ—Å–µ–ª–µ–Ω–Ω—è\")\n",    "        plt.ylabel(\"–í—ñ–¥–Ω–æ—Å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–∫–ª–∞–¥—ñ–≤ –Ω–∞ –ø–æ—Å–µ–ª–µ–Ω–Ω—è\")\n",    "        \n",    "        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –æ—Å—ñ X\n",    "        plt.xticks(rotation=45, ha='right')\n",    "        \n",    "        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫–∞\n",    "        graph_path = os.path.join(GRAPHS_FOLDER, \"education_types_by_location_2022_relative.png\")\n",    "        plt.tight_layout()\n",    "        plt.savefig(graph_path, dpi=300, bbox_inches=\"tight\")\n",    "        plt.close()\n",    "        print(f\"‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: {graph_path}\")\n",    "    \n",    "    except Exception as e:\n",    "        print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ {filename}: {e}\")\n",    "        import traceback\n",    "        traceback.print_exc()\n",    "\n",    "# –í–∏–∫–ª–∏–∫ —Ñ—É–Ω–∫—Ü—ñ—ó\n",    "visualize_education_types_by_location_2022()\n",    "\n",    "print(f\"\\nüéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ '{RESULTS_FOLDER}'\")"   ],   "id": "61f31e64b10be968",   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "üîÑ –û–±—Ä–æ–±–∫–∞ 2022.csv...\n",      "   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 213647 —Ä—è–¥–∫—ñ–≤, 36 —Å—Ç–æ–≤–ø—Ü—ñ–≤\n",      "   –ù–∞—è–≤–Ω—ñ —Ç–∏–ø–∏ –∑–∞–∫–ª–∞–¥—ñ–≤: ['–≥—ñ–º–Ω–∞–∑—ñ—è', '–∑–∞–∫–ª–∞–¥ —Ñ–∞—Ö–æ–≤–æ—ó –ø–µ—Ä–µ–¥–≤–∏—â–æ—ó –æ—Å–≤—ñ—Ç–∏', '–ª—ñ—Ü–µ–π', '–Ω–∞–≤—á–∞–ª—å–Ω–æ-–≤–∏—Ö–æ–≤–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å', '—Å–µ—Ä–µ–¥–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–æ—Å–≤—ñ—Ç–Ω—è —à–∫–æ–ª–∞', '—Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —à–∫–æ–ª–∞']\n",      "‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: results/graphs/education_types_by_location_2022_relative.png\n",      "\n",      "üéâ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ 'results'\n"     ]    },    {     "data": {      "text/plain": [       "<Figure size 1000x600 with 0 Axes>"      ]     },     "metadata": {},     "output_type": "display_data"    }   ],   "execution_count": 19  },  {   "metadata": {},   "cell_type": "code",   "outputs": [],   "execution_count": null,   "source": "",   "id": "5ab28757896bd048"  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}